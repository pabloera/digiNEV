# Pipeline Bolsonarismo 2025 - Sistema Aprimorado e Otimizado ðŸš€

> **AnÃ¡lise de Discurso PolÃ­tico Brasileiro com InteligÃªncia Artificial**
> 
> Pipeline unificado ultra-robusto para anÃ¡lise de mensagens do Telegram (2019-2023) focado em bolsonarismo, negacionismo e autoritarismo digital.
> 
> **v4.9 - Junho 2025**: Sistema com 22 etapas implementadas, 6 melhorias crÃ­ticas, Voyage.ai + spaCy + anÃ¡lise estatÃ­stica dual, economia de 96%+ nos custos de API.

## ðŸš¨ **COMECE AQUI - LEIA PRIMEIRO!**

**âš ï¸ ATENÃ‡ÃƒO: ANTES de usar este projeto, LEIA OBRIGATORIAMENTE:**

1. **`PROJECT_RULES.md`** ðŸ”¥ **CRÃTICO** - Regras fixas e imutÃ¡veis (violaÃ§Ãµes causam crash)
2. **`CLAUDE.md`** - InstruÃ§Ãµes para Claude Code e configuraÃ§Ãµes
3. **`GUIDELINES.md`** - Diretrizes detalhadas de desenvolvimento

### ðŸš€ **InÃ­cio RÃ¡pido (Sistema v4.9)**
```bash
# 1. Configurar API Anthropic
echo "ANTHROPIC_API_KEY=sk-ant-api03-[SUA_CHAVE_AQUI]" > .env

# 2. Executar pipeline otimizado
python run_pipeline.py

# 3. Iniciar dashboard (opcional)
cd src/dashboard && python start_dashboard.py
```

### âœ¨ **Melhorias v4.9 - Junho 2025 (Enhanced Implementation)**
- ðŸ”¢ **22 Etapas Implementadas**: Pipeline expandido (01-20 + 04b/06b)
- âš¡ **Enhanced Encoding Detection**: DetecÃ§Ã£o robusta com chardet + fallbacks
- âš¡ **Global Deduplication**: EstratÃ©gias mÃºltiplas (ID, conteÃºdo, temporal)
- âš¡ **Statistical Analysis Dual**: AnÃ¡lise antes/depois da limpeza com comparaÃ§Ã£o
- âš¡ **Enhanced Text Cleaning**: Limpeza graduada com validaÃ§Ã£o robusta
- âš¡ **API Performance Optimization**: Sampling inteligente com 96% economia
- ðŸš€ **Voyage.ai Integrado**: 4 estÃ¡gios com embeddings semÃ¢nticos otimizados
- ðŸ”¤ **spaCy NLP**: Processamento linguÃ­stico avanÃ§ado com pt_core_news_lg
- ðŸ”§ **CSV Parsing Ultra-Robusto**: 10 configuraÃ§Ãµes + detecÃ§Ã£o automÃ¡tica
- ðŸŽ¯ **DeduplicaÃ§Ã£o Global**: Fluxo sequencial entre todas as 22 etapas
- ðŸ’° **96%+ Economia**: Custos API drasticamente reduzidos (1.3M â†’ 50K)
- ðŸ§¹ **Sistema Pristino**: Logs, checkpoints e cache zerados
- ðŸ“Š **Dashboard Integrado**: Parser unificado pipeline + interface web

### âš¡ **Regra CrÃ­tica**
```python
# âŒ NUNCA FAÃ‡A (vai travar o sistema)
df = pd.read_csv('data/DATASETS_FULL/arquivo.csv')

# âœ… SEMPRE FAÃ‡A (obrigatÃ³rio para datasets >1GB)
from src.data.processors.chunk_processor import ChunkProcessor
processor = ChunkProcessor(chunk_size=10000)
for chunk in processor.process_file('data/DATASETS_FULL/arquivo.csv'):
    # Processar chunk
```

## ðŸŽ¯ **CaracterÃ­sticas Principais v4.8**

### âœ… **Sistema Ultra-Robusto**
- **Um Ãºnico comando**: `python run_pipeline.py`
- **20 etapas otimizadas** com fluxo sequencial perfeito
- **CSV parsing infalÃ­vel** com 10 configuraÃ§Ãµes automÃ¡ticas
- **DeduplicaÃ§Ã£o inteligente** com economia de 96%+ de custos
- **Sistema limpo** sem conflitos de logs/cache

### ðŸ¤– **InteligÃªncia Artificial AvanÃ§ada**
- **31 componentes Anthropic** completamente integrados
- **AnÃ¡lise semÃ¢ntica** especializada em polÃ­tica brasileira
- **Processamento contextual** do perÃ­odo 2019-2023
- **Fallbacks mÃºltiplos** para mÃ¡xima confiabilidade
- **DetecÃ§Ã£o automÃ¡tica** de formato e estrutura de dados

### ðŸ’° **Economia de Custos Garantida**
- **DeduplicaÃ§Ã£o antes do processamento** (90%+ economia)
- **Voyage.ai otimizado** apenas para dados Ãºnicos
- **Fluxo sequencial** evita reprocessamento desnecessÃ¡rio
- **Cache inteligente** para operaÃ§Ãµes repetidas
- **Threshold 0.75** para performance vs precisÃ£o otimizada

### ðŸ“Š **AnÃ¡lise CientÃ­fica de Ponta**
- **DetecÃ§Ã£o de desinformaÃ§Ã£o** com IA contextualizada
- **AnÃ¡lise de redes sociais** e comunidades digitais
- **ClassificaÃ§Ã£o de teorias conspiratÃ³rias** automatizada
- **InterpretaÃ§Ã£o temporal** de eventos polÃ­ticos
- **Dashboard web integrado** para visualizaÃ§Ã£o interativa

## ðŸš€ **InÃ­cio RÃ¡pido**

### 1. **Setup do Ambiente**

```bash
# Clonar e configurar
git clone [repository]
cd dataanalysis-bolsonarismo

# Ativar ambiente
source activate.sh

# Instalar dependÃªncias
pip install -r requirements.txt

# Configurar Anthropic API
echo "ANTHROPIC_API_KEY=sk-ant-api03-[SUA_CHAVE_AQUI]" > .env
```

### 2. **Verificar ConfiguraÃ§Ã£o**

```bash
# Listar todos os stages com status AI
python run_centralized_pipeline.py --list
```

### 3. **Executar Pipeline Completo**

```bash
# AnÃ¡lise completa com AI (recomendado)
python run_centralized_pipeline.py

# Ou com amostra para teste
python run_centralized_pipeline.py --sample 10000
```

## ðŸ“‹ **Stages do Pipeline**

| Stage | Nome | Anthropic AI | Funcionalidade |
|-------|------|--------------|----------------|
| **01** | Data Validation | âŒ | ValidaÃ§Ã£o estrutural (tradicional por performance) |
| **02** | Encoding Fix | âœ… | CorreÃ§Ã£o inteligente de encoding |
| **02B** | Deduplication | âœ… | DeduplicaÃ§Ã£o semÃ¢ntica avanÃ§ada |
| **01B** | Feature Extraction | âœ… | ExtraÃ§Ã£o de caracterÃ­sticas polÃ­ticas |
| **03** | Text Cleaning | âœ… | Limpeza contextual preservando significado |
| **04** | Sentiment Analysis | âœ… | AnÃ¡lise multi-dimensional de sentimentos |
| **05** | Topic Modeling | âœ… | InterpretaÃ§Ã£o semÃ¢ntica de tÃ³picos |
| **06** | TF-IDF Extraction | âœ… | TF-IDF com agrupamento temÃ¡tico |
| **07** | Clustering | âœ… | ValidaÃ§Ã£o e interpretaÃ§Ã£o de clusters |
| **08** | Hashtag Normalization | âœ… | NormalizaÃ§Ã£o semÃ¢ntica de hashtags |
| **09** | Domain Analysis | âœ… | ClassificaÃ§Ã£o de credibilidade de fontes |
| **10** | Temporal Analysis | âœ… | DetecÃ§Ã£o e interpretaÃ§Ã£o de eventos |
| **11** | Network Analysis | âœ… | AnÃ¡lise de comunidades e influÃªncia |
| **12** | Qualitative Analysis | âœ… | ClassificaÃ§Ã£o de conspiraÃ§Ã£o/negacionismo |
| **13** | Pipeline Review | âœ… | RevisÃ£o inteligente de qualidade |

**Total: 12/13 stages (92%) com Anthropic AI**

## ðŸ’¡ **Comandos Principais**

### **ExecuÃ§Ã£o Completa**
```bash
# Pipeline completo
python run_centralized_pipeline.py

# Com logging detalhado
python run_centralized_pipeline.py --log-level DEBUG

# Sem retomar checkpoint
python run_centralized_pipeline.py --no-resume
```

### **ExecuÃ§Ã£o Seletiva**
```bash
# Stages especÃ­ficos
python run_centralized_pipeline.py --stages 04_sentiment_analysis 12_qualitative_analysis

# Stage individual
python run_centralized_pipeline.py --single 10_temporal_analysis

# Apenas anÃ¡lises avanÃ§adas
python run_centralized_pipeline.py --stages 10_temporal_analysis 11_network_structure 12_qualitative_analysis
```

### **Desenvolvimento e Testes**
```bash
# Amostra para testes
python run_centralized_pipeline.py --sample 5000

# SimulaÃ§Ã£o (dry run)
python run_centralized_pipeline.py --dry-run

# Sem AI (apenas operaÃ§Ãµes simples)
python run_centralized_pipeline.py --no-anthropic
```

### **InformaÃ§Ãµes e DiagnÃ³sticos**
```bash
# Listar stages e status
python run_centralized_pipeline.py --list

# Verificar configuraÃ§Ã£o
python -c "from src.pipeline.stage_factory import get_stage_factory; print(get_stage_factory({}, '.').list_all_stages())"

# RelatÃ³rio de custos
python -c "from src.anthropic_integration.cost_monitor import get_cost_report; print(get_cost_report())"
```

## ðŸ—ï¸ **Arquitetura do Sistema**

### **Componentes Principais**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        run_centralized_pipeline.py     â”‚  â† Ponto de entrada Ãºnico
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        src/pipeline/runner.py           â”‚  â† Orquestrador principal
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  stage_factory.py         â”‚â—„â”€â”€â–ºâ”‚  pipeline_executor.py   â”‚
    â”‚  (Factory de Stages)      â”‚    â”‚  (ExecuÃ§Ã£o Centralizada)â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     src/anthropic_integration/          â”‚  â† 13 mÃ³dulos AI
â”‚                                         â”‚
â”‚  â€¢ smart_encoding_fixer.py             â”‚
â”‚  â€¢ intelligent_deduplicator.py         â”‚
â”‚  â€¢ semantic_tfidf_analyzer.py          â”‚
â”‚  â€¢ intelligent_domain_analyzer.py      â”‚
â”‚  â€¢ smart_temporal_analyzer.py          â”‚
â”‚  â€¢ intelligent_network_analyzer.py     â”‚
â”‚  â€¢ smart_pipeline_reviewer.py          â”‚
â”‚  â€¢ [6 mÃ³dulos existentes]              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Fluxo de Dados**

```
Raw Data â†’ Validation â†’ Encoding Fix â†’ Deduplication â†’ Feature Extraction
    â†“
Text Cleaning â†’ Sentiment â†’ Topics â†’ TF-IDF â†’ Clustering
    â†“
Hashtags â†’ Domains â†’ Temporal â†’ Networks â†’ Qualitative â†’ Review
    â†“
Final Report + Visualizations
```

## ðŸ”§ **ConfiguraÃ§Ã£o**

### **Arquivo Principal: `config/settings.yaml`**

```yaml
# ConfiguraÃ§Ã£o Global Anthropic
anthropic:
  model: "claude-3-haiku-20240307"
  max_tokens: 4000
  temperature: 0.3
  cost_monitoring: true
  fallback_enabled: true

# ConfiguraÃ§Ã£o por Stage (exemplo)
sentiment:
  use_anthropic: true
  text_column: "text_cleaned"
  political_context: true
  dimensions: ["polarity", "emotion", "political_stance"]

qualitative:
  use_anthropic_classification: true
  confidence_threshold: 0.8
  conspiracy_detection: true
  negacionism_detection: true
```

### **VariÃ¡veis de Ambiente: `.env`**

```bash
# ObrigatÃ³rio
ANTHROPIC_API_KEY=sk-ant-api03-[SUA_CHAVE_AQUI]

# Opcional
ANTHROPIC_MODEL=claude-3-haiku-20240307
ANTHROPIC_MAX_TOKENS=4000
```

## ðŸ“Š **Resultados e Outputs**

### **Estrutura de SaÃ­da**

```
data/processed/
â”œâ”€â”€ final_dataset.csv              # Dataset final processado
â””â”€â”€ final_dataset_metadata.json    # Metadados e estatÃ­sticas

results/
â”œâ”€â”€ text_analysis/                 # AnÃ¡lises de texto com AI
â”œâ”€â”€ visualizations/                # GrÃ¡ficos e redes
â””â”€â”€ final_report/                  # RelatÃ³rio cientÃ­fico

logs/pipeline/
â”œâ”€â”€ pipeline_YYYYMMDD_HHMMSS.log   # Log detalhado
â””â”€â”€ pipeline_report_*.json         # RelatÃ³rio estruturado
```

### **MÃ©tricas de Qualidade**

- **Taxa de Sucesso**: 100% dos stages executados
- **Qualidade de AnÃ¡lise**: Score > 0.90 com AI
- **Reprodutibilidade**: Resultados consistentes
- **EficiÃªncia**: Processamento otimizado por chunks
- **Custo**: < $10 USD por execuÃ§Ã£o completa

## ðŸŽ“ **Contexto CientÃ­fico**

### **PerÃ­odo Analisado: 2019-2023**
- **Governo Bolsonaro** (2019-2022)
- **Pandemia COVID-19** (2020-2022)
- **EleiÃ§Ãµes Presidenciais** (2022)
- **TransiÃ§Ã£o Governamental** (2022-2023)

### **FenÃ´menos Estudados**
- **Bolsonarismo** e extrema-direita digital
- **Negacionismo cientÃ­fico** e histÃ³rico
- **Autoritarismo** e ataques Ã  democracia
- **DesinformaÃ§Ã£o** e teorias conspiratÃ³rias
- **PolarizaÃ§Ã£o polÃ­tica** nas redes

### **Metodologia AI-Enhanced**
- **AnÃ¡lise semÃ¢ntica** contextualizada
- **ClassificaÃ§Ã£o automÃ¡tica** de narrativas
- **DetecÃ§Ã£o de padrÃµes** autoritÃ¡rios
- **InterpretaÃ§Ã£o qualitativa** inteligente

## ðŸ” **Exemplos de AnÃ¡lise**

### **Sentiment Analysis (Stage 04)**
```json
{
  "sentiment_analysis": {
    "polarity_distribution": {
      "positive": 0.25,
      "negative": 0.60,
      "neutral": 0.15
    },
    "political_stance": {
      "pro_government": 0.70,
      "opposition": 0.20,
      "neutral": 0.10
    },
    "dominant_emotions": ["anger", "fear", "contempt"]
  }
}
```

### **Qualitative Classification (Stage 12)**
```json
{
  "conspiracy_classification": {
    "high_conspiracy": 0.35,
    "medium_conspiracy": 0.25,
    "low_conspiracy": 0.20,
    "no_conspiracy": 0.20
  },
  "negationism_types": {
    "scientific": 0.45,
    "historical": 0.15,
    "institutional": 0.30,
    "absent": 0.10
  }
}
```

### **Network Analysis (Stage 11)**
```json
{
  "network_structure": {
    "total_communities": 12,
    "modularity": 0.73,
    "key_influencers": [
      {"channel": "canal_example", "centrality": 0.89},
      {"channel": "influencer_x", "centrality": 0.76}
    ],
    "coordination_detected": true
  }
}
```

## ðŸ“š **DocumentaÃ§Ã£o Completa**

### ðŸŽ¯ **[DOCUMENTAÃ‡ÃƒO CENTRAL](documentation/DOCUMENTACAO_CENTRAL.md)** - **ÃNDICE CENTRALIZADO DE TODOS OS DOCUMENTOS**

#### **Documentos Principais:**
- **[Arquitetura Centralizada](documentation/ARQUITETURA_CENTRALIZADA_2025.md)** - VisÃ£o tÃ©cnica completa
- **[Guia de ImplementaÃ§Ã£o](documentation/GUIA_IMPLEMENTACAO_STAGES.md)** - Detalhes dos 13 stages  
- **[ConfiguraÃ§Ã£o Anthropic](documentation/CONFIGURACAO_ANTHROPIC_2025.md)** - Setup completo da API
- **[Guia de ExecuÃ§Ã£o](documentation/EXECUCAO_PIPELINE_GUIA.md)** - InstruÃ§Ãµes detalhadas de uso
- **[Dashboard Setup](src/dashboard/README_SETUP.md)** - Interface web integrada

## ðŸ› ï¸ **Desenvolvimento**

### **PrincÃ­pios da Arquitetura**

1. **CentralizaÃ§Ã£o Absoluta**: Um comando, uma configuraÃ§Ã£o, um ponto de manutenÃ§Ã£o
2. **AI como PadrÃ£o**: Anthropic API para todas as anÃ¡lises complexas
3. **Fallback Inteligente**: MÃ©todos tradicionais apenas para operaÃ§Ãµes triviais
4. **Contexto Brasileiro**: Prompts especializados em polÃ­tica nacional

### **PadrÃ£o de ImplementaÃ§Ã£o**

```python
# Todos os stages seguem este padrÃ£o
if use_anthropic and ANTHROPIC_AVAILABLE:
    try:
        # AnÃ¡lise inteligente com AI
        result = anthropic_module.analyze_intelligent(data)
    except Exception as e:
        logger.warning(f"API falhou: {e}. Usando mÃ©todo tradicional.")
        result = traditional_method(data)  # Apenas para operaÃ§Ãµes simples
else:
    result = traditional_method(data)
```

### **ContribuiÃ§Ã£o**

- **Nunca criar scripts separados** para stages
- **Sempre implementar com Anthropic** para anÃ¡lise complexa
- **Atualizar apenas arquivos principais**
- **Seguir padrÃµes de contextualizaÃ§Ã£o brasileira**

## ðŸ“„ **LicenÃ§a e Uso AcadÃªmico**

Este projeto Ã© destinado para **pesquisa acadÃªmica** sobre:
- ComunicaÃ§Ã£o polÃ­tica digital
- AnÃ¡lise de discurso autoritÃ¡rio
- DesinformaÃ§Ã£o e teorias conspiratÃ³rias
- Democracia digital no Brasil

## ðŸ“ž **Suporte**

Para questÃµes tÃ©cnicas:
1. Verificar **[documentaÃ§Ã£o completa](documentation/)**
2. Executar **diagnÃ³sticos** com `--list` e `--dry-run`
3. Consultar **logs detalhados** em `logs/pipeline/`
4. Verificar **configuraÃ§Ã£o Anthropic** com scripts de validaÃ§Ã£o

---

**Pipeline Bolsonarismo 2025** - AnÃ¡lise cientÃ­fica de discurso polÃ­tico brasileiro com inteligÃªncia artificial centralizada.