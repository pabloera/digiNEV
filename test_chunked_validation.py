#!/usr/bin/env python3
"""
Valida√ß√£o R√°pida do Sistema ChunkedAnalyzer
==========================================

Teste r√°pido para validar que o sistema chunked est√° funcionando
corretamente sem sobrecarregar com muitos dados.
"""

import pandas as pd
import logging
import time
import gc
from pathlib import Path
from src.chunked_analyzer import ChunkedAnalyzer

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def clean_system():
    """Limpar sistema."""
    logger.info("üßπ Limpando sistema...")
    gc.collect()
    logger.info("‚úÖ Sistema limpo")

def quick_validation_test():
    """Teste r√°pido de valida√ß√£o do sistema chunked."""
    logger.info("‚ö° VALIDA√á√ÉO R√ÅPIDA - ChunkedAnalyzer")
    logger.info("=" * 50)

    dataset_path = Path("data/1_2019-2021-govbolso.csv")

    if not dataset_path.exists():
        logger.error(f"‚ùå Dataset n√£o encontrado: {dataset_path}")
        return False

    # Limpar sistema
    clean_system()

    # Configurar analyzer com chunks pequenos para teste r√°pido
    analyzer = ChunkedAnalyzer(
        chunk_size=500,  # Chunks pequenos para teste r√°pido
        memory_limit_gb=1.0
    )

    logger.info("üß™ Testando com 2,000 registros em chunks de 500...")

    start_time = time.time()

    try:
        # Executar an√°lise chunked com amostra pequena
        stats = analyzer.analyze_chunked_dataset(
            file_path=str(dataset_path),
            max_records=2000,  # Apenas 2k registros para valida√ß√£o
            output_file="chunked_validation_output.csv"
        )

        end_time = time.time()
        duration = end_time - start_time

        # Validar resultados
        logger.info("‚úÖ VALIDA√á√ÉO CONCLU√çDA:")
        logger.info(f"üìä Registros processados: {stats['total_records_processed']:,}")
        logger.info(f"üì¶ Chunks processados: {stats['total_chunks']}")
        logger.info(f"‚è±Ô∏è Tempo total: {duration:.1f}s")
        logger.info(f"üìà Performance: {stats['performance_records_per_second']:.1f} reg/s")

        # Verificar distribui√ß√£o pol√≠tica
        political_dist = stats['consolidated_stats']['political_distribution']
        if political_dist:
            logger.info(f"üèõÔ∏è Distribui√ß√£o pol√≠tica detectada: {len(political_dist)} categorias")
            top_categories = sorted(political_dist.items(), key=lambda x: x[1], reverse=True)[:3]
            for category, count in top_categories:
                logger.info(f"   ‚Ä¢ {category}: {count} registros")

        # Gerar relat√≥rio
        analyzer.generate_consolidated_report(stats, "RELATORIO_VALIDACAO_CHUNKED.txt")

        logger.info("üéâ SISTEMA CHUNKED VALIDADO COM SUCESSO!")
        return True

    except Exception as e:
        logger.error(f"‚ùå Erro na valida√ß√£o: {e}")
        return False

def test_memory_management():
    """Testar gest√£o de mem√≥ria do sistema."""
    logger.info("\nüß† TESTE DE GEST√ÉO DE MEM√ìRIA")
    logger.info("-" * 40)

    dataset_path = Path("data/1_2019-2021-govbolso.csv")

    # Configurar com limite baixo de mem√≥ria para for√ßar limpezas
    analyzer = ChunkedAnalyzer(
        chunk_size=300,
        memory_limit_gb=0.5  # Limite baixo para testar limpeza
    )

    try:
        # Processar alguns chunks pequenos
        chunk_count = 0
        for chunk in analyzer.load_dataset_chunks(str(dataset_path), max_records=1000):
            chunk_count += 1
            logger.info(f"üì¶ Chunk {chunk_count}: {len(chunk)} registros carregados")

            # Simular processamento
            time.sleep(0.1)

            if chunk_count >= 3:  # Testar apenas 3 chunks
                break

        logger.info(f"‚úÖ Gest√£o de mem√≥ria testada com {chunk_count} chunks")
        return True

    except Exception as e:
        logger.error(f"‚ùå Erro no teste de mem√≥ria: {e}")
        return False

def main():
    """Fun√ß√£o principal de valida√ß√£o."""
    logger.info("üöÄ VALIDA√á√ÉO SISTEMA CHUNKED ANALYZER")
    logger.info("Dataset: Governo Bolsonaro")
    logger.info("=" * 60)

    try:
        # 1. Valida√ß√£o r√°pida
        validation_success = quick_validation_test()

        # 2. Teste de gest√£o de mem√≥ria
        memory_success = test_memory_management()

        # 3. Resultado final
        if validation_success and memory_success:
            logger.info("\nüèÜ VALIDA√á√ÉO COMPLETA: SISTEMA CHUNKED APROVADO")
            logger.info("‚úÖ Processamento em chunks funcionando")
            logger.info("‚úÖ Gest√£o de mem√≥ria operacional")
            logger.info("‚úÖ Sistema pronto para datasets grandes")
        else:
            logger.error("\n‚ùå VALIDA√á√ÉO FALHOU: Verificar problemas")

    except Exception as e:
        logger.error(f"‚ùå Erro na valida√ß√£o: {e}")

if __name__ == "__main__":
    main()