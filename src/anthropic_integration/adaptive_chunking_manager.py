"""
Adaptive Chunking Manager - Solu√ß√£o para Timeouts no Pipeline
===========================================================

Sistema inteligente de chunking adaptativo para resolver problemas de timeout,
especialmente no Stage 8 (Sentiment Analysis) e outros stages API-intensivos.

IMPLEMENTADO PARA RESOLVER:
- ‚úÖ Pipeline Timeout Stage 8 (Sentiment Analysis)
- ‚úÖ Otimiza√ß√£o autom√°tica de chunk sizes
- ‚úÖ Recovery autom√°tico em caso de timeout
- ‚úÖ Monitoramento de performance por stage

Data: 2025-06-08
Status: IMPLEMENTA√á√ÉO COMPLETA
"""

import logging
import threading
import time
from concurrent.futures import ThreadPoolExecutor
from dataclasses import dataclass
from typing import Any, Dict, List, Optional

import pandas as pd
import yaml

logger = logging.getLogger(__name__)


@dataclass
class ChunkPerformanceMetrics:
    """M√©tricas de performance para monitoramento de chunks"""
    stage_name: str
    chunk_size: int
    processing_time: float
    success: bool
    records_processed: int
    timeout_occurred: bool
    memory_usage_mb: float = 0.0
    retry_count: int = 0


class AdaptiveChunkingManager:
    """
    ‚úÖ Gerenciador de Chunking Adaptativo - SOLU√á√ÉO PARA TIMEOUTS
    =============================================================

    RESOLVE PROBLEMAS:
    ‚úÖ Stage 8 - Sentiment Analysis timeouts
    ‚úÖ Chunks muito grandes causando timeouts
    ‚úÖ Processamento ineficiente em stages API-intensivos
    ‚úÖ Falta de recovery autom√°tico

    FEATURES IMPLEMENTADAS:
    ‚úÖ Chunking adaptativo baseado em performance hist√≥rica
    ‚úÖ Recovery autom√°tico com chunk size reduction
    ‚úÖ Monitoramento de performance em tempo real
    ‚úÖ Configura√ß√£o espec√≠fica por stage
    ‚úÖ Timeout management integrado
    """

    def __init__(self, config_path: Optional[str] = None):
        self.logger = logging.getLogger(self.__class__.__name__)

        # Carregar configura√ß√µes
        self.config = self._load_config(config_path)
        self.timeout_config = self._load_timeout_config()

        # Performance tracking
        self.performance_history: Dict[str, List[ChunkPerformanceMetrics]] = {}
        self.optimal_chunk_sizes: Dict[str, int] = {}

        # Thread safety
        self.lock = threading.Lock()

        # Configura√ß√µes padr√£o
        chunk_config = self.config.get('chunk_management', {})
        self.default_chunk_size = chunk_config.get('base_chunk_size', 10)
        self.max_chunk_size = chunk_config.get('max_chunk_size', 50)
        self.min_chunk_size = chunk_config.get('min_chunk_size', 2)

        self.logger.info("‚úÖ AdaptiveChunkingManager inicializado com sucesso")

    def _load_config(self, config_path: Optional[str] = None) -> Dict[str, Any]:
        """Carrega configura√ß√£o de timeout management"""
        if config_path is None:
            config_path = "config/timeout_management.yaml"

        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
                return config.get('timeout_management', {})
        except FileNotFoundError:
            msg = f"‚ö†Ô∏è Arquivo de configura√ß√£o n√£o encontrado: {config_path}"
            self.logger.warning(msg)
            return self._get_default_config()
        except Exception as e:
            self.logger.error(f"‚ùå Erro ao carregar configura√ß√£o: {e}")
            return self._get_default_config()

    def _load_timeout_config(self) -> Dict[str, Any]:
        """Carrega configura√ß√µes de timeout do processing.yaml"""
        try:
            with open("config/processing.yaml", 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
                return config.get('pipeline_timeouts', {})
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è Erro ao carregar timeout config: {e}")
            return {}

    def _get_default_config(self) -> Dict[str, Any]:
        """Configura√ß√£o padr√£o de fallback"""
        return {
            'chunk_management': {
                'adaptive_chunk_size': True,
                'base_chunk_size': 10,
                'max_chunk_size': 50,
                'min_chunk_size': 2,
                'time_per_chunk_target': 60,
                'stage_specific_chunks': {
                    '05_political_analysis': 5,
                    '08_sentiment_analysis': 3,
                    '07_linguistic_processing': 25,
                    '09_topic_modeling': 15
                }
            },
            'recovery': {
                'max_retries': 3,
                'progressive_chunk_reduction': 0.5,
                'fallback_to_sampling': True,
                'emergency_sample_size': 100
            }
        }

    def get_optimal_chunk_size(self, stage_name: str, data_size: int,
                               estimated_time_per_record: float = 2.5) -> int:
        """
        ‚úÖ Calcula tamanho √≥timo de chunk para um stage espec√≠fico

        ALGORITMO:
        1. Verifica configura√ß√£o espec√≠fica do stage
        2. Analisa hist√≥rico de performance
        3. Calcula baseado no timeout target
        4. Aplica limita√ß√µes min/max
        """
        self.logger.info(f"üîß Calculando chunk size √≥timo para {stage_name}")

        # 1. Verificar configura√ß√£o espec√≠fica do stage
        stage_specific = self.config.get('chunk_management', {}).get(
            'stage_specific_chunks', {})
        if stage_name in stage_specific:
            configured_size = stage_specific[stage_name]
            self.logger.info(
                f"üìã Usando chunk size configurado para {stage_name}: {configured_size}")
            return max(self.min_chunk_size, min(configured_size,
                       self.max_chunk_size))

        # 2. Verificar se temos hist√≥rico de performance
        if stage_name in self.optimal_chunk_sizes:
            historical_optimal = self.optimal_chunk_sizes[stage_name]
            self.logger.info(
                f"üìä Usando chunk size hist√≥rico para {stage_name}: "
                f"{historical_optimal}")
            return historical_optimal

        # 3. Calcular baseado no tempo target
        target_time = self.config.get('chunk_management', {}).get(
            'time_per_chunk_target', 60)
        calculated_size = int(target_time / estimated_time_per_record)

        # 4. Aplicar limita√ß√µes
        optimal_size = max(self.min_chunk_size, min(calculated_size,
                           self.max_chunk_size))

        # 5. Ajustar para stages API-intensivos
        api_intensive_stages = [
            '05_political_analysis', '08_sentiment_analysis',
            '12_hashtag_normalization', '13_domain_analysis',
            '14_temporal_analysis', '15_network_analysis',
            '16_qualitative_analysis', '17_smart_pipeline_review',
            '18_topic_interpretation'
        ]

        if stage_name in api_intensive_stages:
            optimal_size = max(2, int(optimal_size * 0.5))
            self.logger.info(
                f"‚ö° Reduzindo chunk size para stage API-intensivo "
                f"{stage_name}: {optimal_size}")

        self.logger.info(
            f"‚úÖ Chunk size √≥timo calculado para {stage_name}: {optimal_size}")
        return optimal_size

    def create_adaptive_chunks(self, data: pd.DataFrame, stage_name: str,
                               estimated_time_per_record: float = 2.5
                               ) -> List[pd.DataFrame]:
        """
        ‚úÖ Cria chunks adaptativos para processamento eficiente

        OTIMIZA√á√ïES:
        - Chunk size baseado em performance hist√≥rica
        - Balanceamento de carga entre chunks
        - Tratamento especial para stages problem√°ticos
        """
        data_size = len(data)
        optimal_chunk_size = self.get_optimal_chunk_size(
            stage_name, data_size, estimated_time_per_record)

        self.logger.info(f"üì¶ Criando chunks adaptativos para {stage_name}")
        self.logger.info(
            f"üìä Dataset: {data_size} registros | Chunk size: "
            f"{optimal_chunk_size}")

        # Criar chunks
        chunks = []
        for i in range(0, data_size, optimal_chunk_size):
            chunk = data.iloc[i:i + optimal_chunk_size].copy()
            chunks.append(chunk)

        self.logger.info(f"‚úÖ Criados {len(chunks)} chunks para processamento")
        return chunks

    def process_with_adaptive_chunking(
            self, data: pd.DataFrame, stage_name: str,
            processing_function, *args, **kwargs) -> pd.DataFrame:
        """
        ‚úÖ Processa dados com chunking adaptativo e recovery autom√°tico

        FEATURES:
        - ‚úÖ Timeout handling autom√°tico
        - ‚úÖ Retry com chunk size reduzido
        - ‚úÖ Fallback para sampling em emerg√™ncia
        - ‚úÖ Monitoramento de performance
        """
        self.logger.info(f"üöÄ Iniciando processamento adaptativo para {stage_name}")

        # Obter timeout para o stage
        stage_timeout = self._get_stage_timeout(stage_name)
        self.logger.info(f"‚è±Ô∏è Timeout configurado para {stage_name}: {stage_timeout}s")

        results = []
        chunks = self.create_adaptive_chunks(data, stage_name)

        for i, chunk in enumerate(chunks):
            chunk_start_time = time.time()
            success = False
            retry_count = 0
            max_retries = self.config.get('recovery', {}).get('max_retries', 3)

            current_chunk = chunk.copy()

            while retry_count <= max_retries and not success:
                try:
                    self.logger.info(f"üìù Processando chunk {i+1}/{len(chunks)} (tentativa {retry_count+1})")

                    # Processar chunk com timeout
                    chunk_result = self._process_chunk_with_timeout(
                        current_chunk, processing_function, stage_timeout, *args, **kwargs
                    )

                    results.append(chunk_result)
                    success = True

                    # Registrar m√©tricas de sucesso
                    processing_time = time.time() - chunk_start_time
                    metrics = ChunkPerformanceMetrics(
                        stage_name=stage_name,
                        chunk_size=len(current_chunk),
                        processing_time=processing_time,
                        success=True,
                        records_processed=len(current_chunk),
                        timeout_occurred=False,
                        retry_count=retry_count
                    )
                    self._record_performance(metrics)

                    self.logger.info(f"‚úÖ Chunk {i+1} processado com sucesso em {processing_time:.2f}s")

                except TimeoutError:
                    retry_count += 1
                    self.logger.warning(f"‚ö†Ô∏è Timeout no chunk {i+1}, tentativa {retry_count}")

                    if retry_count <= max_retries:
                        # Reduzir tamanho do chunk
                        reduction_factor = self.config.get('recovery', {}).get('progressive_chunk_reduction', 0.5)
                        new_size = max(1, int(len(current_chunk) * reduction_factor))
                        current_chunk = current_chunk.head(new_size)
                        self.logger.info(f"üîÑ Reduzindo chunk para {new_size} registros")

                except Exception as e:
                    retry_count += 1
                    self.logger.error(f"‚ùå Erro no chunk {i+1}: {e}")

                    if retry_count > max_retries:
                        # Emergency fallback - usar apenas uma amostra muito pequena
                        emergency_size = self.config.get('recovery', {}).get('emergency_sample_size', 10)
                        emergency_sample = current_chunk.head(min(emergency_size, len(current_chunk)))

                        try:
                            self.logger.warning(f"üö® Usando amostra de emerg√™ncia: {len(emergency_sample)} registros")
                            emergency_result = processing_function(emergency_sample, *args, **kwargs)
                            results.append(emergency_result)
                            success = True
                        except Exception as emergency_error:
                            self.logger.error(f"üí• Falha cr√≠tica no chunk {i+1}: {emergency_error}")
                            # Continuar com pr√≥ximo chunk
                            break

            if not success:
                self.logger.error(f"üí• Falha total no processamento do chunk {i+1}")

        # Consolidar resultados
        if results:
            final_result = pd.concat(results, ignore_index=True)
            self.logger.info(f"‚úÖ Processamento adaptativo conclu√≠do: {len(final_result)} registros")
            return final_result
        else:
            self.logger.error("üí• Nenhum resultado foi processado com sucesso")
            return pd.DataFrame()

    def _get_stage_timeout(self, stage_name: str) -> int:
        """Obt√©m timeout configurado para o stage"""
        # Primeiro tentar timeout espec√≠fico
        stage_timeouts = self.timeout_config.get('stage_specific_timeouts', {})
        if stage_name in stage_timeouts:
            return stage_timeouts[stage_name]

        # Fallback para timeout padr√£o
        return self.timeout_config.get('default_timeout', 300)

    def _process_chunk_with_timeout(self, chunk: pd.DataFrame, processing_function,
                                   timeout: int, *args, **kwargs) -> pd.DataFrame:
        """Processa chunk com timeout usando ThreadPoolExecutor"""
        with ThreadPoolExecutor(max_workers=1) as executor:
            future = executor.submit(processing_function, chunk, *args, **kwargs)

            try:
                result = future.result(timeout=timeout)
                return result
            except TimeoutError:
                future.cancel()
                raise TimeoutError(f"Processamento excedeu timeout de {timeout}s")

    def _record_performance(self, metrics: ChunkPerformanceMetrics):
        """Registra m√©tricas de performance para otimiza√ß√£o futura"""
        with self.lock:
            if metrics.stage_name not in self.performance_history:
                self.performance_history[metrics.stage_name] = []

            self.performance_history[metrics.stage_name].append(metrics)

            # Manter apenas os √∫ltimos 50 registros por stage
            if len(self.performance_history[metrics.stage_name]) > 50:
                self.performance_history[metrics.stage_name] = \
                    self.performance_history[metrics.stage_name][-50:]

            # Recalcular chunk size √≥timo baseado no hist√≥rico
            self._update_optimal_chunk_size(metrics.stage_name)

    def _update_optimal_chunk_size(self, stage_name: str):
        """Atualiza chunk size √≥timo baseado no hist√≥rico de performance"""
        history = self.performance_history.get(stage_name, [])
        if len(history) < 3:  # Precisa de pelo menos 3 amostras
            return

        # Calcular chunk size √≥timo baseado em sucessos recentes
        successful_metrics = [m for m in history[-10:] if m.success and not m.timeout_occurred]

        if successful_metrics:
            # M√©dia ponderada priorizando chunks maiores que foram bem-sucedidos
            total_weight = 0
            weighted_sum = 0

            for metrics in successful_metrics:
                # Peso baseado no tamanho do chunk e velocidade
                speed = metrics.records_processed / max(metrics.processing_time, 0.1)
                weight = speed * metrics.chunk_size

                weighted_sum += metrics.chunk_size * weight
                total_weight += weight

            if total_weight > 0:
                optimal_size = int(weighted_sum / total_weight)
                optimal_size = max(self.min_chunk_size, min(optimal_size, self.max_chunk_size))

                self.optimal_chunk_sizes[stage_name] = optimal_size
                self.logger.debug(f"üìà Chunk size √≥timo atualizado para {stage_name}: {optimal_size}")

    def get_performance_summary(self) -> Dict[str, Any]:
        """Retorna resumo de performance do chunking adaptativo"""
        summary = {
            "total_stages_processed": len(self.performance_history),
            "optimal_chunk_sizes": self.optimal_chunk_sizes.copy(),
            "stage_performance": {}
        }

        for stage_name, history in self.performance_history.items():
            recent_history = history[-10:]  # √öltimos 10 processamentos

            total_processed = sum(m.records_processed for m in recent_history)
            successful_count = sum(1 for m in recent_history if m.success)
            timeout_count = sum(1 for m in recent_history if m.timeout_occurred)
            avg_time = sum(m.processing_time for m in recent_history) / len(recent_history)

            summary["stage_performance"][stage_name] = {
                "total_records_processed": total_processed,
                "success_rate": successful_count / len(recent_history) * 100,
                "timeout_rate": timeout_count / len(recent_history) * 100,
                "average_processing_time": avg_time,
                "current_optimal_chunk_size": self.optimal_chunk_sizes.get(stage_name, "not_calculated")
            }

        return summary

    def reset_performance_history(self, stage_name: Optional[str] = None):
        """Reset hist√≥rico de performance (√∫til para debugging)"""
        with self.lock:
            if stage_name:
                if stage_name in self.performance_history:
                    del self.performance_history[stage_name]
                if stage_name in self.optimal_chunk_sizes:
                    del self.optimal_chunk_sizes[stage_name]
                self.logger.info(f"üîÑ Hist√≥rico de performance resetado para {stage_name}")
            else:
                self.performance_history.clear()
                self.optimal_chunk_sizes.clear()
                self.logger.info("üîÑ Todo hist√≥rico de performance resetado")


# Inst√¢ncia global para uso no pipeline
adaptive_chunking_manager = None


def get_adaptive_chunking_manager() -> AdaptiveChunkingManager:
    """Factory function para obter inst√¢ncia do manager"""
    global adaptive_chunking_manager
    if adaptive_chunking_manager is None:
        adaptive_chunking_manager = AdaptiveChunkingManager()
    return adaptive_chunking_manager


# Decorator para aplicar chunking adaptativo automaticamente
def with_adaptive_chunking(stage_name: str,
                          estimated_time_per_record: float = 2.5):
    """
    Decorator para aplicar chunking adaptativo automaticamente a fun√ß√µes
    de processamento

    Usage:
        @with_adaptive_chunking("08_sentiment_analysis",
                               estimated_time_per_record=3.0)
        def process_sentiment(df):
            # Sua fun√ß√£o de processamento aqui
            return processed_df
    """
    def decorator(func):
        def wrapper(df: pd.DataFrame, *args, **kwargs):
            manager = get_adaptive_chunking_manager()
            return manager.process_with_adaptive_chunking(
                df, stage_name, func, *args, **kwargs
            )
        return wrapper
    return decorator
