"""
Data Analysis Dashboard - Digital Discourse Monitor v5.0.0
============================================================

Dashboard exclusively focused on presenting RESULTS of data analyses
generated by pipeline stages. Presents insights, visualizations
and discoveries about Brazilian political discourse in Telegram data.

üéØ FOCUS: Analysis of processed data and generated insights
üìä OBJECTIVE: Visualize results of political content analyses
üîç SCOPE: Analytical dashboards, not pipeline monitoring
"""

import json
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import streamlit as st
from pathlib import Path
from typing import Dict, List, Any, Optional
import numpy as np
from datetime import datetime
from plotly.subplots import make_subplots

# GUARDRAILS: Sistema de valida√ß√£o de conte√∫do
from dashboard_guardrails import dashboard_guardrail, require_real_data_only, validate_dashboard_data

# Stage 04 Duplication Statistics
from stage04_duplication_stats_dashboard import Stage04DuplicationStatsView

# Page configuration
st.set_page_config(
    page_title="Political Analysis - Brazil Telegram",
    page_icon="üèõÔ∏è",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for data analysis
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #2E4057;
        text-align: center;
        margin-bottom: 2rem;
    }
    
    .insight-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 1.5rem;
        border-radius: 10px;
        margin: 1rem 0;
    }
    
    .metric-highlight {
        background-color: #f8f9fa;
        border-left: 4px solid #007bff;
        padding: 1rem;
        margin: 0.5rem 0;
    }
    
    .category-political {
        background-color: #e3f2fd;
        border-left: 4px solid #1976d2;
    }
    
    .category-sentiment {
        background-color: #f3e5f5;
        border-left: 4px solid #7b1fa2;
    }
    
    .category-discourse {
        background-color: #e8f5e8;
        border-left: 4px solid #388e3c;
    }
</style>
""", unsafe_allow_html=True)

class DataAnalysisDashboard:
    """Dashboard principal para an√°lise dos dados processados"""
    
    def __init__(self):
        """Inicializa o dashboard"""
        self.project_root = Path(__file__).parent.parent.parent
        
        # Caminhos para dados processados (legacy)
        self.data_path = self.project_root / "data/interim/sample_dataset_v495_19_pipeline_validated.csv"
        self.validation_report_path = self.project_root / "logs/pipeline/validation_report_20250611_150026.json"

        # Novos caminhos para dados do pipeline consolidado
        self.pipeline_outputs_path = self.project_root / "pipeline_outputs" / "dashboard_ready"
        self.dashboard_results_path = self.project_root / "src" / "dashboard" / "data" / "dashboard_results"

        # Caminhos para dados antes/depois da limpeza
        self.data_original_path = self.project_root / "data/interim/sample_dataset_v495_01_chunked.csv"
        self.data_deduplicated_path = self.project_root / "data/interim/sample_dataset_v495_03_deduplicated.csv"
        self.pre_cleaning_stats_path = self.project_root / "data/interim/sample_dataset_v495_01_chunked_02_encoding_validated_03_deduplicated_04_feature_validated_04b_pre_cleaning_stats.json"
        self.post_cleaning_stats_path = self.project_root / "data/interim/sample_dataset_v495_01_chunked_02_encoding_validated_03_deduplicated_04_feature_validated_05_political_analyzed_06_text_cleaned_06b_post_cleaning_stats.json"

        # Carregar dados (priorizar dados novos do pipeline)
        latest_df = self._load_latest_pipeline_data()
        if latest_df is not None and not latest_df.empty:
            self.df = latest_df
        else:
            self.df = self._load_dataset()
        self.validation_data = self._load_validation_report()
        self.pipeline_results = self._load_pipeline_results()

        # Carregar dados antes/depois para compara√ß√£o
        self.df_original = self._load_dataset_from_path(self.data_original_path)
        self.df_deduplicated = self._load_dataset_from_path(self.data_deduplicated_path)
        self.pre_cleaning_stats = self._load_json_file(self.pre_cleaning_stats_path)
        self.post_cleaning_stats = self._load_json_file(self.post_cleaning_stats_path)
    
    def _load_dataset(self) -> Optional[pd.DataFrame]:
        """Carrega o dataset processado"""
        try:
            if self.data_path.exists():
                df = pd.read_csv(self.data_path, sep=';', quoting=1)
                # Converter datetime
                df['datetime'] = pd.to_datetime(df['datetime'])
                return df
            return None
        except Exception as e:
            st.error(f"Erro carregando dataset: {e}")
            return None
    
    def _load_validation_report(self) -> Optional[Dict]:
        """Carrega o relat√≥rio de valida√ß√£o"""
        try:
            if self.validation_report_path.exists():
                with open(self.validation_report_path, 'r') as f:
                    return json.load(f)
            return None
        except Exception as e:
            st.error(f"Erro carregando relat√≥rio: {e}")
            return None
    
    def _load_dataset_from_path(self, path: Path) -> Optional[pd.DataFrame]:
        """Carrega dataset de um caminho espec√≠fico"""
        try:
            if path.exists():
                df = pd.read_csv(path, sep=';', quoting=1)
                if 'datetime' in df.columns:
                    df['datetime'] = pd.to_datetime(df['datetime'])
                return df
            return None
        except Exception as e:
            st.error(f"Erro carregando dataset {path.name}: {e}")
            return None
    
    def _load_json_file(self, path: Path) -> Optional[Dict]:
        """Carrega arquivo JSON"""
        try:
            if path.exists():
                with open(path, 'r') as f:
                    return json.load(f)
            return None
        except Exception as e:
            st.error(f"Erro carregando arquivo JSON {path.name}: {e}")
            return None

    def _load_latest_pipeline_data(self) -> Optional[pd.DataFrame]:
        """Carrega os dados mais recentes do pipeline consolidado"""
        try:
            # Verificar se h√° dados novos do pipeline
            if self.pipeline_outputs_path.exists():
                csv_files = list(self.pipeline_outputs_path.glob('*.csv'))
                if csv_files:
                    # Pegar o arquivo mais recente
                    latest_file = max(csv_files, key=lambda x: x.stat().st_mtime)
                    st.info(f"üìä Carregando dados do pipeline: {latest_file.name}")

                    # Tentar diferentes separadores
                    for sep in [';', ',', '\t']:
                        try:
                            df = pd.read_csv(latest_file, sep=sep, encoding='utf-8')
                            if len(df.columns) > 1:
                                if 'datetime' in df.columns:
                                    df['datetime'] = pd.to_datetime(df['datetime'], errors='coerce')
                                return df
                        except:
                            continue
            return None
        except Exception as e:
            st.warning(f"Erro carregando dados do pipeline: {e}")
            return None

    def _load_pipeline_results(self) -> Optional[Dict]:
        """Carrega resultados JSON do pipeline"""
        try:
            if self.dashboard_results_path.exists():
                json_files = list(self.dashboard_results_path.glob('*.json'))
                if json_files:
                    # Pegar o arquivo mais recente
                    latest_file = max(json_files, key=lambda x: x.stat().st_mtime)
                    with open(latest_file, 'r', encoding='utf-8') as f:
                        return json.load(f)
            return None
        except Exception as e:
            st.warning(f"Erro carregando resultados do pipeline: {e}")
            return None
    
    def run(self):
        """Executa o dashboard principal"""
        self._render_header()
        self._render_navigation()
        
        if self.df is None:
            self._render_no_data_page()
            return
        
        # Menu de navega√ß√£o
        page = st.session_state.get('current_page', 'overview')
        
        if page == 'overview':
            self._render_overview_page()
        elif page == 'political_analysis':
            self._render_political_analysis_page()
        elif page == 'duplication_stats':
            self._render_duplication_stats_page()
        elif page == 'sentiment_analysis':
            self._render_sentiment_analysis_page()
        elif page == 'discourse_analysis':
            self._render_discourse_analysis_page()
        elif page == 'temporal_analysis':
            self._render_temporal_analysis_page()
        elif page == 'linguistic_analysis':
            self._render_linguistic_analysis_page()
        elif page == 'clustering_analysis':
            self._render_clustering_analysis_page()
        elif page == 'network_analysis':
            self._render_network_analysis_page()
        elif page == 'comparative_analysis':
            self._render_comparative_analysis_page()
    
    def _render_header(self):
        """Renderiza o cabe√ßalho"""
        st.markdown('<div class="main-header">üèõÔ∏è An√°lise do Discurso Pol√≠tico Brasileiro</div>', unsafe_allow_html=True)
        st.markdown("### üìä Pipeline Consolidado v5.0.0 - Telegram (2019-2023)")

        # Verificar fonte dos dados
        data_source_info = self._get_data_source_info()
        if data_source_info['is_new_pipeline']:
            st.success(f"‚úÖ **Dados do Pipeline Consolidado**: {data_source_info['source_file']} | ‚è±Ô∏è Atualizado: {data_source_info['last_updated']}")
        else:
            st.info("üìö **Dados Legacy**: Execute `python run_pipeline.py` para gerar dados atualizados")

        # M√©tricas comparativas principais
        if self.df is not None:
            col1, col2, col3, col4 = st.columns(4)

            with col1:
                total_records = len(self.df)
                st.metric("üìä Total de Registros", f"{total_records:,}")

            with col2:
                if 'political_category' in self.df.columns:
                    political_categories = self.df['political_category'].nunique()
                    st.metric("üèõÔ∏è Categorias Pol√≠ticas", f"{political_categories}")
                else:
                    st.metric("üèõÔ∏è Categorias Pol√≠ticas", "N/A")

            with col3:
                if 'cluster_name' in self.df.columns:
                    clusters = self.df['cluster_name'].nunique()
                    st.metric("üîç Clusters Sem√¢nticos", f"{clusters}")
                else:
                    st.metric("üîç Clusters Sem√¢nticos", "N/A")

            with col4:
                # N√∫mero de colunas como proxy para est√°gios executados
                analysis_columns = [col for col in self.df.columns if any(keyword in col.lower() for keyword in ['political', 'sentiment', 'topic', 'cluster', 'discourse'])]
                st.metric("‚öôÔ∏è An√°lises Executadas", f"{len(analysis_columns)}")

        st.markdown("---")

    def _get_data_source_info(self) -> Dict[str, Any]:
        """Obt√©m informa√ß√µes sobre a fonte dos dados"""
        info = {
            'is_new_pipeline': False,
            'source_file': 'Legacy data',
            'last_updated': 'Unknown'
        }

        try:
            # Verificar se os dados vieram do pipeline novo
            if self.pipeline_outputs_path.exists():
                csv_files = list(self.pipeline_outputs_path.glob('*.csv'))
                if csv_files:
                    latest_file = max(csv_files, key=lambda x: x.stat().st_mtime)
                    info['is_new_pipeline'] = True
                    info['source_file'] = latest_file.name
                    info['last_updated'] = datetime.fromtimestamp(latest_file.stat().st_mtime).strftime('%Y-%m-%d %H:%M:%S')

        except Exception:
            pass

        return info
    
    def _render_navigation(self):
        """Renderiza a navega√ß√£o lateral"""
        with st.sidebar:
            st.header("üß≠ Navega√ß√£o")
            
            pages = {
                'overview': 'üìã Vis√£o Geral',
                'political_analysis': 'üèõÔ∏è An√°lise Pol√≠tica',
                'duplication_stats': 'üìä Estat√≠sticas de Duplica√ß√£o',
                'sentiment_analysis': 'üòä An√°lise de Sentimento',
                'discourse_analysis': 'üí¨ An√°lise do Discurso',
                'temporal_analysis': 'üìÖ An√°lise Temporal',
                'linguistic_analysis': 'üî§ An√°lise Lingu√≠stica',
                'clustering_analysis': 'üîç An√°lise de Agrupamentos',
                'network_analysis': 'üåê An√°lise de Redes',
                'comparative_analysis': '‚öñÔ∏è An√°lise Comparativa'
            }
            
            for page_key, page_name in pages.items():
                if st.button(page_name, key=f"nav_{page_key}", use_container_width=True):
                    st.session_state.current_page = page_key
                    st.rerun()
            
            # Informa√ß√µes do dataset
            if self.df is not None:
                st.markdown("---")
                st.subheader("üìä Estat√≠sticas")
                st.write(f"**Registros:** {len(self.df):,}")
                st.write(f"**Colunas:** {len(self.df.columns)}")
                
                # Top categorias pol√≠ticas
                if 'political_category' in self.df.columns:
                    top_categories = self.df['political_category'].value_counts().head(3)
                    st.write("**Top Categorias:**")
                    for cat, count in top_categories.items():
                        st.write(f"‚Ä¢ {cat}: {count}")
    
    def _render_no_data_page(self):
        """P√°gina quando n√£o h√° dados"""
        st.error("üìä Nenhum dado dispon√≠vel para an√°lise")
        st.markdown("""
        ### Como gerar dados para an√°lise:
        
        1. **Execute o pipeline completo:**
        ```bash
        poetry run python run_pipeline.py
        ```
        
        2. **Ou execute stages espec√≠ficos:**
        ```bash
        poetry run python src/main.py
        ```
        
        3. **Aguarde o processamento** dos 20 stages do pipeline
        
        4. **Retorne ao dashboard** para visualizar as an√°lises
        """)
    
    def _render_overview_page(self):
        """P√°gina de vis√£o geral com compara√ß√£o antes/depois da limpeza"""
        st.header("üìã An√°lise Comparativa: Antes vs Depois da Limpeza de Dados")
        
        # Se√ß√£o 1: Compara√ß√£o de Volume de Mensagens
        st.subheader("üìä 1. Volume de Mensagens: Original vs Deduplicated")
        
        if self.df_original is not None and self.df_deduplicated is not None:
            col1, col2, col3 = st.columns(3)
            
            original_count = len(self.df_original)
            deduplicated_count = len(self.df_deduplicated)
            reduction_percentage = ((original_count - deduplicated_count) / original_count) * 100 if original_count > 0 else 0
            
            with col1:
                st.metric("üì• Mensagens Originais", f"{original_count:,}")
            
            with col2:
                st.metric("üßπ Ap√≥s Deduplica√ß√£o", f"{deduplicated_count:,}")
            
            with col3:
                st.metric("üìâ Redu√ß√£o", f"{reduction_percentage:.1f}%", f"-{original_count - deduplicated_count:,}")
            
            # Gr√°fico de compara√ß√£o
            comparison_data = {
                'Etapa': ['Original', 'Deduplicated'],
                'Mensagens': [original_count, deduplicated_count],
                'Cor': ['#ff7f7f', '#7fbf7f']
            }
            
            fig_volume = px.bar(
                comparison_data,
                x='Etapa',
                y='Mensagens',
                title="Compara√ß√£o do Volume de Mensagens",
                color='Etapa',
                color_discrete_map={'Original': '#ff7f7f', 'Deduplicated': '#7fbf7f'}
            )
            st.plotly_chart(fig_volume, use_container_width=True)
        
        # Se√ß√£o 2: Top 10 Hashtags - Antes vs Depois
        st.subheader("üè∑Ô∏è 2. Top 10 Hashtags: Antes vs Depois")
        self._render_hashtags_comparison()
        
        # Se√ß√£o 3: Top 10 Men√ß√µes - Antes vs Depois  
        st.subheader("üë• 3. Top 10 Men√ß√µes: Antes vs Depois")
        self._render_mentions_comparison()
        
        # Se√ß√£o 4: Top 10 Dom√≠nios - Antes vs Depois
        st.subheader("üåê 4. Top 10 Dom√≠nios: Antes vs Depois")
        self._render_domains_comparison()
        
        # Se√ß√£o 5: Resumo das Transforma√ß√µes
        st.subheader("üîÑ 5. Resumo das Transforma√ß√µes do Pipeline")
        self._render_transformation_summary()
    
    def _generate_main_insights(self) -> List[str]:
        """Gera insights principais dos dados"""
        insights = []
        
        if 'political_category' in self.df.columns:
            top_category = self.df['political_category'].value_counts().index[0]
            top_percentage = (self.df['political_category'].value_counts().iloc[0] / len(self.df)) * 100
            insights.append(f"üèõÔ∏è **Categoria pol√≠tica dominante:** {top_category} ({top_percentage:.1f}% das mensagens)")
        
        if 'sentiment' in self.df.columns:
            sentiment_counts = self.df['sentiment'].value_counts()
            dominant_sentiment = sentiment_counts.index[0]
            sentiment_percentage = (sentiment_counts.iloc[0] / len(self.df)) * 100
            insights.append(f"üòä **Sentimento predominante:** {dominant_sentiment} ({sentiment_percentage:.1f}% das mensagens)")
        
        if 'discourse_type' in self.df.columns:
            discourse_counts = self.df['discourse_type'].value_counts()
            main_discourse = discourse_counts.index[0]
            discourse_percentage = (discourse_counts.iloc[0] / len(self.df)) * 100
            insights.append(f"üí¨ **Tipo de discurso principal:** {main_discourse} ({discourse_percentage:.1f}% das mensagens)")
        
        if 'text_length' in self.df.columns:
            avg_length = self.df['text_length'].mean()
            insights.append(f"üìù **Comprimento m√©dio das mensagens:** {avg_length:.0f} caracteres")
        
        if 'cluster_name' in self.df.columns:
            unique_clusters = self.df['cluster_name'].nunique()
            insights.append(f"üîç **Grupos tem√°ticos identificados:** {unique_clusters} clusters sem√¢nticos distintos")
        
        return insights
    
    def _render_hashtags_comparison(self):
        """Compara√ß√£o de hashtags antes vs depois"""
        try:
            col1, col2 = st.columns(2)
            
            with col1:
                st.write("**üè∑Ô∏è Antes da Limpeza (Dados Originais)**")
                
                if self.pre_cleaning_stats and 'hashtag_analysis' in self.pre_cleaning_stats:
                    top_hashtags_before = self.pre_cleaning_stats['hashtag_analysis'].get('top_hashtags', {})
                    
                    if top_hashtags_before:
                        hashtags_df_before = pd.DataFrame([
                            {'Hashtag': k, 'Frequ√™ncia': v} 
                            for k, v in list(top_hashtags_before.items())[:10]
                        ])
                        
                        fig_before = px.bar(
                            hashtags_df_before,
                            y='Hashtag',
                            x='Frequ√™ncia',
                            orientation='h',
                            title="Top 10 Hashtags - Dados Originais",
                            color_discrete_sequence=['#ff7f7f']
                        )
                        st.plotly_chart(fig_before, use_container_width=True)
                    else:
                        st.info("Dados de hashtags originais n√£o dispon√≠veis")
                else:
                    st.info("Estat√≠sticas de pr√©-limpeza n√£o dispon√≠veis")
            
            with col2:
                st.write("**üßπ Depois da Limpeza (Dados Processados)**")
                
                if self.df is not None and 'hashtag' in self.df.columns:
                    # Extrair hashtags dos dados processados
                    hashtags_after = []
                    for hashtag_field in self.df['hashtag'].dropna():
                        if hashtag_field and hashtag_field.strip():
                            hashtags_after.extend([h.strip() for h in str(hashtag_field).split(',') if h.strip()])
                    
                    if hashtags_after:
                        hashtag_counts_after = pd.Series(hashtags_after).value_counts().head(10)
                        
                        hashtags_df_after = pd.DataFrame({
                            'Hashtag': hashtag_counts_after.index,
                            'Frequ√™ncia': hashtag_counts_after.values
                        })
                        
                        fig_after = px.bar(
                            hashtags_df_after,
                            y='Hashtag',
                            x='Frequ√™ncia',
                            orientation='h',
                            title="Top 10 Hashtags - Dados Processados",
                            color_discrete_sequence=['#7fbf7f']
                        )
                        st.plotly_chart(fig_after, use_container_width=True)
                    else:
                        st.info("Nenhuma hashtag encontrada nos dados processados")
                else:
                    st.info("Coluna de hashtags n√£o dispon√≠vel nos dados processados")
                    
        except Exception as e:
            st.error(f"Erro na compara√ß√£o de hashtags: {e}")
    
    def _render_mentions_comparison(self):
        """Compara√ß√£o de men√ß√µes antes vs depois"""
        try:
            col1, col2 = st.columns(2)
            
            with col1:
                st.write("**üë• Antes da Limpeza (Dados Originais)**")
                
                if self.df_original is not None and 'mentions' in self.df_original.columns:
                    mentions_before = []
                    for mention_field in self.df_original['mentions'].dropna():
                        if mention_field and mention_field.strip():
                            mentions_before.extend([m.strip() for m in str(mention_field).split(',') if m.strip()])
                    
                    if mentions_before:
                        mention_counts_before = pd.Series(mentions_before).value_counts().head(10)
                        
                        mentions_df_before = pd.DataFrame({
                            'Men√ß√£o': mention_counts_before.index,
                            'Frequ√™ncia': mention_counts_before.values
                        })
                        
                        fig_before = px.bar(
                            mentions_df_before,
                            y='Men√ß√£o',
                            x='Frequ√™ncia', 
                            orientation='h',
                            title="Top 10 Men√ß√µes - Dados Originais",
                            color_discrete_sequence=['#ff7f7f']
                        )
                        st.plotly_chart(fig_before, use_container_width=True)
                    else:
                        st.info("Nenhuma men√ß√£o encontrada nos dados originais")
                else:
                    st.info("Dados originais n√£o dispon√≠veis")
            
            with col2:
                st.write("**üßπ Depois da Limpeza (Dados Processados)**")
                
                if self.df is not None and 'mentions' in self.df.columns:
                    mentions_after = []
                    for mention_field in self.df['mentions'].dropna():
                        if mention_field and mention_field.strip():
                            mentions_after.extend([m.strip() for m in str(mention_field).split(',') if m.strip()])
                    
                    if mentions_after:
                        mention_counts_after = pd.Series(mentions_after).value_counts().head(10)
                        
                        mentions_df_after = pd.DataFrame({
                            'Men√ß√£o': mention_counts_after.index,
                            'Frequ√™ncia': mention_counts_after.values
                        })
                        
                        fig_after = px.bar(
                            mentions_df_after,
                            y='Men√ß√£o',
                            x='Frequ√™ncia',
                            orientation='h',
                            title="Top 10 Men√ß√µes - Dados Processados",
                            color_discrete_sequence=['#7fbf7f']
                        )
                        st.plotly_chart(fig_after, use_container_width=True)
                    else:
                        st.info("Nenhuma men√ß√£o encontrada nos dados processados")
                else:
                    st.info("Coluna de men√ß√µes n√£o dispon√≠vel nos dados processados")
                    
        except Exception as e:
            st.error(f"Erro na compara√ß√£o de men√ß√µes: {e}")
    
    def _render_domains_comparison(self):
        """Compara√ß√£o de dom√≠nios antes vs depois"""
        try:
            col1, col2 = st.columns(2)
            
            with col1:
                st.write("**üåê Antes da Limpeza (Dados Originais)**")
                
                if self.pre_cleaning_stats and 'url_analysis' in self.pre_cleaning_stats:
                    top_domains_before = self.pre_cleaning_stats['url_analysis'].get('top_domains', {})
                    
                    if top_domains_before:
                        domains_df_before = pd.DataFrame([
                            {'Dom√≠nio': k, 'Frequ√™ncia': v} 
                            for k, v in list(top_domains_before.items())[:10]
                        ])
                        
                        fig_before = px.bar(
                            domains_df_before,
                            y='Dom√≠nio',
                            x='Frequ√™ncia',
                            orientation='h',
                            title="Top 10 Dom√≠nios - Dados Originais",
                            color_discrete_sequence=['#ff7f7f']
                        )
                        st.plotly_chart(fig_before, use_container_width=True)
                    else:
                        st.info("Dados de dom√≠nios originais n√£o dispon√≠veis")
                else:
                    st.info("Estat√≠sticas de URL originais n√£o dispon√≠veis")
            
            with col2:
                st.write("**üßπ Depois da Limpeza (Dados Processados)**")
                
                if self.df is not None and 'domain' in self.df.columns:
                    domain_counts_after = self.df['domain'].value_counts().head(10)
                    
                    if len(domain_counts_after) > 0:
                        domains_df_after = pd.DataFrame({
                            'Dom√≠nio': domain_counts_after.index,
                            'Frequ√™ncia': domain_counts_after.values
                        })
                        
                        fig_after = px.bar(
                            domains_df_after,
                            y='Dom√≠nio',
                            x='Frequ√™ncia',
                            orientation='h',
                            title="Top 10 Dom√≠nios - Dados Processados",
                            color_discrete_sequence=['#7fbf7f']
                        )
                        st.plotly_chart(fig_after, use_container_width=True)
                    else:
                        st.info("Nenhum dom√≠nio encontrado nos dados processados")
                else:
                    st.info("Coluna de dom√≠nios n√£o dispon√≠vel nos dados processados")
                    
        except Exception as e:
            st.error(f"Erro na compara√ß√£o de dom√≠nios: {e}")
    
    def _render_transformation_summary(self):
        """Resumo das transforma√ß√µes aplicadas pelo pipeline"""
        try:
            st.write("### üìù Principais Transforma√ß√µes Aplicadas:")
            
            transformations = [
                "üîç **Stage 01-02**: Valida√ß√£o de encoding e estrutura dos dados",
                "üßπ **Stage 03**: Deduplica√ß√£o inteligente com m√∫ltiplas estrat√©gias",
                "üìä **Stage 04**: Valida√ß√£o e enriquecimento de features b√°sicas",
                "üèõÔ∏è **Stage 05**: An√°lise pol√≠tica com classifica√ß√£o autom√°tica via IA",
                "‚ú® **Stage 06**: Limpeza inteligente de texto preservando contexto",
                "üî§ **Stage 07**: Processamento lingu√≠stico avan√ßado com spaCy",
                "üòä **Stage 08**: An√°lise de sentimento contextualizada",
                "üéØ **Stage 09-11**: Modelagem de t√≥picos e clustering sem√¢ntico",
                "üè∑Ô∏è **Stage 12**: Normaliza√ß√£o de hashtags pol√≠ticas",
                "üåê **Stage 13-15**: An√°lise de dom√≠nios, temporal e redes sociais",
                "üî¨ **Stage 16-20**: An√°lise qualitativa e valida√ß√£o final do pipeline"
            ]
            
            for transformation in transformations:
                st.markdown(transformation)
            
            # Estat√≠sticas finais de transforma√ß√£o
            if self.pre_cleaning_stats and self.post_cleaning_stats:
                st.write("### üìà Estat√≠sticas de Transforma√ß√£o:")
                
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    pre_chars = self.pre_cleaning_stats.get('text_statistics', {}).get('total_characters', 0)
                    post_chars = self.post_cleaning_stats.get('text_statistics', {}).get('total_characters', 0)
                    char_reduction = ((int(pre_chars) - int(post_chars)) / int(pre_chars)) * 100 if int(pre_chars) > 0 else 0
                    st.metric("Redu√ß√£o de Caracteres", f"{char_reduction:.1f}%")
                
                with col2:
                    pre_words = self.pre_cleaning_stats.get('text_statistics', {}).get('total_words', 0)
                    post_words = self.post_cleaning_stats.get('text_statistics', {}).get('total_words', 0)
                    word_reduction = ((int(pre_words) - int(post_words)) / int(pre_words)) * 100 if int(pre_words) > 0 else 0
                    st.metric("Redu√ß√£o de Palavras", f"{word_reduction:.1f}%")
                
                with col3:
                    if self.df is not None:
                        final_columns = len(self.df.columns)
                        original_columns = len(self.df_original.columns) if self.df_original is not None else 0
                        column_increase = final_columns - original_columns
                        st.metric("Colunas Adicionadas", f"+{column_increase}")
                        
        except Exception as e:
            st.error(f"Erro no resumo de transforma√ß√µes: {e}")
    
    def _render_temporal_overview(self):
        """Renderiza overview temporal"""
        if 'datetime' in self.df.columns:
            # Mensagens por m√™s
            df_monthly = self.df.set_index('datetime').resample('M').size().reset_index()
            df_monthly.columns = ['M√™s', 'Mensagens']
            
            fig_temporal = px.line(
                df_monthly,
                x='M√™s',
                y='Mensagens',
                title="Evolu√ß√£o do Volume de Mensagens",
                markers=True
            )
            st.plotly_chart(fig_temporal, use_container_width=True)
    
    def _render_political_analysis_page(self):
        """üèõÔ∏è An√°lise Pol√≠tica Hier√°rquica Completa - 4 N√≠veis"""
        st.header("üèõÔ∏è An√°lise Pol√≠tica Hier√°rquica - Taxonomia Brasileira (4 N√≠veis)")
        
        # Verificar disponibilidade de dados pol√≠ticos
        political_columns = ['political_category', 'political_alignment', 'discourse_type', 'radicalization_level']
        available_columns = [col for col in political_columns if col in self.df.columns]
        
        if not available_columns:
            st.warning("‚ö†Ô∏è Dados de an√°lise pol√≠tica n√£o dispon√≠veis")
            return
        
        st.info(f"üìä **Dataset:** {len(self.df):,} mensagens analisadas com taxonomia pol√≠tica hier√°rquica")
        
        # ============================
        # SE√á√ÉO 1: VIS√ÉO GERAL HIER√ÅRQUICA
        # ============================
        st.subheader("üìã 1. Vis√£o Geral da Taxonomia Pol√≠tica Hier√°rquica")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            if 'political_alignment' in self.df.columns:
                alignment_counts = self.df['political_alignment'].value_counts()
                dominant_alignment = alignment_counts.index[0]
                alignment_pct = (alignment_counts.iloc[0] / len(self.df)) * 100
                st.metric(
                    "üéØ N√≠vel 2: Alinhamento Dominante", 
                    dominant_alignment.title(), 
                    f"{alignment_pct:.1f}%"
                )
        
        with col2:
            if 'political_category' in self.df.columns:
                category_counts = self.df['political_category'].value_counts()
                dominant_category = category_counts.index[0]
                category_pct = (category_counts.iloc[0] / len(self.df)) * 100
                st.metric(
                    "üè∑Ô∏è Categoria Dominante", 
                    dominant_category.title(), 
                    f"{category_pct:.1f}%"
                )
        
        with col3:
            if 'discourse_type' in self.df.columns:
                discourse_counts = self.df['discourse_type'].value_counts()
                dominant_discourse = discourse_counts.index[0]
                discourse_pct = (discourse_counts.iloc[0] / len(self.df)) * 100
                st.metric(
                    "üí¨ Tipo de Discurso Principal", 
                    dominant_discourse.title(), 
                    f"{discourse_pct:.1f}%"
                )
        
        with col4:
            if 'radicalization_level' in self.df.columns:
                radical_counts = self.df['radicalization_level'].value_counts()
                radical_high_pct = (radical_counts.get('alto', 0) / len(self.df)) * 100
                st.metric(
                    "üî• Taxa de Radicaliza√ß√£o Alta", 
                    f"{radical_high_pct:.1f}%", 
                    f"{radical_counts.get('alto', 0)} mensagens"
                )
        
        # ============================
        # SE√á√ÉO 2: DISTRIBUI√á√ïES POR N√çVEL HIER√ÅRQUICO
        # ============================
        st.subheader("üìä 2. Distribui√ß√µes por N√≠vel Hier√°rquico")
        
        # N√≠vel 2: Alinhamento Pol√≠tico
        if 'political_alignment' in self.df.columns:
            col1, col2 = st.columns(2)
            
            with col1:
                st.write("**üéØ N√≠vel 2: Alinhamento Pol√≠tico**")
                alignment_counts = self.df['political_alignment'].value_counts()
                
                # Mapear cores espec√≠ficas para alinhamentos pol√≠ticos
                color_map_alignment = {
                    'direita': '#FF6B6B',      # Vermelho suave
                    'esquerda': '#4ECDC4',     # Verde azulado
                    'neutro': '#95A5A6',       # Cinza
                    'indefinido': '#F39C12'    # Laranja
                }
                
                colors_alignment = [color_map_alignment.get(align, '#95A5A6') for align in alignment_counts.index]
                
                fig_alignment = px.pie(
                    values=alignment_counts.values,
                    names=alignment_counts.index,
                    title="Distribui√ß√£o do Alinhamento Pol√≠tico",
                    color_discrete_sequence=colors_alignment,
                    hole=0.3
                )
                fig_alignment.update_traces(textinfo='percent+label', textfont_size=12)
                st.plotly_chart(fig_alignment, use_container_width=True)
            
            with col2:
                st.write("**üè∑Ô∏è Categoria Pol√≠tica Espec√≠fica**")
                if 'political_category' in self.df.columns:
                    category_counts = self.df['political_category'].value_counts()
                    
                    # Cores para categorias pol√≠ticas
                    color_map_category = {
                        'bolsonarista': '#E74C3C',    # Vermelho forte
                        'petista': '#E67E22',         # Laranja forte
                        'geral': '#3498DB',           # Azul
                        'neutro': '#95A5A6'           # Cinza
                    }
                    
                    colors_category = [color_map_category.get(cat, '#95A5A6') for cat in category_counts.index]
                    
                    fig_category = px.bar(
                        y=category_counts.index,
                        x=category_counts.values,
                        orientation='h',
                        title="Mensagens por Categoria Pol√≠tica",
                        color=category_counts.index,
                        color_discrete_sequence=colors_category
                    )
                    fig_category.update_layout(height=400, showlegend=False)
                    st.plotly_chart(fig_category, use_container_width=True)
        
        # N√≠vel 3: Tipo de Discurso e Radicaliza√ß√£o
        col1, col2 = st.columns(2)
        
        with col1:
            if 'discourse_type' in self.df.columns:
                st.write("**üí¨ N√≠vel 3: Tipo de Discurso**")
                discourse_counts = self.df['discourse_type'].value_counts()
                
                color_map_discourse = {
                    'informativo': '#2ECC71',     # Verde
                    'agressivo': '#E74C3C',       # Vermelho
                    'mobilizador': '#F39C12',     # Laranja
                    'conspirat√≥rio': '#8E44AD'    # Roxo
                }
                
                colors_discourse = [color_map_discourse.get(disc, '#95A5A6') for disc in discourse_counts.index]
                
                fig_discourse = px.pie(
                    values=discourse_counts.values,
                    names=discourse_counts.index,
                    title="Tipos de Discurso Identificados",
                    color_discrete_sequence=colors_discourse,
                    hole=0.3
                )
                st.plotly_chart(fig_discourse, use_container_width=True)
        
        with col2:
            if 'radicalization_level' in self.df.columns:
                st.write("**üî• N√≠vel de Radicaliza√ß√£o**")
                radical_counts = self.df['radicalization_level'].value_counts()
                
                color_map_radical = {
                    'baixo': '#2ECC71',      # Verde
                    'm√©dio': '#F39C12',      # Laranja
                    'alto': '#E74C3C'        # Vermelho
                }
                
                colors_radical = [color_map_radical.get(level, '#95A5A6') for level in radical_counts.index]
                
                fig_radical = px.bar(
                    x=radical_counts.index,
                    y=radical_counts.values,
                    title="Distribui√ß√£o de N√≠veis de Radicaliza√ß√£o",
                    color=radical_counts.index,
                    color_discrete_sequence=colors_radical
                )
                fig_radical.update_layout(showlegend=False)
                st.plotly_chart(fig_radical, use_container_width=True)
        
        # ============================
        # SE√á√ÉO 3: CORRELA√á√ïES ENTRE N√çVEIS HIER√ÅRQUICOS
        # ============================
        st.subheader("üîó 3. Correla√ß√µes entre N√≠veis Hier√°rquicos")
        
        if 'political_alignment' in self.df.columns and 'discourse_type' in self.df.columns:
            # Matriz de correla√ß√£o pol√≠tica √ó discurso
            correlation_table = pd.crosstab(
                self.df['political_alignment'], 
                self.df['discourse_type'],
                normalize='index'
            ) * 100
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.write("**üìä Correla√ß√£o: Alinhamento √ó Tipo de Discurso (%)**")
                
                fig_correlation = px.imshow(
                    correlation_table.values,
                    x=correlation_table.columns,
                    y=correlation_table.index,
                    title="Heatmap: Alinhamento Pol√≠tico √ó Tipo de Discurso",
                    color_continuous_scale="RdYlBu_r",
                    aspect="auto"
                )
                fig_correlation.update_layout(height=400)
                st.plotly_chart(fig_correlation, use_container_width=True)
            
            with col2:
                # Tabela de correla√ß√£o num√©rica
                st.write("**üìã Tabela de Correla√ß√£o (%)**")
                st.dataframe(correlation_table.round(1), use_container_width=True)
                
                # Insights autom√°ticos
                st.write("**üí° Insights Autom√°ticos:**")
                for alignment in correlation_table.index:
                    max_discourse = correlation_table.loc[alignment].idxmax()
                    max_percentage = correlation_table.loc[alignment].max()
                    st.write(f"‚Ä¢ **{alignment.title()}**: {max_percentage:.1f}% ‚Üí {max_discourse}")
        
        # ============================
        # SE√á√ÉO 4: AN√ÅLISE TEMPORAL HIER√ÅRQUICA
        # ============================
        st.subheader("üìÖ 4. Evolu√ß√£o Temporal das Categorias Pol√≠ticas")
        self._render_political_temporal_hierarchy()
        
        # ============================
        # SE√á√ÉO 5: T√ìPICOS E AGRUPAMENTOS ESPEC√çFICOS (N√çVEL 4)
        # ============================
        self._render_level4_analysis()
        
        # ============================
        # SE√á√ÉO 6: AN√ÅLISE COMPARATIVA AVAN√áADA
        # ============================
        self._render_advanced_political_comparison()
    
    def _render_political_temporal_hierarchy(self):
        """An√°lise temporal hier√°rquica das categorias pol√≠ticas"""
        
        if 'datetime' not in self.df.columns:
            st.warning("‚ö†Ô∏è Dados temporais n√£o dispon√≠veis para an√°lise hier√°rquica")
            return
        
        df_temp = self.df.copy()
        df_temp['month'] = df_temp['datetime'].dt.to_period('M').astype(str)
        df_temp['year'] = df_temp['datetime'].dt.year
        
        col1, col2 = st.columns(2)
        
        with col1:
            if 'political_alignment' in self.df.columns:
                st.write("**üìä Evolu√ß√£o do Alinhamento Pol√≠tico**")
                monthly_alignment = df_temp.groupby(['month', 'political_alignment']).size().unstack(fill_value=0)
                
                if not monthly_alignment.empty:
                    fig_temporal_alignment = px.area(
                        monthly_alignment,
                        title="Evolu√ß√£o Temporal do Alinhamento Pol√≠tico",
                        labels={'value': 'Mensagens', 'index': 'Per√≠odo'},
                        color_discrete_sequence=['#FF6B6B', '#4ECDC4', '#95A5A6', '#F39C12']
                    )
                    st.plotly_chart(fig_temporal_alignment, use_container_width=True)
        
        with col2:
            if 'discourse_type' in self.df.columns:
                st.write("**üí¨ Evolu√ß√£o do Tipo de Discurso**")
                monthly_discourse = df_temp.groupby(['month', 'discourse_type']).size().unstack(fill_value=0)
                
                if not monthly_discourse.empty:
                    fig_temporal_discourse = px.line(
                        monthly_discourse,
                        title="Evolu√ß√£o Temporal do Tipo de Discurso",
                        labels={'value': 'Mensagens', 'index': 'Per√≠odo'},
                        markers=True
                    )
                    st.plotly_chart(fig_temporal_discourse, use_container_width=True)
        
        # An√°lise anual
        if len(df_temp['year'].unique()) > 1:
            st.write("**üìÖ Distribui√ß√£o Anual por Categoria**")
            try:
                yearly_analysis = df_temp.groupby(['year', 'political_category']).size().unstack(fill_value=0)
                
                if not yearly_analysis.empty:
                    fig_yearly = px.bar(
                        yearly_analysis,
                        title="Distribui√ß√£o Anual das Categorias Pol√≠ticas",
                        labels={'value': 'N√∫mero de Mensagens', 'index': 'Ano'},
                        barmode='stack'
                    )
                    st.plotly_chart(fig_yearly, use_container_width=True)
                else:
                    st.info("‚ÑπÔ∏è Dados insuficientes para an√°lise anual")
            except Exception as e:
                st.warning(f"‚ö†Ô∏è Erro na an√°lise anual: {str(e)}")
                # Fallback: mostrar apenas contagem por ano
                yearly_simple = df_temp['year'].value_counts().sort_index()
                if len(yearly_simple) > 0:
                    fig_yearly_simple = px.bar(
                        x=yearly_simple.index,
                        y=yearly_simple.values,
                        title="Distribui√ß√£o Anual Total de Mensagens",
                        labels={'x': 'Ano', 'y': 'N√∫mero de Mensagens'}
                    )
                    st.plotly_chart(fig_yearly_simple, use_container_width=True)

    def _render_level4_analysis(self):
        """An√°lise do N√≠vel 4: T√≥picos e Agrupamentos Espec√≠ficos"""
        st.subheader("üéØ 5. An√°lise de N√≠vel 4: T√≥picos e Agrupamentos Espec√≠ficos")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # An√°lise de topic_name (N√≠vel 4)
            if 'topic_name' in self.df.columns:
                st.write("**üè∑Ô∏è T√≥picos Espec√≠ficos Identificados**")
                topic_counts = self.df['topic_name'].value_counts()
                
                # Filtrar apenas t√≥picos classificados (n√£o "N√£o Classificado")
                classified_topics = topic_counts[topic_counts.index != 'N√£o Classificado']
                
                if len(classified_topics) > 0:
                    st.write(f"**üìä {len(classified_topics)} t√≥picos espec√≠ficos identificados:**")
                    
                    fig_topics = px.bar(
                        y=classified_topics.index,
                        x=classified_topics.values,
                        orientation='h',
                        title="T√≥picos Pol√≠ticos Espec√≠ficos",
                        color=classified_topics.values,
                        color_continuous_scale="Viridis"
                    )
                    fig_topics.update_layout(height=400, showlegend=False)
                    st.plotly_chart(fig_topics, use_container_width=True)
                    
                    # Tabela detalhada
                    st.write("**üìã Detalhamento dos T√≥picos:**")
                    topics_df = pd.DataFrame({
                        'T√≥pico': classified_topics.index,
                        'Mensagens': classified_topics.values,
                        'Percentual': (classified_topics.values / len(self.df) * 100).round(1)
                    })
                    st.dataframe(topics_df, use_container_width=True)
                else:
                    st.info("‚ÑπÔ∏è Maioria das mensagens n√£o foi classificada em t√≥picos espec√≠ficos")
            else:
                st.info("‚ÑπÔ∏è Dados de t√≥picos espec√≠ficos n√£o dispon√≠veis")
        
        with col2:
            # An√°lise de cluster_name (Agrupamentos Sem√¢nticos)
            if 'cluster_name' in self.df.columns:
                st.write("**üîç Agrupamentos Sem√¢nticos (Clusters)**")
                cluster_counts = self.df['cluster_name'].value_counts()
                
                if len(cluster_counts) > 0:
                    # Gr√°fico de pizza para clusters
                    color_map_clusters = {
                        'Cultura Bolsonarista Digital': '#3498DB',
                        'Narrativa Bolsonarista Antipetista': '#E74C3C',
                        'Mobiliza√ß√£o Conservadora': '#F39C12',
                        'Discurso Institucional': '#2ECC71'
                    }
                    
                    colors_clusters = [color_map_clusters.get(cluster, '#95A5A6') for cluster in cluster_counts.index]
                    
                    fig_clusters = px.pie(
                        values=cluster_counts.values,
                        names=cluster_counts.index,
                        title="Distribui√ß√£o dos Agrupamentos Sem√¢nticos",
                        color_discrete_sequence=colors_clusters,
                        hole=0.3
                    )
                    fig_clusters.update_traces(textinfo='percent+label', textfont_size=10)
                    st.plotly_chart(fig_clusters, use_container_width=True)
                    
                    # Tabela detalhada de clusters
                    st.write("**üìä An√°lise dos Clusters:**")
                    clusters_df = pd.DataFrame({
                        'Cluster': cluster_counts.index,
                        'Mensagens': cluster_counts.values,
                        'Percentual': (cluster_counts.values / len(self.df) * 100).round(1)
                    })
                    st.dataframe(clusters_df, use_container_width=True)
            else:
                st.info("‚ÑπÔ∏è Dados de clustering sem√¢ntico n√£o dispon√≠veis")
        
        # An√°lise de qualidade sem√¢ntica
        if 'semantic_quality' in self.df.columns:
            st.write("**‚≠ê Qualidade Sem√¢ntica dos Agrupamentos**")
            
            col1, col2, col3 = st.columns(3)
            
            quality_scores = pd.to_numeric(self.df['semantic_quality'], errors='coerce').dropna()
            
            if len(quality_scores) > 0:
                with col1:
                    avg_quality = quality_scores.mean()
                    st.metric("Qualidade M√©dia", f"{avg_quality:.3f}")
                
                with col2:
                    high_quality_count = (quality_scores >= 0.7).sum()
                    high_quality_pct = (high_quality_count / len(quality_scores)) * 100
                    st.metric("Alta Qualidade (‚â•0.7)", f"{high_quality_pct:.1f}%")
                
                with col3:
                    max_quality = quality_scores.max()
                    st.metric("Qualidade M√°xima", f"{max_quality:.3f}")

    def _render_advanced_political_comparison(self):
        """An√°lise Comparativa Avan√ßada entre Dimens√µes Pol√≠ticas"""
        st.subheader("üî¨ 6. An√°lise Comparativa Avan√ßada")
        
        # An√°lise multidimensional
        if all(col in self.df.columns for col in ['political_alignment', 'political_category', 'discourse_type']):
            st.write("**üé≠ An√°lise Multidimensional: Alinhamento √ó Categoria √ó Discurso**")
            
            # Criar an√°lise tridimensional
            multi_analysis = self.df.groupby(['political_alignment', 'political_category', 'discourse_type']).size().reset_index(name='count')
            
            if not multi_analysis.empty:
                # Sunburst chart para visualiza√ß√£o hier√°rquica
                fig_sunburst = px.sunburst(
                    multi_analysis,
                    path=['political_alignment', 'political_category', 'discourse_type'],
                    values='count',
                    title="Hierarquia Pol√≠tica: Alinhamento ‚Üí Categoria ‚Üí Discurso",
                    color='count',
                    color_continuous_scale="Viridis"
                )
                st.plotly_chart(fig_sunburst, use_container_width=True)
        
        # Compara√ß√£o de caracter√≠sticas textuais por categoria pol√≠tica
        if all(col in self.df.columns for col in ['political_category', 'text_length', 'word_count']):
            st.write("**üìè Caracter√≠sticas Textuais por Categoria Pol√≠tica**")
            
            col1, col2 = st.columns(2)
            
            with col1:
                # Box plot de comprimento de texto por categoria
                fig_length_box = px.box(
                    self.df,
                    x='political_category',
                    y='text_length',
                    title="Distribui√ß√£o do Comprimento de Texto por Categoria",
                    color='political_category',
                    color_discrete_sequence=['#3498DB', '#E74C3C', '#F39C12']
                )
                st.plotly_chart(fig_length_box, use_container_width=True)
            
            with col2:
                # Estat√≠sticas descritivas
                text_stats = self.df.groupby('political_category')[['text_length', 'word_count']].describe()
                st.write("**üìä Estat√≠sticas Descritivas:**")
                st.dataframe(text_stats.round(1), use_container_width=True)
        
        # An√°lise de densidade de entidades pol√≠ticas
        if all(col in self.df.columns for col in ['political_category', 'political_entity_density']):
            st.write("**üéØ Densidade de Entidades Pol√≠ticas por Categoria**")
            
            entity_density = self.df.groupby('political_category')['political_entity_density'].agg(['mean', 'median', 'std']).round(4)
            
            col1, col2 = st.columns(2)
            
            with col1:
                fig_density = px.bar(
                    x=entity_density.index,
                    y=entity_density['mean'],
                    title="Densidade M√©dia de Entidades Pol√≠ticas",
                    color=entity_density['mean'],
                    color_continuous_scale="Reds"
                )
                st.plotly_chart(fig_density, use_container_width=True)
            
            with col2:
                st.write("**üìã Estat√≠sticas de Densidade:**")
                st.dataframe(entity_density, use_container_width=True)
    
    def _render_political_temporal_analysis(self):
        """An√°lise temporal das categorias pol√≠ticas (compatibilidade)"""
        self._render_political_temporal_hierarchy()
    
    def _render_sentiment_analysis_page(self):
        """An√°lise de sentimento detalhada"""
        st.header("üòä An√°lise de Sentimento Detalhada")
        
        if 'sentiment' not in self.df.columns:
            st.warning("Dados de an√°lise de sentimento n√£o dispon√≠veis")
            return
        
        col1, col2 = st.columns(2)
        
        with col1:
            # Distribui√ß√£o geral de sentimentos
            sentiment_counts = self.df['sentiment'].value_counts()
            
            colors = {
                'positivo': '#2E8B57',
                'neutro': '#4682B4', 
                'negativo': '#DC143C'
            }
            
            sentiment_colors = [colors.get(sent.lower(), '#808080') for sent in sentiment_counts.index]
            
            fig_sentiment = px.bar(
                x=sentiment_counts.index,
                y=sentiment_counts.values,
                title="Distribui√ß√£o Geral de Sentimentos",
                color=sentiment_counts.index,
                color_discrete_map=colors
            )
            st.plotly_chart(fig_sentiment, use_container_width=True)
        
        with col2:
            # Sentimento por score
            if 'sentiment_score' in self.df.columns:
                fig_score = px.histogram(
                    self.df,
                    x='sentiment_score',
                    title="Distribui√ß√£o dos Scores de Sentimento",
                    nbins=20,
                    color_discrete_sequence=['#4CAF50']
                )
                st.plotly_chart(fig_score, use_container_width=True)
        
        # Sentimento por categoria pol√≠tica
        if 'political_category' in self.df.columns:
            st.subheader("üèõÔ∏è Sentimento por Categoria Pol√≠tica")
            
            sentiment_political = pd.crosstab(
                self.df['political_category'], 
                self.df['sentiment'], 
                normalize='index'
            ) * 100
            
            fig_sentiment_political = px.bar(
                sentiment_political,
                title="Distribui√ß√£o de Sentimentos por Categoria Pol√≠tica (%)",
                labels={'value': 'Percentual (%)', 'index': 'Categoria Pol√≠tica'}
            )
            st.plotly_chart(fig_sentiment_political, use_container_width=True)
        
        # Evolu√ß√£o temporal do sentimento
        self._render_sentiment_temporal_analysis()
    
    def _render_sentiment_temporal_analysis(self):
        """An√°lise temporal dos sentimentos"""
        st.subheader("üìà Evolu√ß√£o Temporal dos Sentimentos")
        
        if 'datetime' in self.df.columns:
            df_temp = self.df.copy()
            df_temp['month'] = df_temp['datetime'].dt.to_period('M').astype(str)
            
            monthly_sentiment = df_temp.groupby(['month', 'sentiment']).size().unstack(fill_value=0)
            
            fig_temporal_sentiment = px.area(
                monthly_sentiment,
                title="Evolu√ß√£o dos Sentimentos ao Longo do Tempo",
                labels={'value': 'N√∫mero de Mensagens', 'index': 'Per√≠odo'}
            )
            st.plotly_chart(fig_temporal_sentiment, use_container_width=True)
    
    def _render_discourse_analysis_page(self):
        """An√°lise do tipo de discurso"""
        st.header("üí¨ An√°lise do Discurso")
        
        if 'discourse_type' not in self.df.columns:
            st.warning("Dados de an√°lise de discurso n√£o dispon√≠veis")
            return
        
        # Distribui√ß√£o dos tipos de discurso
        discourse_counts = self.df['discourse_type'].value_counts()
        
        col1, col2 = st.columns(2)
        
        with col1:
            fig_discourse = px.pie(
                values=discourse_counts.values,
                names=discourse_counts.index,
                title="Tipos de Discurso Identificados",
                color_discrete_sequence=px.colors.qualitative.Set2
            )
            st.plotly_chart(fig_discourse, use_container_width=True)
        
        with col2:
            # Comprimento m√©dio por tipo de discurso
            if 'text_length' in self.df.columns:
                avg_length_discourse = self.df.groupby('discourse_type')['text_length'].mean().sort_values(ascending=False)
                
                fig_length_discourse = px.bar(
                    x=avg_length_discourse.values,
                    y=avg_length_discourse.index,
                    orientation='h',
                    title="Comprimento M√©dio por Tipo de Discurso",
                    color=avg_length_discourse.values,
                    color_continuous_scale="Viridis"
                )
                st.plotly_chart(fig_length_discourse, use_container_width=True)
    
    def _render_temporal_analysis_page(self):
        """An√°lise temporal detalhada"""
        st.header("üìÖ An√°lise Temporal Detalhada")
        
        if 'datetime' not in self.df.columns:
            st.warning("Dados temporais n√£o dispon√≠veis")
            return
        
        # Atividade por hora do dia
        col1, col2 = st.columns(2)
        
        with col1:
            df_temp = self.df.copy()
            df_temp['hour'] = df_temp['datetime'].dt.hour
            hourly_activity = df_temp['hour'].value_counts().sort_index()
            
            fig_hourly = px.bar(
                x=hourly_activity.index,
                y=hourly_activity.values,
                title="Atividade por Hora do Dia",
                labels={'x': 'Hora', 'y': 'N√∫mero de Mensagens'}
            )
            st.plotly_chart(fig_hourly, use_container_width=True)
        
        with col2:
            # Atividade por dia da semana
            df_temp['weekday'] = df_temp['datetime'].dt.day_name()
            weekday_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
            weekday_activity = df_temp['weekday'].value_counts().reindex(weekday_order)
            
            fig_weekday = px.bar(
                x=weekday_activity.index,
                y=weekday_activity.values,
                title="Atividade por Dia da Semana",
                labels={'x': 'Dia da Semana', 'y': 'N√∫mero de Mensagens'}
            )
            st.plotly_chart(fig_weekday, use_container_width=True)
    
    def _render_linguistic_analysis_page(self):
        """An√°lise lingu√≠stica dos dados"""
        st.header("üî§ An√°lise Lingu√≠stica")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # Distribui√ß√£o de comprimento de texto
            if 'text_length' in self.df.columns:
                fig_length = px.histogram(
                    self.df,
                    x='text_length',
                    title="Distribui√ß√£o do Comprimento das Mensagens",
                    nbins=30,
                    color_discrete_sequence=['#FF6B6B']
                )
                st.plotly_chart(fig_length, use_container_width=True)
        
        with col2:
            # Distribui√ß√£o de contagem de palavras
            if 'word_count' in self.df.columns:
                fig_words = px.histogram(
                    self.df,
                    x='word_count',
                    title="Distribui√ß√£o do N√∫mero de Palavras",
                    nbins=30,
                    color_discrete_sequence=['#4ECDC4']
                )
                st.plotly_chart(fig_words, use_container_width=True)
        
        # An√°lise de complexidade lingu√≠stica
        if 'spacy_linguistic_complexity' in self.df.columns:
            st.subheader("üß† Complexidade Lingu√≠stica")
            
            complexity_stats = self.df['spacy_linguistic_complexity'].describe()
            
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("M√©dia", f"{complexity_stats['mean']:.3f}")
            with col2:
                st.metric("Mediana", f"{complexity_stats['50%']:.3f}")
            with col3:
                st.metric("M√≠nimo", f"{complexity_stats['min']:.3f}")
            with col4:
                st.metric("M√°ximo", f"{complexity_stats['max']:.3f}")
    
    def _render_clustering_analysis_page(self):
        """An√°lise de agrupamentos sem√¢nticos"""
        st.header("üîç An√°lise de Agrupamentos Sem√¢nticos")
        
        if 'cluster_name' not in self.df.columns:
            st.warning("Dados de clustering n√£o dispon√≠veis")
            return
        
        # Distribui√ß√£o dos clusters
        cluster_counts = self.df['cluster_name'].value_counts()
        
        fig_clusters = px.bar(
            x=cluster_counts.values,
            y=cluster_counts.index,
            orientation='h',
            title="Distribui√ß√£o de Mensagens por Cluster Sem√¢ntico",
            color=cluster_counts.values,
            color_continuous_scale="Plasma"
        )
        fig_clusters.update_layout(height=500)
        st.plotly_chart(fig_clusters, use_container_width=True)
        
        # An√°lise de qualidade sem√¢ntica
        if 'semantic_quality' in self.df.columns:
            st.subheader("üéØ Qualidade Sem√¢ntica")
            
            avg_quality = self.df['semantic_quality'].mean()
            quality_dist = self.df['semantic_quality'].value_counts().sort_index()
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.metric("Qualidade Sem√¢ntica M√©dia", f"{avg_quality:.3f}")
                
                fig_quality = px.histogram(
                    self.df,
                    x='semantic_quality',
                    title="Distribui√ß√£o da Qualidade Sem√¢ntica",
                    nbins=20
                )
                st.plotly_chart(fig_quality, use_container_width=True)
    
    def _render_network_analysis_page(self):
        """An√°lise de redes e intera√ß√µes"""
        st.header("üåê An√°lise de Redes e Intera√ß√µes")
        
        # An√°lise de men√ß√µes
        if 'mentions' in self.df.columns:
            mentions_data = self.df[self.df['mentions'].notna() & (self.df['mentions'] != '')]
            
            if len(mentions_data) > 0:
                st.subheader("üì¢ An√°lise de Men√ß√µes")
                st.metric("Mensagens com Men√ß√µes", f"{len(mentions_data):,}")
                percentage_mentions = (len(mentions_data) / len(self.df)) * 100
                st.metric("Percentual com Men√ß√µes", f"{percentage_mentions:.1f}%")
        
        # An√°lise de hashtags
        if 'hashtag' in self.df.columns:
            hashtag_data = self.df[self.df['hashtag'].notna() & (self.df['hashtag'] != '')]
            
            if len(hashtag_data) > 0:
                st.subheader("# An√°lise de Hashtags")
                st.metric("Mensagens com Hashtags", f"{len(hashtag_data):,}")
                percentage_hashtags = (len(hashtag_data) / len(self.df)) * 100
                st.metric("Percentual com Hashtags", f"{percentage_hashtags:.1f}%")
        
        # An√°lise de URLs
        if 'url' in self.df.columns:
            url_data = self.df[self.df['url'].notna() & (self.df['url'] != '')]
            
            if len(url_data) > 0:
                st.subheader("üîó An√°lise de URLs")
                st.metric("Mensagens com URLs", f"{len(url_data):,}")
                percentage_urls = (len(url_data) / len(self.df)) * 100
                st.metric("Percentual com URLs", f"{percentage_urls:.1f}%")
    
    def _render_comparative_analysis_page(self):
        """An√°lise comparativa entre diferentes dimens√µes"""
        st.header("‚öñÔ∏è An√°lise Comparativa")
        
        # Compara√ß√£o entre categorias pol√≠ticas e sentimentos
        if 'political_category' in self.df.columns and 'sentiment' in self.df.columns:
            st.subheader("üèõÔ∏è vs üòä Pol√≠tica √ó Sentimento")
            
            comparison_table = pd.crosstab(
                self.df['political_category'], 
                self.df['sentiment'],
                normalize='index'
            ) * 100
            
            fig_comparison = px.imshow(
                comparison_table.values,
                x=comparison_table.columns,
                y=comparison_table.index,
                title="Heatmap: Sentimento por Categoria Pol√≠tica (%)",
                aspect="auto",
                color_continuous_scale="RdYlBu_r"
            )
            st.plotly_chart(fig_comparison, use_container_width=True)
        
        # Compara√ß√£o temporal
        st.subheader("üìä Estat√≠sticas Comparativas")
        
        if 'text_length' in self.df.columns and 'political_category' in self.df.columns:
            length_by_category = self.df.groupby('political_category')['text_length'].agg(['mean', 'median', 'std'])
            st.dataframe(length_by_category, use_container_width=True)

    def _render_duplication_stats_page(self):
        """Render Stage 04 duplication statistics analysis"""
        try:
            duplication_dashboard = Stage04DuplicationStatsView()
            duplication_dashboard.render_dashboard()
        except Exception as e:
            st.error(f"Erro ao carregar an√°lise de duplica√ß√£o: {e}")
            st.markdown("""
            ### An√°lise de Padr√µes de Duplica√ß√£o n√£o dispon√≠vel

            Esta p√°gina apresenta estat√≠sticas detalhadas dos padr√µes de duplica√ß√£o identificados no Stage 04 do pipeline.

            **Recursos inclusos:**
            - üìä Distribui√ß√£o de frequ√™ncia de duplicatas
            - üîÑ An√°lise de ocorr√™ncias repetidas
            - üîó Estat√≠sticas de sobreposi√ß√£o entre datasets
            - üìà Resumo estat√≠stico consolidado

            Execute o pipeline completo para gerar os dados necess√°rios.
            """)

def main():
    """Fun√ß√£o principal"""
    dashboard = DataAnalysisDashboard()
    dashboard.run()

if __name__ == "__main__":
    main()