"""
digiNEV Research Dashboard Application: Comprehensive visualization system for Brazilian political discourse analysis
Function: Interactive Streamlit dashboard with real-time monitoring, quality control, and research-focused data visualization
Usage: Social scientists explore analysis results through web interface - displays political patterns, sentiment trends, and violence indicators
"""

import json
import logging
import os
import sys
import time
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any, Dict, List, Optional

import numpy as np
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import streamlit as st
from plotly.subplots import make_subplots

# Page configuration
st.set_page_config(
    page_title="Digital Discourse Monitor v5.0.0",
    page_icon="üéØ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Add src to path
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root / 'src'))

# Import custom modules
try:
    from dashboard.pipeline_monitor import PipelineMonitor, StageStatus
    from dashboard.pipeline_visualizations import PipelineVisualizations
    from dashboard.quality_control_charts import QualityControlCharts
    CUSTOM_MODULES_AVAILABLE = True
except ImportError as e:
    CUSTOM_MODULES_AVAILABLE = False
    st.error(f"Error importing custom modules: {e}")

# Custom CSS
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }

    .stage-card {
        background-color: #f8f9fa;
        border-radius: 10px;
        padding: 1rem;
        margin: 0.5rem 0;
        border-left: 4px solid #1f77b4;
    }

    .status-completed {
        border-left-color: #28a745 !important;
    }

    .status-running {
        border-left-color: #ffc107 !important;
    }

    .status-failed {
        border-left-color: #dc3545 !important;
    }

    .status-pending {
        border-left-color: #6c757d !important;
    }

    .metric-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 1.5rem;
        border-radius: 10px;
        text-align: center;
    }

    .metric-value {
        font-size: 2rem;
        font-weight: bold;
        margin: 0.5rem 0;
    }

    .metric-label {
        font-size: 0.9rem;
        opacity: 0.8;
    }

    .sidebar-section {
        background-color: #f1f3f4;
        border-radius: 8px;
        padding: 1rem;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

class PipelineDashboardNew:
    """Dashboard principal integrado v4.9.1"""

    def __init__(self):
        """Inicializa o dashboard"""
        self.project_root = project_root

        if CUSTOM_MODULES_AVAILABLE:
            self.monitor = PipelineMonitor(self.project_root)
            self.visualizations = PipelineVisualizations(self.monitor)
            self.quality_control = QualityControlCharts(self.project_root)
        else:
            self.monitor = None
            self.visualizations = None
            self.quality_control = None

        # Inicializar estado da sess√£o
        if 'last_refresh' not in st.session_state:
            st.session_state.last_refresh = datetime.now()
        if 'auto_refresh' not in st.session_state:
            st.session_state.auto_refresh = True
        if 'refresh_interval' not in st.session_state:
            st.session_state.refresh_interval = 30  # segundos

    def run(self):
        """Executa o dashboard principal"""
        self._render_header()
        self._render_sidebar()

        if not CUSTOM_MODULES_AVAILABLE:
            self._render_error_page()
            return

        # Load pipeline data
        self.monitor.load_current_session()

        # Main menu
        main_tab = st.session_state.get('main_tab', 'overview')

        if main_tab == 'overview':
            self._render_overview_page()
        elif main_tab == 'pipeline_monitor':
            self._render_pipeline_monitor_page()
        elif main_tab == 'stage_details':
            self._render_stage_details_page()
        elif main_tab == 'stages_17_20':
            self._render_stages_17_20_page()
        elif main_tab == 'quality_control':
            self._render_quality_control_page()
        elif main_tab == 'performance_analysis':
            self._render_performance_analysis_page()
        elif main_tab == 'api_cost_analysis':
            self._render_api_cost_analysis_page()
        elif main_tab == 'system_health':
            self._render_system_health_page()

        # Auto-refresh
        self._handle_auto_refresh()

    def _render_header(self):
        """Renderiza o cabe√ßalho principal"""
        st.markdown('<div class="main-header">üéØ Monitor do Discurso Digital v5.0.0</div>', unsafe_allow_html=True)
        st.markdown("---")

        # Status bar
        col1, col2, col3, col4 = st.columns(4)

        with col1:
            st.markdown("**üìä Sistema:** Pipeline An√°lise Pol√≠tica")
        with col2:
            st.markdown(f"**‚è∞ √öltima Atualiza√ß√£o:** {st.session_state.last_refresh.strftime('%H:%M:%S')}")
        with col3:
            if CUSTOM_MODULES_AVAILABLE:
                st.markdown("**üü¢ Status:** Sistemas Operacionais")
            else:
                st.markdown("**üî¥ Status:** Erro nos M√≥dulos")
        with col4:
            st.markdown("**üîÑ Auto-refresh:** " + ("Ativo" if st.session_state.auto_refresh else "Inativo"))

    def _render_sidebar(self):
        """Renderiza a barra lateral com navega√ß√£o"""
        with st.sidebar:
            st.markdown("## üß≠ Navega√ß√£o")

            # Menu principal
            st.markdown('<div class="sidebar-section">', unsafe_allow_html=True)

            tabs = {
                'overview': 'üìã Vis√£o Geral',
                'pipeline_monitor': 'üîÑ Monitor do Pipeline',
                'stage_details': 'üîç Detalhes das Etapas',
                'stages_17_20': 'üéØ Stages Finais (17-20)',
                'quality_control': 'üìä Controle de Qualidade',
                'performance_analysis': '‚ö° An√°lise de Performance',
                'api_cost_analysis': 'üí∞ An√°lise de Custos API',
                'system_health': 'üè• Sa√∫de do Sistema'
            }

            for tab_key, tab_name in tabs.items():
                if st.button(tab_name, key=f"btn_{tab_key}", use_container_width=True):
                    st.session_state.main_tab = tab_key
                    st.rerun()

            st.markdown('</div>', unsafe_allow_html=True)

            # Configura√ß√µes de refresh
            st.markdown("## ‚öôÔ∏è Configura√ß√µes")
            st.markdown('<div class="sidebar-section">', unsafe_allow_html=True)

            st.session_state.auto_refresh = st.checkbox("Auto-refresh", value=st.session_state.auto_refresh)

            if st.session_state.auto_refresh:
                st.session_state.refresh_interval = st.selectbox(
                    "Intervalo (segundos)",
                    [10, 30, 60, 120, 300],
                    index=1
                )

            if st.button("üîÑ Atualizar Agora", use_container_width=True):
                st.session_state.last_refresh = datetime.now()
                st.rerun()

            st.markdown('</div>', unsafe_allow_html=True)

            # Informa√ß√µes do sistema
            if CUSTOM_MODULES_AVAILABLE and self.monitor:
                st.markdown("## üìà Status R√°pido")
                st.markdown('<div class="sidebar-section">', unsafe_allow_html=True)

                overview = self.monitor.get_pipeline_overview()

                st.metric("Progresso", f"{overview['overall_progress']:.0%}")
                st.metric("Etapas Conclu√≠das", f"{overview['completed_stages']}/{overview['total_stages']}")

                if overview['running_stages'] > 0:
                    st.metric("Em Execu√ß√£o", overview['running_stages'])
                if overview['failed_stages'] > 0:
                    st.metric("Falhas", overview['failed_stages'])

                st.markdown('</div>', unsafe_allow_html=True)

    def _render_error_page(self):
        """Renderiza p√°gina de erro quando m√≥dulos n√£o est√£o dispon√≠veis"""
        st.error("üö® Erro: M√≥dulos customizados n√£o dispon√≠veis")
        st.markdown("""
        ### Poss√≠veis Solu√ß√µes:
        1. Verifique se os arquivos est√£o no local correto:
           - `src/dashboard/pipeline_monitor.py`
           - `src/dashboard/pipeline_visualizations.py`
           - `src/dashboard/quality_control_charts.py`

        2. Execute o pipeline principal para gerar dados:
           ```bash
           python run_pipeline.py
           ```

        3. Reinicie o dashboard:
           ```bash
           python src/dashboard/start_dashboard.py
           ```
        """)

    def _render_overview_page(self):
        """Renderiza a p√°gina de vis√£o geral"""
        st.header("üìã Vis√£o Geral do Pipeline")

        # M√©tricas principais simplificadas
        try:
            overview = self.monitor.get_pipeline_overview()
            
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("Progresso Geral", f"{overview['overall_progress']:.0%}")
            
            with col2:
                st.metric("Etapas Conclu√≠das", f"{overview['completed_stages']}/{overview['total_stages']}")
            
            with col3:
                st.metric("Total de Registros", f"{overview['total_records']:,}")
            
            with col4:
                if overview['running_stages'] > 0:
                    st.metric("Em Execu√ß√£o", overview['running_stages'])
                elif overview['failed_stages'] > 0:
                    st.metric("Falharam", overview['failed_stages'])
                else:
                    st.metric("Status", "OK")
                    
        except Exception as e:
            st.error(f"Erro carregando overview: {e}")
            st.info("üí° Execute o pipeline para gerar dados de monitoramento.")

        st.markdown("---")

        # Timeline das etapas simplificada
        st.subheader("‚è±Ô∏è Status das Etapas")
        timeline_data = self.monitor.get_timeline_data()

        if timeline_data:
            # Criar DataFrame para exibi√ß√£o simples
            df_timeline = pd.DataFrame([
                {
                    'ID': stage['stage_id'],
                    'Nome': stage['name'],
                    'Categoria': stage['category'],
                    'Status': stage['status'],
                    'Cr√≠tica': 'üî¥' if stage.get('critical', False) else 'üü°',
                    'Dura√ß√£o (s)': stage.get('duration', 0)
                }
                for stage in timeline_data
            ])

            st.dataframe(df_timeline, use_container_width=True)

        else:
            st.info("‚ÑπÔ∏è Nenhum dado de timeline dispon√≠vel. Execute o pipeline para gerar dados.")

    def _render_pipeline_monitor_page(self):
        """Renderiza a p√°gina de monitoramento do pipeline"""
        st.header("üîÑ Monitor do Pipeline em Tempo Real")

        try:
            overview = self.monitor.get_pipeline_overview()

            # Alertas de status
            if overview['failed_stages'] > 0:
                st.error(f"üö® {overview['failed_stages']} etapa(s) falharam! Verifique os logs.")
            elif overview['running_stages'] > 0:
                st.info(f"üîÑ {overview['running_stages']} etapa(s) em execu√ß√£o...")
            elif overview['overall_progress'] == 1.0:
                st.success("Pipeline conclu√≠do com sucesso!")

            # M√©tricas simples
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("Tempo Estimado Total", f"{overview.get('estimated_total_time', 0)} min")
            
            with col2:
                st.metric("Tempo Decorrido", f"{overview.get('elapsed_time', 0)} min")
            
            with col3:
                st.metric("Tempo Restante", f"{overview.get('estimated_remaining_time', 0)} min")

            # Etapa atual
            current_stage = overview.get('current_stage')
            next_stage = overview.get('next_stage')

            if current_stage:
                st.subheader("üîÑ Etapa Atual")
                stage_details = self.monitor.get_stage_details(current_stage)
                st.info(f"**{stage_details['name']}** - {stage_details['description']}")

            if next_stage:
                st.subheader("‚è≠Ô∏è Pr√≥xima Etapa")
                next_details = self.monitor.get_stage_details(next_stage)
                st.info(f"**{next_details['name']}** - {next_details['description']}")

        except Exception as e:
            st.error(f"Erro no monitoramento: {e}")
            st.info("üí° Execute o pipeline para gerar dados de monitoramento.")

    def _render_stage_details_page(self):
        """Renderiza a p√°gina de detalhes das etapas"""
        st.header("üîç Detalhes das Etapas")

        try:
            # Seletor de etapa
            timeline_data = self.monitor.get_timeline_data()
            if timeline_data:
                stage_options = {stage['stage_id']: f"{stage['stage_id']}: {stage['name']}"
                                for stage in timeline_data}

                selected_stage = st.selectbox(
                    "Selecionar Etapa:",
                    options=list(stage_options.keys()),
                    format_func=lambda x: stage_options[x]
                )

                if selected_stage:
                    # Detalhes da etapa selecionada
                    stage_details = self.monitor.get_stage_details(selected_stage)
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.subheader("üìã Informa√ß√µes B√°sicas")
                        st.write(f"**Nome:** {stage_details['name']}")
                        st.write(f"**Categoria:** {stage_details['category']}")
                        st.write(f"**Status:** {stage_details['status']}")
                        st.write(f"**Cr√≠tica:** {'Sim' if stage_details.get('critical', False) else 'N√£o'}")
                    
                    with col2:
                        st.subheader("üìä M√©tricas")
                        st.write(f"**Dura√ß√£o:** {stage_details.get('duration', 0)} segundos")
                        st.write(f"**Tempo Esperado:** {stage_details.get('expected_duration', 0)} segundos")
                        st.write(f"**Registros Processados:** {stage_details.get('records_processed', 0)}")
                        st.write(f"**Taxa de Sucesso:** {stage_details.get('success_rate', 0):.1%}")
                    
                    st.markdown("---")
                    st.subheader("üìù Descri√ß√£o")
                    st.write(stage_details.get('description', 'Sem descri√ß√£o dispon√≠vel'))
            else:
                st.info("‚ÑπÔ∏è Nenhum dado de etapas dispon√≠vel. Execute o pipeline para gerar dados.")
                
        except Exception as e:
            st.error(f"Erro carregando detalhes das etapas: {e}")
            st.info("üí° Execute o pipeline para gerar dados de monitoramento.")

    def _render_stages_17_20_page(self):
        """Renderiza a p√°gina espec√≠fica dos stages 17-20"""
        st.header("üéØ Stages Finais (17-20) - Pipeline Enhanced v4.9.7")
        
        # Carregar dados dos stages finais
        try:
            # Dados do validation report
            validation_report_path = self.monitor.project_root / "logs/pipeline/validation_report_20250611_150026.json"
            validation_data = None
            if validation_report_path.exists():
                with open(validation_report_path, 'r') as f:
                    validation_data = json.load(f)
            
            # Dados do dataset final
            final_dataset_path = self.monitor.project_root / "data/interim/sample_dataset_v495_19_pipeline_validated.csv"
            dataset_df = None
            if final_dataset_path.exists():
                dataset_df = pd.read_csv(final_dataset_path, sep=';', quoting=1, on_bad_lines='warn', nrows=100)
            
            # Dados de custos API
            costs_path = self.monitor.project_root / "logs/anthropic_costs.json"
            costs_data = None
            if costs_path.exists():
                with open(costs_path, 'r') as f:
                    costs_data = json.load(f)
            
            # Resumo dos stages 17-20
            st.subheader("üìä Resumo dos Stages Finais")
            
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric(
                    "Stage 17: Pipeline Review",
                    "Conclu√≠do",
                    "An√°lise de qualidade"
                )
            
            with col2:
                st.metric(
                    "Stage 18: Topic Interpretation", 
                    "Conclu√≠do",
                    "13 lotes processados"
                )
            
            with col3:
                st.metric(
                    "Stage 19: Semantic Search",
                    "Conclu√≠do", 
                    "222 docs indexados"
                )
                
            with col4:
                st.metric(
                    "Stage 20: Pipeline Validation",
                    "Conclu√≠do",
                    "Valida√ß√£o final"
                )
            
            # Visualiza√ß√£o de custos dos stages 17-20
            if costs_data:
                st.subheader("üí∞ An√°lise de Custos (Stages 17-20)")
                
                # Extrair custos por stage
                stages_17_20_costs = {}
                for session in costs_data.get('sessions', []):
                    for operation in session.get('operations', []):
                        stage = operation.get('stage', 'unknown')
                        if any(s in stage for s in ['13_', 'pipeline_validation', '05_topic_modeling']):
                            if stage not in stages_17_20_costs:
                                stages_17_20_costs[stage] = 0
                            stages_17_20_costs[stage] += operation.get('total_cost', 0)
                
                if stages_17_20_costs:
                    fig_costs = go.Figure()
                    fig_costs.add_trace(go.Bar(
                        x=list(stages_17_20_costs.keys()),
                        y=list(stages_17_20_costs.values()),
                        marker_color='lightblue'
                    ))
                    fig_costs.update_layout(
                        title="Custos por Stage (17-20)",
                        xaxis_title="Stage",
                        yaxis_title="Custo (USD)",
                        height=400
                    )
                    st.plotly_chart(fig_costs, use_container_width=True)
                
                # M√©tricas de custo total
                total_cost = costs_data.get('total_cost', 0)
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.metric("Custo Total Pipeline", f"${total_cost:.3f}")
                
                with col2:
                    stages_17_20_total = sum(stages_17_20_costs.values())
                    st.metric("Custo Stages 17-20", f"${stages_17_20_total:.3f}")
                
                with col3:
                    if total_cost > 0:
                        percentage = (stages_17_20_total / total_cost) * 100
                        st.metric("% do Total", f"{percentage:.1f}%")
            
            # An√°lise de qualidade do dataset final
            if dataset_df is not None:
                st.subheader("üìã An√°lise do Dataset Final")
                
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.metric("Total de Registros", len(dataset_df))
                
                with col2:
                    st.metric("Total de Colunas", len(dataset_df.columns))
                
                with col3:
                    validated_count = len(dataset_df[dataset_df['pipeline_validated'] == True])
                    st.metric("Registros Validados", validated_count)
                
                # Distribui√ß√£o de categorias pol√≠ticas
                if 'political_category' in dataset_df.columns:
                    st.subheader("üèõÔ∏è Distribui√ß√£o de Categorias Pol√≠ticas")
                    political_dist = dataset_df['political_category'].value_counts()
                    
                    fig_political = go.Figure()
                    fig_political.add_trace(go.Pie(
                        labels=political_dist.index,
                        values=political_dist.values,
                        hole=0.3
                    ))
                    fig_political.update_layout(
                        title="Distribui√ß√£o de Categorias Pol√≠ticas",
                        height=400
                    )
                    st.plotly_chart(fig_political, use_container_width=True)
                
                # An√°lise de clustering
                if 'cluster_name' in dataset_df.columns:
                    st.subheader("üîç An√°lise de Clustering (Stage 11)")
                    cluster_dist = dataset_df['cluster_name'].value_counts()
                    
                    fig_cluster = go.Figure()
                    fig_cluster.add_trace(go.Bar(
                        x=cluster_dist.index,
                        y=cluster_dist.values,
                        marker_color='lightgreen'
                    ))
                    fig_cluster.update_layout(
                        title="Distribui√ß√£o de Clusters Sem√¢nticos",
                        xaxis_title="Cluster",
                        yaxis_title="N√∫mero de Mensagens",
                        height=400
                    )
                    st.plotly_chart(fig_cluster, use_container_width=True)
            
            # Relat√≥rio de valida√ß√£o (Stage 20)
            if validation_data:
                st.subheader("üìã Relat√≥rio de Valida√ß√£o Final (Stage 20)")
                
                overall_assessment = validation_data.get('overall_assessment', {})
                
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    quality_score = overall_assessment.get('overall_score', 0)
                    st.metric("Score de Qualidade", f"{quality_score:.3f}")
                
                with col2:
                    quality_level = overall_assessment.get('quality_level', 'desconhecido')
                    st.metric("N√≠vel de Qualidade", quality_level.title())
                
                with col3:
                    ready_for_analysis = overall_assessment.get('ready_for_analysis', False)
                    status = "Pronto" if ready_for_analysis else "‚ö†Ô∏è Revisar"
                    st.metric("Status para An√°lise", status)
                
                # Issues identificadas
                api_intelligence = validation_data.get('api_intelligence', {})
                critical_issues = api_intelligence.get('critical_issues_identified', [])
                
                if critical_issues:
                    st.subheader("‚ö†Ô∏è Issues Cr√≠ticas Identificadas")
                    for issue in critical_issues:
                        st.warning(f"‚Ä¢ {issue}")
                
                # Recomenda√ß√µes estrat√©gicas
                strategic_recommendations = api_intelligence.get('strategic_recommendations', [])
                if strategic_recommendations:
                    st.subheader("üí° Recomenda√ß√µes Estrat√©gicas")
                    for rec in strategic_recommendations:
                        priority = rec.get('priority', 'media')
                        icon = "üî¥" if priority == 'alta' else "üü°" if priority == 'media' else "üü¢"
                        st.info(f"{icon} **{rec.get('recommendation', '')}** (Prioridade: {priority})")
            
            # Timeline dos stages 17-20
            st.subheader("üìÖ Timeline de Execu√ß√£o")
            
            stages_info = [
                {"stage": "Stage 17", "name": "Smart Pipeline Review", "status": "Conclu√≠do", "time": "~5 min"},
                {"stage": "Stage 18", "name": "Topic Interpretation", "status": "Conclu√≠do", "time": "~3 min"}, 
                {"stage": "Stage 19", "name": "Semantic Search", "status": "Conclu√≠do", "time": "~12 min"},
                {"stage": "Stage 20", "name": "Pipeline Validation", "status": "Conclu√≠do", "time": "~11 min"}
            ]
            
            for stage_info in stages_info:
                with st.expander(f"{stage_info['stage']}: {stage_info['name']} - {stage_info['status']}"):
                    st.write(f"**Tempo de execu√ß√£o:** {stage_info['time']}")
                    st.write(f"**Status:** {stage_info['status']}")
            
        except Exception as e:
            st.error(f"Erro ao carregar dados dos stages 17-20: {str(e)}")
            st.info("üí° Verifique se o pipeline foi executado e os arquivos de dados est√£o dispon√≠veis.")

    def _render_quality_control_page(self):
        """Renderiza a p√°gina de controle de qualidade"""
        st.header("üìä Controle de Qualidade")

        try:
            if self.quality_control:
                st.info("üîß Funcionalidade de controle de qualidade em desenvolvimento")
                st.write("Esta p√°gina incluir√°:")
                st.write("- Gr√°ficos de controle estat√≠stico")
                st.write("- An√°lise de capacidade do processo") 
                st.write("- Pareto de problemas identificados")
                st.write("- Alertas autom√°ticos de qualidade")
            else:
                st.error("M√≥dulo de controle de qualidade n√£o dispon√≠vel")
        except Exception as e:
            st.error(f"Erro no controle de qualidade: {e}")

    def _render_performance_analysis_page(self):
        """Renderiza a p√°gina de an√°lise de performance"""
        st.header("‚ö° An√°lise de Performance")

        try:
            # An√°lise de efici√™ncia simplificada
            st.subheader("üéØ An√°lise de Efici√™ncia")
            timeline_data = self.monitor.get_timeline_data()
            completed_stages = [stage for stage in timeline_data if stage['status'] == 'completed']

            if completed_stages:
                # Tabela simples de performance
                performance_data = []
                for stage in completed_stages:
                    expected = stage.get('expected_duration', 0)
                    actual = stage.get('duration', 0)
                    efficiency = expected / actual if actual > 0 else 0
                    
                    performance_data.append({
                        'Etapa': stage['name'],
                        'Categoria': stage['category'],
                        'Tempo Esperado (s)': expected,
                        'Tempo Real (s)': actual,
                        'Efici√™ncia': f"{efficiency:.2f}x"
                    })

                df_performance = pd.DataFrame(performance_data)
                st.dataframe(df_performance, use_container_width=True)

                # Recomenda√ß√µes simples
                st.subheader("üí° Recomenda√ß√µes de Otimiza√ß√£o")
                
                slow_stages = [stage for stage in completed_stages
                              if stage.get('duration', 0) > stage.get('expected_duration', 0) * 1.5]

                if slow_stages:
                    st.warning("‚ö†Ô∏è Etapas com performance abaixo do esperado:")
                    for stage in slow_stages:
                        expected = stage.get('expected_duration', 1)
                        actual = stage.get('duration', 0)
                        efficiency = expected / actual if actual > 0 else 0
                        st.markdown(f"- **{stage['name']}**: {efficiency:.2f}x efici√™ncia")
                else:
                    st.success("Todas as etapas est√£o dentro do desempenho esperado")

            else:
                st.info("‚ÑπÔ∏è Nenhuma etapa conclu√≠da para an√°lise de performance")
                
        except Exception as e:
            st.error(f"Erro na an√°lise de performance: {e}")
            st.info("üí° Execute o pipeline para gerar dados de performance.")

    def _render_api_cost_analysis_page(self):
        """Renderiza a p√°gina de an√°lise de custos de API"""
        st.header("üí∞ An√°lise de Custos de API - Pipeline v4.9.7")

        # Carregar dados reais de custos
        try:
            costs_path = self.monitor.project_root / "logs/anthropic_costs.json"
            if costs_path.exists():
                with open(costs_path, 'r') as f:
                    costs_data = json.load(f)
                
                # M√©tricas principais com dados reais
                st.subheader("üìä Custos Reais do Pipeline")
                
                col1, col2, col3, col4 = st.columns(4)
                
                total_cost = costs_data.get('total_cost', 0)
                daily_cost_today = costs_data.get('daily_usage', {}).get('2025-06-11', {}).get('cost', 0)
                total_requests = sum(model_data.get('requests', 0) for model_data in costs_data.get('by_model', {}).values())
                
                with col1:
                    st.metric("Custo Total Pipeline", f"${total_cost:.3f}")
                
                with col2:
                    st.metric("Custo Hoje", f"${daily_cost_today:.3f}")
                
                with col3:
                    st.metric("Total de Requests", total_requests)
                
                with col4:
                    avg_cost_per_request = total_cost / total_requests if total_requests > 0 else 0
                    st.metric("Custo M√©dio/Request", f"${avg_cost_per_request:.4f}")
                
                # Gr√°fico de custos por modelo
                st.subheader("üìà Custos por Modelo")
                model_costs = costs_data.get('by_model', {})
                
                if model_costs:
                    fig_models = go.Figure()
                    models = list(model_costs.keys())
                    costs = [model_costs[model]['cost'] for model in models]
                    
                    fig_models.add_trace(go.Bar(
                        x=models,
                        y=costs,
                        marker_color=['lightblue', 'lightgreen']
                    ))
                    
                    fig_models.update_layout(
                        title="Distribui√ß√£o de Custos por Modelo",
                        xaxis_title="Modelo",
                        yaxis_title="Custo (USD)",
                        height=400
                    )
                    st.plotly_chart(fig_models, use_container_width=True)
                
                # Gr√°fico de custos por stage
                st.subheader("üìä Custos por Stage")
                stage_costs = costs_data.get('by_stage', {})
                
                if stage_costs:
                    # Filtrar stages principais (remover unknown)
                    filtered_stages = {k: v for k, v in stage_costs.items() if k != 'unknown'}
                    
                    if filtered_stages:
                        fig_stages = go.Figure()
                        stages = list(filtered_stages.keys())
                        stage_costs_values = [filtered_stages[stage]['cost'] for stage in stages]
                        
                        fig_stages.add_trace(go.Bar(
                            x=stages,
                            y=stage_costs_values,
                            marker_color='lightcoral'
                        ))
                        
                        fig_stages.update_layout(
                            title="Custos por Stage do Pipeline",
                            xaxis_title="Stage",
                            yaxis_title="Custo (USD)",
                            height=400,
                            xaxis_tickangle=-45
                        )
                        st.plotly_chart(fig_stages, use_container_width=True)
                
                # Timeline de custos por dia
                st.subheader("üìÖ Evolu√ß√£o de Custos por Dia")
                daily_usage = costs_data.get('daily_usage', {})
                
                if daily_usage:
                    dates = list(daily_usage.keys())
                    daily_costs = [daily_usage[date]['cost'] for date in dates]
                    
                    fig_timeline = go.Figure()
                    fig_timeline.add_trace(go.Scatter(
                        x=dates,
                        y=daily_costs,
                        mode='lines+markers',
                        name='Custo Di√°rio',
                        line=dict(color='blue', width=3)
                    ))
                    
                    fig_timeline.update_layout(
                        title="Evolu√ß√£o dos Custos por Dia",
                        xaxis_title="Data",
                        yaxis_title="Custo (USD)",
                        height=400
                    )
                    st.plotly_chart(fig_timeline, use_container_width=True)
                
            else:
                st.warning("‚ö†Ô∏è Arquivo de custos n√£o encontrado. Execute o pipeline para gerar dados de custos.")
                
        except Exception as e:
            st.error(f"Erro ao carregar dados de custos: {str(e)}")
        
        # Gr√°fico de custos removido temporariamente devido a problemas de compatibilidade
        # Will be reimplemented in next version

        # Proje√ß√µes
        st.subheader("üìà Proje√ß√µes de Custo")

        # Simula√ß√£o de cen√°rios
        scenarios = {
            'Conservador (sampling 98%)': 0.005,
            'Atual (sampling 96%)': 0.02,
            'Sem sampling': 0.45,
            'Dados completos': 1.2
        }

        fig = go.Figure()
        fig.add_trace(go.Bar(
            x=list(scenarios.keys()),
            y=list(scenarios.values()),
            marker_color=['green', 'blue', 'orange', 'red']
        ))

        fig.update_layout(
            title="Cen√°rios de Custo por Dataset",
            xaxis_title="Cen√°rio",
            yaxis_title="Custo Estimado (USD)",
            height=400
        )

        st.plotly_chart(fig, use_container_width=True)

    def _render_system_health_page(self):
        """Renderiza a p√°gina de sa√∫de do sistema"""
        st.header("üè• Sa√∫de do Sistema")

        # Status dos componentes
        st.subheader("üîß Status dos Componentes")

        components = {
            'Pipeline Core': 'üü¢ Operacional',
            'Anthropic API': 'üü¢ Conectado',
            'Voyage.ai API': 'üü¢ Conectado',
            'spaCy NLP': 'üü¢ Carregado (pt_core_news_lg)',
            'Database': 'üü¢ Acess√≠vel',
            'Dashboard': 'üü¢ Funcionando',
            'Monitoring': 'üü¢ Ativo'
        }

        col1, col2 = st.columns(2)

        with col1:
            for comp, status in list(components.items())[:4]:
                st.markdown(f"**{comp}:** {status}")

        with col2:
            for comp, status in list(components.items())[4:]:
                st.markdown(f"**{comp}:** {status}")

        # M√©tricas do sistema
        st.subheader("üìä M√©tricas do Sistema")

        col1, col2, col3, col4 = st.columns(4)

        with col1:
            st.metric("Uptime", "99.8%", "+0.1%")

        with col2:
            st.metric("Disponibilidade APIs", "99.9%", "Normal")

        with col3:
            st.metric("Tempo Resp. M√©dio", "2.3s", "-0.5s")

        with col4:
            st.metric("Taxa de Erro", "0.1%", "-0.05%")

        # Logs recentes
        st.subheader("üìã Logs Recentes")

        # Simular logs (na implementa√ß√£o real, viria de arquivo de log)
        logs = [
            {'timestamp': '14:32:15', 'level': 'INFO', 'message': 'Pipeline stage 05 completed successfully'},
            {'timestamp': '14:31:48', 'level': 'INFO', 'message': 'Anthropic API call successful (47ms)'},
            {'timestamp': '14:31:22', 'level': 'WARNING', 'message': 'High memory usage detected (78%)'},
            {'timestamp': '14:30:55', 'level': 'INFO', 'message': 'Quality control check passed'},
            {'timestamp': '14:30:12', 'level': 'INFO', 'message': 'Stage 04 processing 1,250 records'}
        ]

        for log in logs:
            level_color = {
                'INFO': 'üü¢',
                'WARNING': 'üü°',
                'ERROR': 'üî¥',
                'DEBUG': 'üîµ'
            }.get(log['level'], '‚ö™')

            st.markdown(f"{level_color} `{log['timestamp']}` **{log['level']}** {log['message']}")

    def _handle_auto_refresh(self):
        """Gerencia o auto-refresh da p√°gina"""
        if st.session_state.auto_refresh:
            time_since_refresh = (datetime.now() - st.session_state.last_refresh).total_seconds()

            if time_since_refresh >= st.session_state.refresh_interval:
                st.session_state.last_refresh = datetime.now()
                st.rerun()

            # Mostrar countdown
            remaining = st.session_state.refresh_interval - time_since_refresh
            if remaining > 0:
                st.sidebar.markdown(f"üîÑ Pr√≥xima atualiza√ß√£o em: {remaining:.0f}s")

def main():
    """Fun√ß√£o principal"""
    dashboard = PipelineDashboardNew()
    dashboard.run()

if __name__ == "__main__":
    main()
