"""
Page: 12 - AnÃ¡lise SemÃ¢ntica (Stage 12)
AnÃ¡lise de sentimento e padrÃµes semÃ¢nticos no discurso polÃ­tico brasileiro

VisualizaÃ§Ãµes:
1. Gauge charts para distribuiÃ§Ã£o de sentimentos (positivo, negativo, neutro)
2. Timeline de evoluÃ§Ã£o temporal do sentimento
"""

import streamlit as st
import pandas as pd
import sys
import os

# Adicionar src ao path
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))

from dashboard.stage12_semantic_dashboard import main_dashboard, SemanticAnalyzer
from dashboard.data_analysis_dashboard import load_processed_data, get_available_datasets

# ConfiguraÃ§Ã£o da pÃ¡gina
st.set_page_config(
    page_title="AnÃ¡lise SemÃ¢ntica - Stage 12",
    page_icon="ðŸ§ ",
    layout="wide",
    initial_sidebar_state="expanded"
)

def main():
    """FunÃ§Ã£o principal da pÃ¡gina."""
    st.title("ðŸ§  Stage 12 - AnÃ¡lise SemÃ¢ntica")
    st.markdown("""
    **AnÃ¡lise de sentimento e padrÃµes semÃ¢nticos no discurso polÃ­tico brasileiro**

    Esta anÃ¡lise examina caracterÃ­sticas semÃ¢nticas e emocionais dos textos atravÃ©s de:

    - **AnÃ¡lise de Sentimento**: ClassificaÃ§Ã£o de polaridade (positivo, negativo, neutro)
    - **Intensidade Emocional**: MediÃ§Ã£o de intensidade emocional baseada em marcadores
    - **Linguagem Agressiva**: DetecÃ§Ã£o de padrÃµes linguÃ­sticos agressivos
    - **Diversidade SemÃ¢ntica**: AnÃ¡lise da variedade vocabular
    """)

    # Verificar se hÃ¡ dados processados disponÃ­veis
    try:
        available_datasets = get_available_datasets()

        if not available_datasets:
            st.error("ðŸ“ Nenhum dataset processado encontrado")
            st.info("""
            Para usar esta anÃ¡lise:
            1. Execute o pipeline de processamento: `python run_pipeline.py`
            2. Ou carregue dados atravÃ©s da pÃ¡gina Home
            """)
            return

        # Sidebar para seleÃ§Ã£o de dataset
        st.sidebar.header("ðŸ”§ ConfiguraÃ§Ãµes")

        selected_dataset = st.sidebar.selectbox(
            "ðŸ“Š Selecionar Dataset:",
            options=list(available_datasets.keys()),
            format_func=lambda x: f"{x} ({available_datasets[x]['size']})"
        )

        if st.sidebar.button("ðŸ”„ Recarregar Dados"):
            st.cache_data.clear()
            st.experimental_rerun()

        # Carregar dados selecionados
        with st.spinner(f"Carregando {selected_dataset}..."):
            df = load_processed_data(selected_dataset)

        if df is None or df.empty:
            st.error(f"âŒ Erro ao carregar dataset: {selected_dataset}")
            return

        # Verificar se hÃ¡ dados semÃ¢nticos processados
        analyzer = SemanticAnalyzer()
        validation = analyzer.validate_semantic_columns(df)
        missing_columns = [col for col, exists in validation.items() if not exists]

        # InformaÃ§Ãµes do dataset
        st.sidebar.markdown("---")
        st.sidebar.subheader("ðŸ“Š InformaÃ§Ãµes do Dataset")
        st.sidebar.write(f"**Registros:** {len(df):,}")
        st.sidebar.write(f"**Colunas:** {len(df.columns)}")

        # Verificar processamento semÃ¢ntico
        semantic_columns = [col for col in df.columns if any(sem_col in col for sem_col in
                           ['sentiment', 'emotion', 'semantic', 'aggressive'])]

        if semantic_columns:
            st.sidebar.write("**AnÃ¡lise SemÃ¢ntica:**")
            for col in semantic_columns:
                if col in df.columns:
                    if df[col].dtype in ['int64', 'float64']:
                        avg_value = df[col].mean()
                        st.sidebar.write(f"- {col}: {avg_value:.3f} mÃ©dia")
                    elif df[col].dtype == 'bool':
                        pct_true = (df[col] == True).mean() * 100
                        st.sidebar.write(f"- {col}: {pct_true:.1f}% True")
                    else:
                        unique_count = df[col].nunique()
                        st.sidebar.write(f"- {col}: {unique_count} categorias")

        if missing_columns:
            st.warning(f"""
            âš ï¸ **Processamento semÃ¢ntico incompleto**

            Colunas ausentes: {', '.join(missing_columns)}

            Este dataset nÃ£o possui processamento semÃ¢ntico completo (Stage 12).
            """)

            # OpÃ§Ã£o para executar anÃ¡lise bÃ¡sica
            if st.button("ðŸ”„ Executar AnÃ¡lise SemÃ¢ntica BÃ¡sica"):
                if 'body' in df.columns or 'normalized_text' in df.columns:
                    text_column = 'normalized_text' if 'normalized_text' in df.columns else 'body'

                    # AnÃ¡lise bÃ¡sica para amostra
                    sample_size = min(500, len(df))
                    df_sample = df.sample(n=sample_size, random_state=42)

                    with st.spinner("Executando anÃ¡lise semÃ¢ntica..."):
                        # Simular anÃ¡lise semÃ¢ntica bÃ¡sica
                        import re
                        from collections import Counter

                        def basic_sentiment_analysis(text):
                            if pd.isna(text):
                                return 0.0, 'neutral'

                            positive_words = ['bom', 'Ã³timo', 'excelente', 'amor', 'feliz', 'sucesso', 'vitÃ³ria']
                            negative_words = ['ruim', 'pÃ©ssimo', 'Ã³dio', 'raiva', 'erro', 'fracasso', 'problema']

                            text_lower = str(text).lower()
                            pos_count = sum(1 for word in positive_words if word in text_lower)
                            neg_count = sum(1 for word in negative_words if word in text_lower)

                            polarity = (pos_count - neg_count) / max(len(text_lower.split()), 1)

                            if polarity > 0.05:
                                label = 'positive'
                            elif polarity < -0.05:
                                label = 'negative'
                            else:
                                label = 'neutral'

                            return polarity, label

                        def basic_emotion_intensity(text):
                            if pd.isna(text):
                                return 0.0

                            markers = text.count('!') + text.count('?') + text.count('...')
                            caps = sum(1 for word in str(text).split() if word.isupper() and len(word) > 2)
                            return min((markers + caps) / 10.0, 1.0)

                        def detect_aggressive(text):
                            if pd.isna(text):
                                return False

                            aggressive = ['Ã³dio', 'matar', 'destruir', 'burro', 'idiota']
                            return any(word in str(text).lower() for word in aggressive)

                        def semantic_diversity(text):
                            if pd.isna(text):
                                return 0.0

                            words = str(text).split()
                            if len(words) == 0:
                                return 0.0
                            return len(set(words)) / len(words)

                        # Aplicar anÃ¡lises
                        results = df_sample[text_column].apply(basic_sentiment_analysis)
                        df_sample['sentiment_polarity'] = [r[0] for r in results]
                        df_sample['sentiment_label'] = [r[1] for r in results]
                        df_sample['emotion_intensity'] = df_sample[text_column].apply(basic_emotion_intensity)
                        df_sample['has_aggressive_language'] = df_sample[text_column].apply(detect_aggressive)
                        df_sample['semantic_diversity'] = df_sample[text_column].apply(semantic_diversity)

                    st.success(f"âœ… AnÃ¡lise semÃ¢ntica bÃ¡sica executada para {len(df_sample)} mensagens")

                    # Executar dashboard com dados processados
                    main_dashboard(df_sample)

                else:
                    st.error("âŒ Nenhuma coluna de texto encontrada para anÃ¡lise")

            return

        # Verificar qualidade dos dados semÃ¢nticos
        quality_metrics = {}

        if 'sentiment_label' in df.columns:
            sentiment_dist = df['sentiment_label'].value_counts()
            total_sentiment = sentiment_dist.sum()
            quality_metrics['total_with_sentiment'] = total_sentiment
            st.sidebar.write(f"**Sentimentos:** {total_sentiment:,} analisados")

        if 'emotion_intensity' in df.columns:
            high_emotion = (df['emotion_intensity'] > 0.3).sum()
            quality_metrics['high_emotion_count'] = high_emotion
            st.sidebar.write(f"**Alta EmoÃ§Ã£o:** {high_emotion:,} mensagens")

        if 'has_aggressive_language' in df.columns:
            aggressive_count = df['has_aggressive_language'].sum()
            quality_metrics['aggressive_count'] = aggressive_count
            st.sidebar.write(f"**Linguagem Agressiva:** {aggressive_count:,} casos")

        # Executar dashboard principal
        main_dashboard(df)

        # SeÃ§Ã£o de anÃ¡lise avanÃ§ada
        st.markdown("---")
        st.subheader("ðŸ“ˆ AnÃ¡lise EstatÃ­stica AvanÃ§ada")

        with st.expander("ðŸ” EstatÃ­sticas Detalhadas"):
            if 'sentiment_polarity' in df.columns:
                col1, col2, col3 = st.columns(3)

                with col1:
                    st.markdown("**Polaridade de Sentimento:**")
                    polarity_stats = df['sentiment_polarity'].describe()
                    for stat, value in polarity_stats.items():
                        st.write(f"- {stat}: {value:.4f}")

                with col2:
                    if 'emotion_intensity' in df.columns:
                        st.markdown("**Intensidade Emocional:**")
                        emotion_stats = df['emotion_intensity'].describe()
                        for stat, value in emotion_stats.items():
                            st.write(f"- {stat}: {value:.4f}")

                with col3:
                    if 'semantic_diversity' in df.columns:
                        st.markdown("**Diversidade SemÃ¢ntica:**")
                        diversity_stats = df['semantic_diversity'].describe()
                        for stat, value in diversity_stats.items():
                            st.write(f"- {stat}: {value:.4f}")

            # CorrelaÃ§Ãµes entre variÃ¡veis semÃ¢nticas
            if all(col in df.columns for col in ['sentiment_polarity', 'emotion_intensity', 'semantic_diversity']):
                st.markdown("**Matriz de CorrelaÃ§Ã£o:**")
                semantic_cols = ['sentiment_polarity', 'emotion_intensity', 'semantic_diversity']
                correlation_matrix = df[semantic_cols].corr()

                import plotly.express as px
                fig_corr = px.imshow(
                    correlation_matrix,
                    title="CorrelaÃ§Ãµes entre VariÃ¡veis SemÃ¢nticas",
                    color_continuous_scale='RdBu',
                    aspect="auto"
                )
                st.plotly_chart(fig_corr, use_container_width=True)

        # InformaÃ§Ãµes tÃ©cnicas
        with st.expander("â„¹ï¸ InformaÃ§Ãµes TÃ©cnicas"):
            st.markdown("""
            **Metodologia de AnÃ¡lise SemÃ¢ntica (Stage 12):**

            **1. AnÃ¡lise de Sentimento:**
            - Polaridade calculada com base em lÃ©xico de palavras positivas e negativas
            - ClassificaÃ§Ã£o categÃ³rica: positive (>0.1), negative (<-0.1), neutral
            - Foco em contexto polÃ­tico brasileiro

            **2. Intensidade Emocional:**
            - Baseada em marcadores textuais: pontuaÃ§Ã£o (!, ?, ...), palavras em maiÃºsculas
            - Escala normalizada 0-1
            - Indicador de engagement emocional

            **3. DetecÃ§Ã£o de Linguagem Agressiva:**
            - LÃ©xico especÃ­fico de termos agressivos e ofensivos
            - ClassificaÃ§Ã£o binÃ¡ria (True/False)
            - Relevante para anÃ¡lise de radicalizaÃ§Ã£o

            **4. Diversidade SemÃ¢ntica:**
            - RazÃ£o entre palavras Ãºnicas e total de palavras
            - Indicador de complexidade vocabular
            - Correlacionado com sofisticaÃ§Ã£o discursiva

            **LimitaÃ§Ãµes:**
            - AnÃ¡lise baseada em lÃ©xico (nÃ£o contextual profunda)
            - EspecÃ­fico para portuguÃªs brasileiro
            - SensÃ­vel Ã  qualidade do prÃ©-processamento
            """)

    except Exception as e:
        st.error(f"âŒ Erro ao carregar pÃ¡gina: {str(e)}")
        st.info("Tente recarregar a pÃ¡gina ou verificar os logs do sistema")

if __name__ == "__main__":
    main()