"""
Stage 14 Network Analysis - Streamlit Page
==========================================

Brazilian Political Discourse Coordination Detection Dashboard
Comprehensive network analysis revealing coordination patterns and influence networks.

TECHNICAL FEATURES:
- Force-directed network visualization with user/channel coordination connections
- Community detection using modularity-based algorithmic clustering
- Centrality analysis with multiple influence metrics (betweenness, closeness, degree, eigenvector)
- Multi-layer network integration combining coordination, sentiment, and topics

ACADEMIC FOCUS:
- Detection of coordinated behavior in Brazilian political messaging
- Identification of influence networks and information brokers
- Analysis of community structures in political discourse
- Multi-dimensional relationship mapping in social media networks
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from pathlib import Path
import sys
import logging
import os
from datetime import datetime

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Add src to path for imports
current_dir = Path(__file__).parent.parent
src_dir = current_dir.parent
sys.path.append(str(src_dir))

try:
    from dashboard.stage14_network_dashboard import NetworkAnalysisDashboard
    from dashboard.dashboard_guardrails import DashboardGuardrails
except ImportError as e:
    st.error(f"Erro ao importar m√≥dulos: {e}")
    st.stop()

# Page configuration
st.set_page_config(
    page_title="Stage 14: Network Analysis",
    page_icon="üï∏Ô∏è",
    layout="wide",
    initial_sidebar_state="expanded"
)

def load_network_data():
    """
    Load network analysis data from Stage 14 results.

    Returns:
        pd.DataFrame: Network analysis dataset or None if not found
    """
    try:
        data_dir = current_dir / "data" / "dashboard_results"

        # Find most recent Stage 14 network analysis file
        pattern = "*network_analysis*.csv"
        network_files = list(data_dir.glob(pattern))

        if not network_files:
            st.warning("‚ö†Ô∏è Arquivos de an√°lise de rede n√£o encontrados")
            st.info("Execute o pipeline completo para gerar dados de Stage 14")
            return None

        # Get most recent file
        latest_file = max(network_files, key=lambda p: p.stat().st_mtime)

        # Load with proper encoding and separator
        df = pd.read_csv(latest_file, sep=';', encoding='utf-8')

        logger.info(f"Dados de rede carregados: {len(df)} registros de {latest_file.name}")
        return df

    except Exception as e:
        st.error(f"Erro ao carregar dados de rede: {e}")
        logger.error(f"Erro ao carregar dados de rede: {e}")
        return None

def validate_network_columns(df: pd.DataFrame) -> bool:
    """
    Validate required columns for network analysis.

    Args:
        df: Input DataFrame

    Returns:
        bool: True if valid, False otherwise
    """
    required_cols = [
        'user_id', 'channel', 'sender_frequency', 'is_frequent_sender',
        'shared_url_frequency', 'temporal_coordination'
    ]

    missing_cols = [col for col in required_cols if col not in df.columns]

    if missing_cols:
        st.error(f"‚ùå Colunas necess√°rias ausentes: {missing_cols}")
        st.info("Verifique se o Stage 14 foi executado corretamente")
        return False

    return True

def display_data_overview(df: pd.DataFrame):
    """
    Display overview of network analysis data.

    Args:
        df: Network analysis DataFrame
    """
    st.subheader("üìä Vis√£o Geral dos Dados de Rede")

    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.metric("Total de Registros", len(df))

    with col2:
        unique_users = df['user_id'].nunique()
        st.metric("Usu√°rios √önicos", unique_users)

    with col3:
        unique_channels = df['channel'].nunique()
        st.metric("Canais √önicos", unique_channels)

    with col4:
        frequent_senders = df['is_frequent_sender'].sum()
        st.metric("Remetentes Frequentes", frequent_senders)

    # Additional metrics
    col1, col2, col3 = st.columns(3)

    with col1:
        avg_sender_freq = df['sender_frequency'].mean()
        st.metric("Frequ√™ncia M√©dia do Remetente", f"{avg_sender_freq:.1f}")

    with col2:
        avg_url_freq = df['shared_url_frequency'].mean()
        st.metric("Frequ√™ncia M√©dia de URLs", f"{avg_url_freq:.1f}")

    with col3:
        avg_temporal_coord = df['temporal_coordination'].mean()
        st.metric("Coordena√ß√£o Temporal M√©dia", f"{avg_temporal_coord:.3f}")

def display_network_filters(df: pd.DataFrame) -> pd.DataFrame:
    """
    Display interactive filters for network analysis.

    Args:
        df: Input DataFrame

    Returns:
        pd.DataFrame: Filtered DataFrame
    """
    st.sidebar.subheader("üîç Filtros de Rede")

    # Minimum sender frequency filter
    min_sender_freq = st.sidebar.slider(
        "Frequ√™ncia M√≠nima do Remetente",
        min_value=int(df['sender_frequency'].min()),
        max_value=int(df['sender_frequency'].max()),
        value=int(df['sender_frequency'].quantile(0.25)),
        help="Filtrar usu√°rios por frequ√™ncia m√≠nima de mensagens"
    )

    # Frequent senders only
    frequent_only = st.sidebar.checkbox(
        "Apenas Remetentes Frequentes",
        value=False,
        help="Mostrar apenas usu√°rios identificados como remetentes frequentes"
    )

    # Minimum URL sharing frequency
    min_url_freq = st.sidebar.slider(
        "Frequ√™ncia M√≠nima de URLs Compartilhadas",
        min_value=int(df['shared_url_frequency'].min()),
        max_value=int(df['shared_url_frequency'].max()),
        value=int(df['shared_url_frequency'].min()),
        help="Filtrar por frequ√™ncia m√≠nima de URLs compartilhadas"
    )

    # Temporal coordination threshold
    min_temporal_coord = st.sidebar.slider(
        "Coordena√ß√£o Temporal M√≠nima",
        min_value=float(df['temporal_coordination'].min()),
        max_value=float(df['temporal_coordination'].max()),
        value=float(df['temporal_coordination'].quantile(0.1)),
        format="%.3f",
        help="Filtrar por n√≠vel m√≠nimo de coordena√ß√£o temporal"
    )

    # Channel selection
    selected_channels = st.sidebar.multiselect(
        "Selecionar Canais",
        options=sorted(df['channel'].unique()),
        default=sorted(df['channel'].unique())[:5],  # Default to first 5 channels
        help="Escolher canais espec√≠ficos para an√°lise"
    )

    # Apply filters
    filtered_df = df[
        (df['sender_frequency'] >= min_sender_freq) &
        (df['shared_url_frequency'] >= min_url_freq) &
        (df['temporal_coordination'] >= min_temporal_coord) &
        (df['channel'].isin(selected_channels))
    ]

    if frequent_only:
        filtered_df = filtered_df[filtered_df['is_frequent_sender'] == True]

    # Display filter results
    st.sidebar.write(f"**Registros ap√≥s filtros:** {len(filtered_df)}")
    if len(filtered_df) < len(df):
        reduction_pct = (1 - len(filtered_df) / len(df)) * 100
        st.sidebar.write(f"**Redu√ß√£o:** {reduction_pct:.1f}%")

    return filtered_df

def display_network_insights(df: pd.DataFrame):
    """
    Display network analysis insights and statistics.

    Args:
        df: Network analysis DataFrame
    """
    st.subheader("üîç Insights da An√°lise de Rede")

    # User activity analysis
    col1, col2 = st.columns(2)

    with col1:
        st.write("**Distribui√ß√£o da Atividade dos Usu√°rios**")

        # Sender frequency distribution
        fig_freq = px.histogram(
            df, x='sender_frequency',
            title="Distribui√ß√£o da Frequ√™ncia de Remetentes",
            labels={'sender_frequency': 'Frequ√™ncia do Remetente', 'count': 'N√∫mero de Usu√°rios'},
            color_discrete_sequence=['lightblue']
        )
        fig_freq.update_layout(height=300, showlegend=False)
        st.plotly_chart(fig_freq, use_container_width=True)

    with col2:
        st.write("**Coordena√ß√£o e Compartilhamento**")

        # Temporal coordination vs URL sharing
        fig_coord = px.scatter(
            df, x='temporal_coordination', y='shared_url_frequency',
            title="Coordena√ß√£o Temporal vs. Compartilhamento de URLs",
            labels={
                'temporal_coordination': 'Coordena√ß√£o Temporal',
                'shared_url_frequency': 'Frequ√™ncia de URLs'
            },
            color='is_frequent_sender',
            color_discrete_map={True: 'red', False: 'blue'}
        )
        fig_coord.update_layout(height=300)
        st.plotly_chart(fig_coord, use_container_width=True)

    # Channel analysis
    st.write("**An√°lise por Canal**")

    channel_stats = df.groupby('channel').agg({
        'user_id': 'nunique',
        'sender_frequency': 'mean',
        'shared_url_frequency': 'mean',
        'temporal_coordination': 'mean',
        'is_frequent_sender': 'sum'
    }).round(3)

    channel_stats.columns = [
        'Usu√°rios √önicos', 'Freq. M√©dia Remetente', 'Freq. M√©dia URLs',
        'Coordena√ß√£o Temporal M√©dia', 'Remetentes Frequentes'
    ]

    st.dataframe(channel_stats, use_container_width=True)

    # Top users analysis
    st.write("**Usu√°rios Mais Ativos**")

    top_users = df.groupby('user_id').agg({
        'sender_frequency': 'first',
        'shared_url_frequency': 'first',
        'temporal_coordination': 'first',
        'is_frequent_sender': 'first',
        'channel': 'nunique'
    }).round(3)

    top_users.columns = [
        'Frequ√™ncia', 'URLs Compartilhadas', 'Coordena√ß√£o Temporal',
        '√â Frequente', 'Canais √önicos'
    ]

    top_users = top_users.sort_values('Frequ√™ncia', ascending=False).head(10)
    st.dataframe(top_users, use_container_width=True)

def main():
    """Main function for Stage 14 Network Analysis page."""

    # Page header
    st.title("üï∏Ô∏è Stage 14: An√°lise de Rede")
    st.markdown("**Detec√ß√£o de coordena√ß√£o e padr√µes de influ√™ncia no discurso pol√≠tico brasileiro**")

    # Initialize guardrails
    guardrails = DashboardGuardrails()

    # Check for data availability
    if not guardrails.check_data_availability():
        st.error("‚ùå Dados n√£o dispon√≠veis para an√°lise")
        st.info("Execute o pipeline de an√°lise para gerar os dados necess√°rios")
        return

    # Load network data
    with st.spinner("Carregando dados de an√°lise de rede..."):
        df = load_network_data()

    if df is None:
        st.error("‚ùå N√£o foi poss√≠vel carregar os dados de rede")
        return

    # Validate columns
    if not validate_network_columns(df):
        return

    # Display data overview
    display_data_overview(df)

    st.markdown("---")

    # Apply filters
    filtered_df = display_network_filters(df)

    if len(filtered_df) == 0:
        st.warning("‚ö†Ô∏è Nenhum registro encontrado com os filtros aplicados")
        st.info("Ajuste os filtros para incluir mais dados")
        return

    # Network insights
    display_network_insights(filtered_df)

    st.markdown("---")

    # Main network analysis dashboard
    st.subheader("üî¨ An√°lise Avan√ßada de Rede")

    if st.button("üöÄ Executar An√°lise Completa de Rede", type="primary"):
        try:
            # Initialize network analysis dashboard
            dashboard = NetworkAnalysisDashboard()

            # Render complete dashboard
            with st.spinner("Executando an√°lise completa de rede..."):
                dashboard.render_dashboard(filtered_df)

        except Exception as e:
            st.error(f"Erro na an√°lise de rede: {e}")
            logger.error(f"Erro na an√°lise de rede: {e}")

    # Additional analysis options
    st.sidebar.markdown("---")
    st.sidebar.subheader("‚öôÔ∏è Op√ß√µes Avan√ßadas")

    if st.sidebar.checkbox("Mostrar Dados Brutos", value=False):
        st.subheader("üìã Dados Brutos de Rede")
        st.dataframe(filtered_df.head(100), use_container_width=True)

        # Download option
        csv = filtered_df.to_csv(index=False, sep=';')
        st.download_button(
            label="üì• Baixar Dados Filtrados (CSV)",
            data=csv,
            file_name=f"network_analysis_filtered_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
            mime="text/csv"
        )

    # Performance monitoring
    if st.sidebar.checkbox("Monitor de Performance", value=False):
        st.sidebar.success(f"‚úÖ {len(filtered_df)} registros carregados")
        st.sidebar.info(f"üìä {filtered_df['user_id'].nunique()} usu√°rios √∫nicos")
        st.sidebar.info(f"üì∫ {filtered_df['channel'].nunique()} canais √∫nicos")

    # Documentation
    st.sidebar.markdown("---")
    st.sidebar.subheader("üìö Sobre Stage 14")
    st.sidebar.write("""
    **An√°lise de Rede para Detec√ß√£o de Coordena√ß√£o:**

    ‚Ä¢ **Force-directed Network**: Visualiza√ß√£o interativa das conex√µes de coordena√ß√£o
    ‚Ä¢ **Community Detection**: Identifica√ß√£o algor√≠tmica de grupos coordenados
    ‚Ä¢ **Centrality Analysis**: M√©tricas de influ√™ncia e import√¢ncia dos n√≥s
    ‚Ä¢ **Multi-layer Network**: Integra√ß√£o de coordena√ß√£o, sentimento e t√≥picos

    **M√©tricas Calculadas:**
    - Frequ√™ncia do remetente
    - Frequ√™ncia de URLs compartilhadas
    - Coordena√ß√£o temporal
    - Identifica√ß√£o de remetentes frequentes
    """)


if __name__ == "__main__":
    main()