"""
Page: 13 - An√°lise Temporal (Stage 13)
An√°lise temporal de padr√µes de coordena√ß√£o no discurso pol√≠tico brasileiro

Visualiza√ß√µes:
1. Line chart: Volume de mensagens ao longo do tempo
2. Event correlation: Picos de atividade vs eventos pol√≠ticos
3. Heatmap: Coordena√ß√£o temporal entre usu√°rios/canais
4. Network graph: Clusters de atividade sincronizada
5. Timeline: Per√≠odos de alta coordena√ß√£o identificados
6. Sankey: Fluxo temporal ‚Üí sentimento ‚Üí affordances
"""

import streamlit as st
import pandas as pd
import sys
import os

# Adicionar src ao path
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))

from dashboard.stage13_temporal_dashboard import main_dashboard, TemporalAnalyzer

# Simplified data loading functions
def get_available_datasets():
    """Get available processed datasets."""
    import os
    processed_dir = "data/processed"
    if not os.path.exists(processed_dir):
        return []

    files = []
    for file in os.listdir(processed_dir):
        if file.endswith('.csv'):
            files.append(file)
    return files

def load_processed_data(filename):
    """Load processed dataset."""
    import pandas as pd
    try:
        if not filename.endswith('.csv'):
            filename += '.csv'
        filepath = f"data/processed/{filename}"
        return pd.read_csv(filepath, sep=';', encoding='utf-8')
    except Exception as e:
        st.error(f"Erro ao carregar dataset: {e}")
        return None

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="An√°lise Temporal - Stage 13",
    page_icon="‚è∞",
    layout="wide",
    initial_sidebar_state="expanded"
)

def main():
    """Fun√ß√£o principal da p√°gina."""
    st.title("‚è∞ Stage 13 - An√°lise Temporal")
    st.markdown("""
    **An√°lise temporal de padr√µes de coordena√ß√£o no discurso pol√≠tico brasileiro**

    Esta an√°lise examina caracter√≠sticas temporais e de coordena√ß√£o atrav√©s de:

    - **Volume Temporal**: Evolu√ß√£o da atividade de mensagens ao longo do tempo
    - **Correla√ß√£o de Eventos**: Picos de atividade correlacionados com eventos pol√≠ticos brasileiros
    - **Coordena√ß√£o Temporal**: Padr√µes de sincroniza√ß√£o entre usu√°rios e canais
    - **Redes de Atividade**: Clusters de atividade sincronizada e coordenada
    - **Timeline de Coordena√ß√£o**: Identifica√ß√£o de per√≠odos de alta coordena√ß√£o
    - **Fluxos Integrados**: An√°lise de fluxo temporal ‚Üí sentimento ‚Üí affordances
    """)

    # Verificar se h√° dados processados dispon√≠veis
    try:
        available_datasets = get_available_datasets()

        if not available_datasets:
            st.error("üìÅ Nenhum dataset processado encontrado")
            st.info("""
            Para usar esta an√°lise:
            1. Execute o pipeline de processamento: `python run_pipeline.py`
            2. Ou carregue dados j√° processados na pasta `/data/processed/`
            3. Certifique-se de que o Stage 13 (An√°lise Temporal) foi executado
            """)
            return

        # Sidebar para sele√ß√£o de dataset
        st.sidebar.header("‚öôÔ∏è Configura√ß√µes")

        selected_dataset = st.sidebar.selectbox(
            "Selecionar Dataset:",
            available_datasets,
            help="Escolha o dataset processado para an√°lise temporal"
        )

        # Op√ß√µes de filtro temporal
        st.sidebar.subheader("üîç Filtros Temporais")

        # Filtro por per√≠odo
        time_filter = st.sidebar.selectbox(
            "Filtrar por per√≠odo:",
            ["Todos os per√≠odos", "Hor√°rio comercial", "Fora do hor√°rio", "Fins de semana", "Dias √∫teis"],
            help="Filtrar dados por per√≠odos espec√≠ficos"
        )

        # Filtro por coordena√ß√£o
        coord_filter = st.sidebar.slider(
            "Coordena√ß√£o m√≠nima:",
            min_value=0.0,
            max_value=1.0,
            value=0.0,
            step=0.1,
            help="Filtrar mensagens por n√≠vel m√≠nimo de coordena√ß√£o temporal"
        )

        # Carregamento dos dados
        with st.spinner(f"Carregando dataset: {selected_dataset}"):
            df = load_processed_data(selected_dataset)

        if df is None or df.empty:
            st.error(f"‚ùå Erro ao carregar dataset: {selected_dataset}")
            return

        # Verificar se cont√©m dados do Stage 13
        temporal_columns = [
            'hour', 'day_of_week', 'month', 'year', 'day_of_year',
            'sender_frequency', 'is_frequent_sender', 'temporal_coordination',
            'is_weekend', 'is_business_hours'
        ]

        available_temporal_cols = [col for col in temporal_columns if col in df.columns]

        if len(available_temporal_cols) < 3:
            st.warning(f"""
            ‚ö†Ô∏è **Dados de Stage 13 incompletos**

            Colunas temporais encontradas: {len(available_temporal_cols)}/10

            Colunas dispon√≠veis: {', '.join(available_temporal_cols) if available_temporal_cols else 'Nenhuma'}

            Execute o pipeline completo para obter dados de an√°lise temporal.
            """)

        # Aplicar filtros
        df_filtered = df.copy()

        # Aplicar filtro temporal
        if time_filter != "Todos os per√≠odos":
            if time_filter == "Hor√°rio comercial" and 'is_business_hours' in df.columns:
                df_filtered = df_filtered[df_filtered['is_business_hours'] == True]
            elif time_filter == "Fora do hor√°rio" and 'is_business_hours' in df.columns:
                df_filtered = df_filtered[df_filtered['is_business_hours'] == False]
            elif time_filter == "Fins de semana" and 'is_weekend' in df.columns:
                df_filtered = df_filtered[df_filtered['is_weekend'] == True]
            elif time_filter == "Dias √∫teis" and 'is_weekend' in df.columns:
                df_filtered = df_filtered[df_filtered['is_weekend'] == False]

        # Aplicar filtro de coordena√ß√£o
        if coord_filter > 0.0 and 'temporal_coordination' in df.columns:
            df_filtered = df_filtered[df_filtered['temporal_coordination'] >= coord_filter]

        # Mostrar informa√ß√µes do dataset filtrado
        col1, col2, col3 = st.columns(3)

        with col1:
            st.metric("üìä Registros totais", f"{len(df):,}")

        with col2:
            st.metric("üîç Registros filtrados", f"{len(df_filtered):,}")

        with col3:
            if len(df) > 0:
                filter_percentage = (len(df_filtered) / len(df)) * 100
                st.metric("üìà % Mantido ap√≥s filtros", f"{filter_percentage:.1f}%")
            else:
                st.metric("üìà % Mantido ap√≥s filtros", "0%")

        if len(df_filtered) == 0:
            st.warning("‚ö†Ô∏è Nenhum registro restante ap√≥s aplicar filtros. Ajuste os crit√©rios de filtro.")
            return

        # An√°lise temporal principal
        st.markdown("---")

        # Informa√ß√µes do dataset
        with st.expander("‚ÑπÔ∏è Informa√ß√µes do Dataset"):
            st.write(f"**Dataset:** {selected_dataset}")
            st.write(f"**Registros:** {len(df_filtered):,}")
            st.write(f"**Colunas:** {len(df_filtered.columns)}")

            if 'datetime' in df_filtered.columns:
                try:
                    df_temp = df_filtered.copy()
                    df_temp['parsed_datetime'] = pd.to_datetime(df_temp['datetime'], format='%d/%m/%Y %H:%M:%S', errors='coerce')
                    valid_dates = df_temp['parsed_datetime'].dropna()

                    if len(valid_dates) > 0:
                        st.write(f"**Per√≠odo:** {valid_dates.min().strftime('%Y-%m-%d')} a {valid_dates.max().strftime('%Y-%m-%d')}")
                        st.write(f"**Dura√ß√£o:** {(valid_dates.max() - valid_dates.min()).days} dias")
                except:
                    st.write("**Per√≠odo:** N√£o dispon√≠vel")

            # Mostrar colunas temporais dispon√≠veis
            st.write("**Colunas temporais dispon√≠veis:**")
            for col in temporal_columns:
                status = "‚úÖ" if col in df_filtered.columns else "‚ùå"
                st.write(f"{status} {col}")

        # Executar dashboard principal
        main_dashboard(df_filtered)

        # Se√ß√£o de an√°lise adicional
        st.markdown("---")
        st.subheader("üìà An√°lise Adicional")

        # Duas colunas para an√°lises extras
        col1, col2 = st.columns(2)

        with col1:
            st.write("**Distribui√ß√£o Temporal**")
            if 'hour' in df_filtered.columns:
                hour_dist = df_filtered['hour'].value_counts().sort_index()
                st.bar_chart(hour_dist)
            else:
                st.info("Dados de hora n√£o dispon√≠veis")

        with col2:
            st.write("**Coordena√ß√£o por Per√≠odo**")
            if 'temporal_coordination' in df_filtered.columns and 'is_business_hours' in df_filtered.columns:
                coord_by_period = df_filtered.groupby('is_business_hours')['temporal_coordination'].mean()
                coord_df = pd.DataFrame({
                    'Per√≠odo': ['Fora do hor√°rio', 'Hor√°rio comercial'],
                    'Coordena√ß√£o': [coord_by_period.get(False, 0), coord_by_period.get(True, 0)]
                })
                st.bar_chart(coord_df.set_index('Per√≠odo'))
            else:
                st.info("Dados de coordena√ß√£o por per√≠odo n√£o dispon√≠veis")

        # Tabela de resumo estat√≠stico
        st.subheader("üìä Resumo Estat√≠stico Temporal")

        temporal_stats = {}

        if 'temporal_coordination' in df_filtered.columns:
            temporal_stats['Coordena√ß√£o Temporal'] = {
                'M√©dia': df_filtered['temporal_coordination'].mean(),
                'Mediana': df_filtered['temporal_coordination'].median(),
                'Desvio Padr√£o': df_filtered['temporal_coordination'].std(),
                'M√≠nimo': df_filtered['temporal_coordination'].min(),
                'M√°ximo': df_filtered['temporal_coordination'].max()
            }

        if 'sender_frequency' in df_filtered.columns:
            temporal_stats['Frequ√™ncia do Remetente'] = {
                'M√©dia': df_filtered['sender_frequency'].mean(),
                'Mediana': df_filtered['sender_frequency'].median(),
                'Desvio Padr√£o': df_filtered['sender_frequency'].std(),
                'M√≠nimo': df_filtered['sender_frequency'].min(),
                'M√°ximo': df_filtered['sender_frequency'].max()
            }

        if temporal_stats:
            stats_df = pd.DataFrame(temporal_stats).round(4)
            st.dataframe(stats_df, use_container_width=True)
        else:
            st.info("Estat√≠sticas temporais n√£o dispon√≠veis")

        # Footer informativo
        st.markdown("---")
        st.markdown("""
        **Sobre a An√°lise Temporal:**

        - **Coordena√ß√£o Temporal**: Mede a sincroniza√ß√£o de atividade entre usu√°rios
        - **Eventos Pol√≠ticos**: Correlaciona picos de atividade com eventos do cen√°rio pol√≠tico brasileiro
        - **Redes de Atividade**: Identifica clusters de usu√°rios com atividade coordenada
        - **Fluxos Integrados**: Conecta padr√µes temporais com an√°lises de sentimento e affordances

        *Esta an√°lise √© parte do Stage 13 do pipeline de an√°lise de discurso pol√≠tico brasileiro.*
        """)

    except Exception as e:
        st.error(f"‚ùå Erro ao carregar an√°lise temporal: {str(e)}")
        st.info("Verifique se o pipeline foi executado corretamente e se os dados est√£o dispon√≠veis.")

if __name__ == "__main__":
    main()