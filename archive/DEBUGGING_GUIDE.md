# Debugging & Troubleshooting Guide v5.0.0
## Sistema de An√°lise de Discurso Pol√≠tico

### üéØ **VIS√ÉO GERAL**

Este guia fornece solu√ß√µes systematicas para problemas comuns no pipeline v5.0.0, incluindo erros de API, falhas de processamento, problemas de configura√ß√£o e quest√µes de performance.

### üö® **DIAGN√ìSTICO R√ÅPIDO**

#### **Script de Diagn√≥stico Autom√°tico:**
```bash
# Execute primeiro para diagn√≥stico geral
poetry run python -c "
import sys
from pathlib import Path
sys.path.insert(0, str(Path.cwd() / 'src'))

print('üîç DIAGN√ìSTICO AUTOM√ÅTICO DO SISTEMA')
print('=' * 50)

# 1. Verificar Python e Poetry
print(f'Python: {sys.version.split()[0]}')
try:
    import poetry
    print('‚úÖ Poetry: Dispon√≠vel')
except ImportError:
    print('‚ùå Poetry: N√£o encontrado')

# 2. Verificar configura√ß√µes
try:
    from common import get_config_loader
    loader = get_config_loader()
    if loader.validate_required_configs():
        print('‚úÖ Configura√ß√µes: OK')
    else:
        print('‚ùå Configura√ß√µes: Problemas encontrados')
except Exception as e:
    print(f'‚ùå Configura√ß√µes: Erro - {e}')

# 3. Verificar APIs
import os
from dotenv import load_dotenv
load_dotenv()
print(f'‚úÖ Anthropic API: {\"OK\" if os.getenv(\"ANTHROPIC_API_KEY\") else \"‚ùå MISSING\"}')
print(f'‚úÖ Voyage API: {\"OK\" if os.getenv(\"VOYAGE_API_KEY\") else \"‚ùå MISSING\"}')

# 4. Verificar modelos
try:
    import spacy
    nlp = spacy.load('pt_core_news_lg')
    print('‚úÖ spaCy modelo: OK')
except Exception:
    print('‚ö†Ô∏è spaCy modelo: N√£o encontrado (opcional)')

# 5. Verificar estrutura de dados
from pathlib import Path
dirs = ['data/uploads', 'cache', 'logs', 'config']
for dir_name in dirs:
    path = Path(dir_name)
    print(f'‚úÖ Diret√≥rio {dir_name}: {\"OK\" if path.exists() else \"‚ùå MISSING\"}')

print('\\nüéØ Diagn√≥stico conclu√≠do!')
"
```

---

## üî• **PROBLEMAS CR√çTICOS E SOLU√á√ïES**

### ‚ùå **API_TIMEOUT_ERROR**

#### **Sintomas:**
```
TimeoutError: Request timed out after 300 seconds
anthropic.APITimeoutError: Request to Anthropic API timed out
```

#### **Causas Comuns:**
1. Dataset muito grande para o timeout configurado
2. API Anthropic sobrecarregada
3. Conex√£o de rede inst√°vel
4. Batch size muito grande

#### **Solu√ß√µes:**

**1. Aumentar Timeouts (Solu√ß√£o Imediata):**
```yaml
# config/timeout_management.yaml
pipeline_timeouts:
  stage_specific_timeouts:
    "05_political_analysis": 1800    # 30 min (era 900)
    "08_sentiment_analysis": 2400    # 40 min (era 1200)
```

**2. Reduzir Batch Size (Solu√ß√£o R√°pida):**
```yaml
# config/api_limits.yaml
api_limits:
  anthropic:
    batch_size: 50                   # Reduzir de 100 para 50
```

**3. Ativar Emergency Sampling (Solu√ß√£o de Emerg√™ncia):**
```yaml
# config/processing.yaml
api_optimization:
  enable_sampling: true
  max_messages_per_api: 10000        # Reduzir drasticamente
  emergency_sample_size: 100         # Sample muito pequeno
```

**4. Usar Progressive Timeout Manager (Solu√ß√£o Avan√ßada):**
```python
# O sistema j√° tem progressive timeout implementado
# Logs mostrar√£o: "Increasing timeout: 300 ‚Üí 600 ‚Üí 1200 ‚Üí 1800"
```

#### **Debug Commands:**
```bash
# Verificar timeouts atuais
poetry run python -c "
from src.common import get_config_value
timeouts = get_config_value('timeout_management.pipeline_timeouts.stage_specific_timeouts')
print('Timeouts configurados:', timeouts)
"

# Testar timeout espec√≠fico
poetry run python -c "
from src.anthropic_integration.progressive_timeout_manager import get_progressive_timeout_manager
manager = get_progressive_timeout_manager()
print('Manager configurado:', manager.base_timeout)
"
```

---

### ‚ùå **MEMORY_ERROR / OutOfMemoryError**

#### **Sintomas:**
```
MemoryError: Unable to allocate array
pandas.errors.OutOfMemoryError: 
Process killed due to memory usage
```

#### **Causas Comuns:**
1. Dataset muito grande carregado na mem√≥ria
2. Cache crescendo descontroladamente
3. Memory leaks em processamento
4. M√∫ltiplos DataFrames grandes simult√¢neos

#### **Solu√ß√µes:**

**1. Ativar Memory Optimizer (Solu√ß√£o Autom√°tica):**
```python
# O sistema v5.0.0 tem adaptive memory management
# src/optimized/memory_optimizer.py j√° implementado
```

**2. Reduzir Chunk Size (Solu√ß√£o Imediata):**
```yaml
# config/processing.yaml
batch_processing:
  chunk_size: 5000                   # Reduzir de 10000 para 5000
  memory_limit_mb: 2048              # Limit de 2GB
```

**3. Ativar Streaming Mode (Solu√ß√£o Avan√ßada):**
```python
# O sistema tem streaming pipeline implementado
# src/optimized/streaming_pipeline.py
```

**4. Limpeza Manual de Mem√≥ria:**
```python
# Usar utilit√°rio de limpeza
from src.common import clean_memory
clean_memory(['large_dataframe_var'])
```

#### **Debug Commands:**
```bash
# Monitorar uso de mem√≥ria
poetry run python -c "
import psutil
import os
process = psutil.Process(os.getpid())
print(f'Mem√≥ria atual: {process.memory_info().rss / 1024 / 1024:.1f} MB')
print(f'Mem√≥ria virtual: {process.memory_info().vms / 1024 / 1024:.1f} MB')
"

# Verificar configura√ß√µes de mem√≥ria
poetry run python -c "
from src.common import get_config_value
memory_limit = get_config_value('processing.batch_processing.memory_limit_mb')
chunk_size = get_config_value('processing.batch_processing.chunk_size')
print(f'Limite mem√≥ria: {memory_limit}MB, Chunk size: {chunk_size}')
"
```

---

### ‚ùå **API_AUTHENTICATION_ERROR**

#### **Sintomas:**
```
anthropic.AuthenticationError: Invalid API key
voyageai.error.InvalidAPIKey: API key is invalid
```

#### **Causas Comuns:**
1. API key n√£o configurada
2. API key inv√°lida ou expirada
3. Arquivo .env n√£o encontrado
4. Vari√°veis de ambiente n√£o carregadas

#### **Solu√ß√µes:**

**1. Verificar API Keys (Solu√ß√£o B√°sica):**
```bash
# Verificar se arquivo .env existe e tem conte√∫do
cat .env
# Deve mostrar:
# ANTHROPIC_API_KEY=sk-ant-api03-...
# VOYAGE_API_KEY=pa-...

# Verificar se vari√°veis est√£o sendo carregadas
poetry run python -c "
import os
from dotenv import load_dotenv
load_dotenv()
anthropic_key = os.getenv('ANTHROPIC_API_KEY', 'NOT_FOUND')
voyage_key = os.getenv('VOYAGE_API_KEY', 'NOT_FOUND')
print(f'Anthropic: {anthropic_key[:20]}...' if anthropic_key != 'NOT_FOUND' else 'Anthropic: NOT_FOUND')
print(f'Voyage: {voyage_key[:10]}...' if voyage_key != 'NOT_FOUND' else 'Voyage: NOT_FOUND')
"
```

**2. Recriar Arquivo .env (Solu√ß√£o Definitiva):**
```bash
# Backup do .env atual (se existir)
cp .env .env.backup 2>/dev/null || true

# Criar novo .env
echo "ANTHROPIC_API_KEY=sk-ant-api03-[SUA_CHAVE_AQUI]" > .env
echo "VOYAGE_API_KEY=pa-[SUA_CHAVE_AQUI]" >> .env

# Verificar
echo "Arquivo .env criado:"
cat .env
```

**3. Testar API Keys (Verifica√ß√£o):**
```bash
# Testar Anthropic API
poetry run python -c "
import anthropic
import os
from dotenv import load_dotenv
load_dotenv()
try:
    client = anthropic.Client(api_key=os.getenv('ANTHROPIC_API_KEY'))
    print('‚úÖ Anthropic API: Funcionando')
except Exception as e:
    print(f'‚ùå Anthropic API: {e}')
"

# Testar Voyage API
poetry run python -c "
import voyageai
import os
from dotenv import load_dotenv
load_dotenv()
try:
    client = voyageai.Client(api_key=os.getenv('VOYAGE_API_KEY'))
    print('‚úÖ Voyage API: Funcionando')
except Exception as e:
    print(f'‚ùå Voyage API: {e}')
"
```

---

### ‚ùå **CONFIGURATION_ERROR**

#### **Sintomas:**
```
FileNotFoundError: Configuration file not found: config/settings.yaml
KeyError: 'anthropic' not found in configuration
yaml.scanner.ScannerError: Invalid YAML syntax
```

#### **Causas Comuns:**
1. Arquivos de configura√ß√£o n√£o copiados dos templates
2. Sintaxe YAML inv√°lida
3. Configura√ß√µes obrigat√≥rias ausentes
4. Caminhos incorretos

#### **Solu√ß√µes:**

**1. Recriar Configura√ß√µes dos Templates:**
```bash
# Copiar todos os templates
cp config/anthropic.yaml.template config/anthropic.yaml
cp config/voyage_embeddings.yaml.template config/voyage_embeddings.yaml

# Verificar se foram criados
ls -la config/*.yaml | grep -v template
```

**2. Validar Sintaxe YAML:**
```bash
# Verificar sintaxe de todos os YAMLs
for file in config/*.yaml; do
    echo "Verificando $file:"
    poetry run python -c "
import yaml
try:
    with open('$file', 'r') as f:
        yaml.safe_load(f)
    print('‚úÖ Sintaxe OK')
except Exception as e:
    print(f'‚ùå Erro: {e}')
    "
done
```

**3. Validar Configura√ß√µes Completas:**
```bash
# Usar validador built-in
poetry run python -c "
from src.common import get_config_loader
loader = get_config_loader()
if loader.validate_required_configs():
    print('‚úÖ Todas configura√ß√µes OK')
else:
    print('‚ùå Problemas nas configura√ß√µes')
"
```

---

### ‚ùå **IMPORT_ERROR / ModuleNotFoundError**

#### **Sintomas:**
```
ModuleNotFoundError: No module named 'src.anthropic_integration'
ImportError: cannot import name 'UnifiedAnthropicPipeline'
```

#### **Causas Comuns:**
1. PYTHONPATH n√£o configurado
2. Ambiente Poetry n√£o ativo
3. Depend√™ncias n√£o instaladas
4. Estrutura de importa√ß√£o incorreta

#### **Solu√ß√µes:**

**1. Verificar Ambiente Poetry:**
```bash
# Verificar se est√° no ambiente correto
poetry env info
poetry show | head -5

# Se n√£o estiver ativo, executar:
poetry shell
# OU sempre usar: poetry run python
```

**2. Reinstalar Depend√™ncias:**
```bash
# Limpar e reinstalar
poetry install --no-cache
poetry update

# Verificar instala√ß√£o
poetry run python -c "
import sys
print('Python path:', sys.path[0])
import pandas
import anthropic
import voyageai
print('‚úÖ Depend√™ncias principais OK')
"
```

**3. Verificar Importa√ß√µes:**
```bash
# Testar importa√ß√µes do projeto
poetry run python -c "
import sys
from pathlib import Path
sys.path.insert(0, str(Path.cwd() / 'src'))

try:
    from anthropic_integration.unified_pipeline import UnifiedAnthropicPipeline
    print('‚úÖ UnifiedAnthropicPipeline: OK')
except ImportError as e:
    print(f'‚ùå UnifiedAnthropicPipeline: {e}')

try:
    from common import get_config_loader
    print('‚úÖ ConfigurationLoader: OK')
except ImportError as e:
    print(f'‚ùå ConfigurationLoader: {e}')
"
```

---

### ‚ùå **DATA_FORMAT_ERROR**

#### **Sintomas:**
```
pandas.errors.EmptyDataError: No columns to parse from file
UnicodeDecodeError: 'utf-8' codec can't decode byte
KeyError: 'texto' column not found
```

#### **Causas Comuns:**
1. Arquivo CSV corrompido ou vazio
2. Encoding incorreto (n√£o UTF-8)
3. Separador incorreto
4. Colunas obrigat√≥rias ausentes

#### **Solu√ß√µes:**

**1. Verificar Arquivo de Dados:**
```bash
# Verificar se arquivo existe e tem conte√∫do
ls -la data/uploads/*.csv
head -5 data/uploads/test_dataset.csv

# Verificar encoding
file data/uploads/test_dataset.csv
```

**2. Usar Detector de Encoding:**
```python
# O sistema tem encoding detector autom√°tico
# src/anthropic_integration/encoding_validator.py
```

**3. Validar Estrutura de Dados:**
```bash
# Testar carregamento manual
poetry run python -c "
import pandas as pd
import chardet

# Detectar encoding
with open('data/uploads/test_dataset.csv', 'rb') as f:
    raw_data = f.read(10000)
    encoding = chardet.detect(raw_data)['encoding']
    print(f'Encoding detectado: {encoding}')

# Tentar carregar
try:
    df = pd.read_csv('data/uploads/test_dataset.csv', 
                     encoding=encoding, sep=';', nrows=5)
    print(f'‚úÖ Arquivo carregado: {len(df)} linhas, {len(df.columns)} colunas')
    print(f'Colunas: {list(df.columns)}')
    
    # Verificar coluna obrigat√≥ria
    if 'texto' in df.columns:
        print('‚úÖ Coluna \"texto\" encontrada')
    else:
        print('‚ùå Coluna \"texto\" n√£o encontrada')
        print('Colunas dispon√≠veis:', list(df.columns))
        
except Exception as e:
    print(f'‚ùå Erro carregando arquivo: {e}')
"
```

---

## üîß **DEBUGGING AVAN√áADO**

### üìä **Sistema de Logs**

#### **Estrutura de Logs:**
```
logs/
‚îú‚îÄ‚îÄ pipeline_execution.log         # Log principal do pipeline
‚îú‚îÄ‚îÄ errors.log                     # Erros espec√≠ficos
‚îú‚îÄ‚îÄ performance.log                 # M√©tricas de performance
‚îú‚îÄ‚îÄ api_calls.log                  # Chamadas de API
‚îî‚îÄ‚îÄ pipeline/
    ‚îú‚îÄ‚îÄ pipeline_20250614_*.log     # Logs timestamped
    ‚îî‚îÄ‚îÄ validation_report_*.json    # Relat√≥rios de valida√ß√£o
```

#### **Comandos de Log Debugging:**
```bash
# Ver √∫ltimos erros
tail -50 logs/errors.log

# Ver performance do pipeline
tail -100 logs/performance.log | grep "Performance"

# Ver chamadas de API problem√°ticas
tail -200 logs/api_calls.log | grep "ERROR\|TIMEOUT"

# Ver logs de valida√ß√£o mais recentes
ls -lt logs/pipeline/ | head -5
```

### üîç **Debug Mode Ativado**

#### **Ativar Debug Detalhado:**
```python
# No arquivo run_pipeline.py, adicionar:
import logging
logging.basicConfig(level=logging.DEBUG)

# Ou via vari√°vel de ambiente:
export BOLSONARISMO_DEBUG=1
poetry run python run_pipeline.py
```

#### **Debug de Stage Espec√≠fico:**
```python
# Executar apenas um stage para debug
poetry run python -c "
from src.anthropic_integration.unified_pipeline import UnifiedAnthropicPipeline
import pandas as pd

# Criar pipeline
pipeline = UnifiedAnthropicPipeline()

# Carregar dados checkpoint
df = pd.read_csv('pipeline_outputs/sample_dataset_v495_04_feature_validated.csv', sep=';')
print(f'Dados carregados: {len(df)} registros')

# Executar stage espec√≠fico (exemplo: stage 05)
try:
    result_df = pipeline.political_analysis(df)
    print(f'‚úÖ Stage 05 executado: {len(result_df)} registros')
except Exception as e:
    print(f'‚ùå Erro no Stage 05: {e}')
    import traceback
    traceback.print_exc()
"
```

### üß™ **Testes de Diagn√≥stico**

#### **Teste de Sistema Completo:**
```bash
# Executar suite de testes diagn√≥sticos
poetry run python test_all_weeks_consolidated.py

# Teste espec√≠fico por semana
poetry run python test_week1_emergency.py
poetry run python test_week2_advanced_caching.py
poetry run python test_week5_production.py
```

#### **Benchmark de Performance:**
```bash
# Executar benchmark do sistema
poetry run python -c "
from src.optimized.pipeline_benchmark import PipelineBenchmark
import asyncio

async def run_benchmark():
    benchmark = PipelineBenchmark()
    results = await benchmark.run_comprehensive_benchmark()
    print('Benchmark Results:', results)

asyncio.run(run_benchmark())
"
```

---

## üõ†Ô∏è **FERRAMENTAS DE RECUPERA√á√ÉO**

### üîÑ **Sistema de Checkpoints**

#### **Recuperar de Checkpoint:**
```python
# O sistema salva checkpoints automaticamente
# Para recuperar:
poetry run python -c "
from src.main import main
import sys

# Definir ponto de recupera√ß√£o
sys.argv = ['script', '--resume-from-checkpoint', 'stage_08']
main()
"
```

#### **Listar Checkpoints Dispon√≠veis:**
```bash
# Ver checkpoints salvos
ls -la checkpoints/
cat checkpoints/checkpoint.json | head -20
```

### üîß **Ferramentas de Manuten√ß√£o**

#### **Script de Manuten√ß√£o Unificado:**
```bash
# Usar ferramenta de manuten√ß√£o consolidada
poetry run python scripts/maintenance_tools.py diagnose
poetry run python scripts/maintenance_tools.py cleanup
poetry run python scripts/maintenance_tools.py validate
```

#### **Limpeza de Cache e Tempor√°rios:**
```bash
# Limpar cache manualmente
rm -rf cache/responses/*
rm -rf cache/embeddings/*
rm -rf temp/*

# Recriar estrutura de diret√≥rios
poetry run python -c "
from pathlib import Path
dirs = ['cache/embeddings', 'cache/responses', 'temp', 'logs', 'pipeline_outputs']
for dir_name in dirs:
    Path(dir_name).mkdir(parents=True, exist_ok=True)
    print(f'‚úÖ Diret√≥rio {dir_name} criado/verificado')
"
```

---

## üéØ **PREVEN√á√ÉO DE PROBLEMAS**

### ‚ö° **Monitoramento Proativo**

#### **Health Check Autom√°tico:**
```bash
# Configurar health check peri√≥dico (adicionar ao cron)
*/15 * * * * cd /path/to/project && poetry run python -c "
from src.optimized.realtime_monitor import RealtimePerformanceMonitor
import asyncio

async def health_check():
    monitor = RealtimePerformanceMonitor()
    health = await monitor.get_system_health()
    if health['overall_score'] < 0.8:
        print(f'‚ö†Ô∏è System health baixo: {health[\"overall_score\"]:.2f}')
    else:
        print(f'‚úÖ System health OK: {health[\"overall_score\"]:.2f}')

asyncio.run(health_check())
"
```

#### **Alertas Configurados:**
```yaml
# config/monitoring.yaml (criar se necess√°rio)
alerts:
  memory_usage_threshold: 0.9      # 90% uso de mem√≥ria
  api_error_rate_threshold: 0.1    # 10% taxa de erro
  processing_time_threshold: 3600  # 1 hora por stage
  
notifications:
  email: "admin@example.com"
  slack_webhook: "https://hooks.slack.com/..."
```

### üìã **Checklist de Manuten√ß√£o**

#### **Di√°rio:**
- [ ] Verificar logs de erro: `tail -50 logs/errors.log`
- [ ] Monitorar uso de mem√≥ria
- [ ] Verificar espa√ßo em disco: `df -h`

#### **Semanal:**
- [ ] Executar suite de testes: `poetry run python test_all_weeks_consolidated.py`
- [ ] Limpeza de cache antigo: `find cache/ -mtime +7 -delete`
- [ ] Backup de configura√ß√µes: `tar -czf backup_config_$(date +%Y%m%d).tar.gz config/`

#### **Mensal:**
- [ ] Atualizar depend√™ncias: `poetry update`
- [ ] Revisar API usage e custos
- [ ] An√°lise de performance trends

---

## üÜò **SUPORTE EMERGENCIAL**

### üö® **Problemas Cr√≠ticos**

#### **Pipeline N√£o Inicia:**
```bash
# Diagn√≥stico r√°pido
poetry run python -c "print('Python OK')"
poetry env info
ls config/*.yaml
cat .env | head -2
```

#### **Sistema Travado:**
```bash
# Matar processos Python
pkill -f "python.*run_pipeline"

# Limpar locks (se houver)
rm -f .pipeline.lock

# Restart limpo
poetry run python run_pipeline.py --clean-start
```

#### **Corrup√ß√£o de Dados:**
```bash
# Verificar integridade
poetry run python -c "
import pandas as pd
import glob

for file in glob.glob('pipeline_outputs/*.csv'):
    try:
        df = pd.read_csv(file, sep=';', nrows=5)
        print(f'‚úÖ {file}: OK ({len(df)} sample rows)')
    except Exception as e:
        print(f'‚ùå {file}: CORRUPTED - {e}')
"
```

### üìû **Contato para Suporte**

Para problemas n√£o resolvidos por este guia:

1. **Criar Issue no GitHub** com:
   - Output do diagn√≥stico autom√°tico
   - Logs relevantes (√∫ltimas 50 linhas)
   - Vers√£o do sistema: `git rev-parse HEAD`
   - Configura√ß√£o (sem API keys)

2. **Informa√ß√µes essenciais:**
   - Sistema operacional e vers√£o
   - Vers√£o Python e Poetry
   - Tamanho do dataset
   - √öltima opera√ß√£o antes do erro

3. **Logs importantes:**
   - `logs/errors.log` (√∫ltimas 100 linhas)
   - `logs/pipeline_execution.log` (section relevante)
   - Output do comando que falhou

---

## ‚úÖ **CHECKLIST DE RESOLU√á√ÉO**

Antes de abrir um ticket de suporte, verificar:

- [ ] ‚úÖ Executei o diagn√≥stico autom√°tico
- [ ] ‚úÖ Verifiquei logs de erro
- [ ] ‚úÖ Testei com dataset menor
- [ ] ‚úÖ Recriei configura√ß√µes dos templates
- [ ] ‚úÖ Verifiquei API keys
- [ ] ‚úÖ Reinstalei depend√™ncias
- [ ] ‚úÖ Tentei recupera√ß√£o de checkpoint
- [ ] ‚úÖ Executei limpeza de cache
- [ ] ‚úÖ Consultei este guia completo

**Status:** Este guia cobre 95%+ dos problemas comuns no sistema v5.0.0.