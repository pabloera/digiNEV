# digiNEV v.final - Brazilian Political Discourse Analysis

## ğŸ¯ CONTEXTO
**Tipo**: Pesquisa AcadÃªmica em CiÃªncias Sociais
**Foco**: AnÃ¡lise sociolÃ³gica de discurso polÃ­tico brasileiro
**Dataset**: Mensagens Telegram (2019-2023)
**Specs**: 4GB RAM | Portuguese-optimized | 14 stages cientÃ­ficos | Consolidado

## ğŸ—ï¸ Sistema CientÃ­fico Consolidado v.final

### Pipeline CientÃ­fico (14 estÃ¡gios) - IMPLEMENTADO
1. **Feature Extraction (01)**: DetecÃ§Ã£o automÃ¡tica de colunas e features
2. **Text Preprocessing (02)**: Limpeza bÃ¡sica de texto em portuguÃªs
3. **Linguistic Processing (03)**: Processamento linguÃ­stico avanÃ§ado com spaCy
4. **Statistical Analysis (04)**: AnÃ¡lise estatÃ­stica com dados spaCy
5. **Political Classification (05)**: ClassificaÃ§Ã£o polÃ­tica brasileira
6. **TF-IDF Vectorization (06)**: TF-IDF com tokens spaCy
7. **Clustering Analysis (07)**: Clustering baseado em features linguÃ­sticas
8. **Topic Modeling (08)**: Topic modeling com embeddings
9. **Temporal Analysis (09)**: AnÃ¡lise temporal
10. **Network Analysis (10)**: CoordenaÃ§Ã£o e padrÃµes de rede
11. **Domain Analysis (11)**: AnÃ¡lise de domÃ­nios e URLs
12. **Semantic Analysis (12)**: AnÃ¡lise semÃ¢ntica avanÃ§ada
13. **Event Context (13)**: DetecÃ§Ã£o de contextos polÃ­ticos
14. **Channel Analysis (14)**: ClassificaÃ§Ã£o de canais/fontes

**Stack**: Python | scikit-learn | spaCy pt_core_news_lg | Streamlit

## ğŸš€ ExecuÃ§Ã£o

### Analyzer v.final
```bash
# ExecuÃ§Ã£o direta
python run_pipeline.py

# Teste com dados controlados
python test_clean_analyzer.py

# Dashboard acadÃªmico
python -m src.dashboard.start_dashboard
```

### Uso ProgramÃ¡tico
```python
from src.analyzer import Analyzer

analyzer = Analyzer()
results = analyzer.analyze_dataset(df)
print(f"Colunas geradas: {results['columns_generated']}")
print(f"Stages completados: {results['stats']['stages_completed']}/14")
```

## ğŸ”§ CaracterÃ­sticas Principais

### ClassificaÃ§Ã£o PolÃ­tica (Stage 05)
- **Categorias**: extrema-direita, direita, centro, esquerda, neutral, unknown
- **LÃ©xico polÃ­tico brasileiro** integrado
- **ClassificaÃ§Ã£o baseada** em anÃ¡lise de conteÃºdo real

### Recursos Implementados
- **spaCy**: Processamento linguÃ­stico em portuguÃªs (pt_core_news_lg)
- **scikit-learn**: TF-IDF, K-Means clustering, LDA topic modeling
- **Python puro**: AnÃ¡lise estatÃ­stica, temporal e de redes
- **Regex otimizado**: ExtraÃ§Ã£o de features em portuguÃªs brasileiro

## ğŸ“ Estrutura

```
â”œâ”€â”€ src/                         # Sistema cientÃ­fico consolidado
â”‚   â”œâ”€â”€ analyzer.py              # Analyzer v.final (nÃºcleo principal) - 14 stages
â”‚   â”œâ”€â”€ lexicon_loader.py        # Carregador de lÃ©xico polÃ­tico
â”‚   â””â”€â”€ dashboard/               # Dashboard acadÃªmico
â”‚       â”œâ”€â”€ start_dashboard.py   # Iniciador do dashboard
â”‚       â”œâ”€â”€ data_analysis_dashboard.py  # Dashboard principal
â”‚       â””â”€â”€ [outros dashboards]  # Dashboards especializados
â”œâ”€â”€ config/                      # ConfiguraÃ§Ã£o unificada
â”‚   â”œâ”€â”€ settings.yaml            # ConfiguraÃ§Ãµes principais
â”‚   â”œâ”€â”€ processing.yaml          # ConfiguraÃ§Ãµes de processamento
â”‚   â””â”€â”€ [outras configs]         # ConfiguraÃ§Ãµes especÃ­ficas
â”œâ”€â”€ data/                        # Datasets de pesquisa
â”œâ”€â”€ run_pipeline.py              # Script principal de execuÃ§Ã£o
â””â”€â”€ test_clean_analyzer.py       # Teste do sistema
```

### Regras Estruturais
- TODO cÃ³digo cientÃ­fico em `/src`
- ConfiguraÃ§Ã£o distribuÃ­da em `/config`
- NUNCA criar `.fixed`, `.new`, `.updated`
- SEMPRE editar arquivos in-place

## ğŸ”¬ AplicaÃ§Ãµes de Pesquisa
- EvoluÃ§Ã£o da polarizaÃ§Ã£o polÃ­tica (2019-2023)
- PadrÃµes de legitimaÃ§Ã£o da violÃªncia
- Marcadores do discurso autoritÃ¡rio
- AnÃ¡lise de coordenaÃ§Ã£o em rede
- Indicadores de erosÃ£o democrÃ¡tica

## ğŸ“Š SaÃ­da de Dados
- **30+ colunas reais** geradas pelo pipeline sequencial de 14 stages
- ClassificaÃ§Ã£o polÃ­tica (extrema-direita, direita, centro, esquerda, neutral)
- AnÃ¡lise estatÃ­stica descritiva (word_count, char_count, sentence_count)
- Features extraÃ­das automaticamente (hashtags, URLs, mentions, emojis)
- TF-IDF com scores reais e top termos por documento
- Clustering K-Means com distÃ¢ncias calculadas
- Topic modeling LDA com probabilidades reais
- AnÃ¡lise temporal (hour, day_of_week, month) quando disponÃ­vel
- CoordenaÃ§Ã£o de rede detectada por cluster e tempo
- AnÃ¡lise de domÃ­nios e URLs com classificaÃ§Ã£o
- AnÃ¡lise semÃ¢ntica avanÃ§ada com conectivos e modalidade
- Contexto de eventos polÃ­ticos brasileiros
- AnÃ¡lise de canais/fontes com autoridade e padrÃµes

## ğŸ§ª Testes
```bash
# Teste do pipeline consolidado
python test_clean_analyzer.py

# ExecuÃ§Ã£o com dados reais
python run_pipeline.py
```

## ğŸ’¡ Diretrizes de Desenvolvimento

### PrincÃ­pios Fundamentais
1. **TESTAR SEMPRE** - Cada mudanÃ§a testada imediatamente
2. **DADOS REAIS** - Usar datasets reais, nÃ£o sintÃ©ticos
3. **REFATORAR INCREMENTALMENTE** - Pequenas mudanÃ§as validadas
4. **FALHAR RÃPIDO** - Detectar problemas cedo
5. **MEDIR IMPACTO** - Comparar performance antes/depois

### Workflow ObrigatÃ³rio
```python
# Baseline â†’ MudanÃ§a â†’ Teste â†’ ValidaÃ§Ã£o â†’ Commit
df_original = pd.read_csv('data/controlled_test_100.csv', sep=';')
baseline_results = pipeline.process_dataset(df_original.copy())
# ... cÃ³digo modificado ...
new_results = pipeline.process_dataset(df_test.copy())
assert len(new_results) == len(baseline_results)
```

## ğŸ”§ PolÃ­ticas de ImplementaÃ§Ã£o

### RefatoraÃ§Ã£o de MÃ³dulos
```python
# 1. Branch â†’ 2. MÃ³dulo isolado â†’ 3. Teste â†’ 4. IntegraÃ§Ã£o â†’ 5. ConsolidaÃ§Ã£o
refactoring_checklist = {
    'political_analyzer.py': {'tested': False, 'integrated': False},
    'sentiment_analyzer.py': {'tested': False, 'integrated': False}
}
# Consolidar APENAS se todos passaram
```

### Debugging e ValidaÃ§Ã£o
```python
# Logging detalhado
logging.debug(f"Input: {df.shape}, Columns: {df.columns.tolist()}")

# Tratamento de erros com contexto
try:
    result = complex_operation(data)
except Exception as e:
    logging.error(f"Erro: {e}, Context: {data.shape}")
    raise

# ValidaÃ§Ã£o pragmÃ¡tica
def validate_dataframe(df, stage_name):
    validations = {'not_empty': len(df) > 0, 'has_text': 'text' in df.columns}
    failed = [k for k, v in validations.items() if not v]
    if failed: logging.warning(f"Stage {stage_name}: {failed}")
    return df
```

### OtimizaÃ§Ã£o e Cache
```python
# Medir antes de otimizar
@measure_performance
def expensive_function(): pass

# Cache inteligente
@lru_cache(maxsize=10)
def cached_operation(cache_key): pass

# Monitoramento de memÃ³ria
def check_memory(expected_gb=2.0):
    mem_gb = psutil.Process().memory_info().rss / 1024**3
    if mem_gb > expected_gb: gc.collect()
```

## ğŸ“ Controle de MudanÃ§as

### Estrutura do Changelog
```markdown
## [2025-09-30] - Sprint Atual
### âœ… Adicionado: Pipeline 22 estÃ¡gios, validaÃ§Ã£o dados reais
### ğŸ”„ Modificado: political_analyzer.py otimizaÃ§Ã£o (linha 45-67)
### ğŸ› Corrigido: Bug memÃ³ria stage_15, encoding UTF-8
### ğŸ“Š MÃ©tricas: Tempo 45sâ†’31s, MemÃ³ria 2.1GBâ†’1.4GB
```

### AutomaÃ§Ã£o
```python
class ChangelogManager:
    def add_change(self, type, description, details=None):
        # Buffer automÃ¡tico com timestamp
    def commit_to_changelog(self, version=None):
        # ConsolidaÃ§Ã£o por tipo: added/changed/fixed/removed
```

## ğŸ­ OrquestraÃ§Ã£o de Tarefas

### PadrÃ£o de OrquestraÃ§Ã£o
```python
@dataclass
class Task:
    name: str
    function: Callable
    dependencies: List[str] = None
    retry_count: int = 3
    timeout: float = 300
    critical: bool = True

class PragmaticOrchestrator:
    def add_task(self, task: Task): # Registrar tarefa
    async def run_task(self, task_name: str): # Executar com retry/timeout
    async def orchestrate(self): # Executar respeitando dependÃªncias
```

### Exemplo de Uso
```python
orchestrator = PragmaticOrchestrator()
orchestrator.add_task(Task("load_data", lambda: pd.read_csv(...), critical=True))
orchestrator.add_task(Task("validate", validate_func, dependencies=["load_data"]))
results = await orchestrator.orchestrate()
```

### Monitoramento
```python
class OrchestratorMonitor:
    def print_status(self): # Status visual das tarefas
    def get_metrics(self): # MÃ©tricas de sucesso/falha
```

## ğŸ”„ Regras de Desenvolvimento

### PolÃ­tica de AtualizaÃ§Ãµes
**ANTES** de modificar: LISTAR â†’ PRESERVAR â†’ COMENTAR â†’ TESTAR

### EdiÃ§Ã£o de CÃ³digo
```python
# âŒ NUNCA: Deletar arquivo inteiro, reescrever do zero
# âœ… SEMPRE: Identificar trecho exato, mostrar "linhas X-Y", verificar impactos
```

### VerificaÃ§Ã£o de IntegraÃ§Ã£o
- [ ] FunÃ§Ã£o alterada: onde Ã© chamada?
- [ ] Import modificado: quais arquivos importam?
- [ ] Output alterado: verificar pipelines dependentes

### ImplementaÃ§Ã£o
```python
# Dados reais obrigatÃ³rios
if not os.path.exists(data_path):
    raise FileNotFoundError(f"Dados reais necessÃ¡rios: {data_path}")

# Guardrails sempre
assert data is not None and len(data) > 0
assert required_columns.issubset(data.columns)
```

### Continuidade de Pipeline
```python
# Pipeline atual:
# [âœ“] Etapa 1: Coleta â†’ [âœ“] Etapa 2: Limpeza â†’ [â–º] Etapa 3: ALTERANDO
```

## âš ï¸ Checklist CrÃ­tico
- [ ] Arquivo em `/src`?
- [ ] Nome preservado?
- [ ] CÃ³digo comentado?
- [ ] CHANGELOG atualizado?
- [ ] Linguagem acadÃªmica?

## ğŸš« ProibiÃ§Ãµes
- âŒ Inventar funÃ§Ãµes sem verificar
- âŒ Criar fora de `/src`
- âŒ Usar linguagem comercial
- âŒ Criar `.fixed`/`.new`
- âŒ Deletar sem preservar

## ğŸ“Š Dados e Arquivos

### Datasets de Pesquisa
- `batch_analyzer/data/1_2019-2021-govbolso.csv` (135.88 MB)
- `batch_analyzer/data/2_2021-2022-pandemia.csv` (229.96 MB)
- `data/controlled_test_100.csv` (teste local)

### Arquivos CrÃ­ticos
**Sistema Principal:**
- `/src/analyzer.py` - Pipeline consolidado 14 estÃ¡gios
- `/run_pipeline.py` - Script de execuÃ§Ã£o principal
- `/test_clean_analyzer.py` - Teste do sistema

**Dashboard:**
- `/src/dashboard/data_analysis_dashboard.py` - Dashboard principal
- `/src/dashboard/start_dashboard.py` - Iniciador do dashboard

## ğŸ“ AtualizaÃ§Ãµes Recentes (Out 2025)
- âœ… Pipeline consolidado em 14 stages sequenciais
- âœ… Analyzer.py implementado com todos os estÃ¡gios funcionais
- âœ… ClassificaÃ§Ã£o polÃ­tica brasileira integrada
- âœ… Dashboard unificado disponÃ­vel
- âœ… Sistema testado e validado
- âœ… DocumentaÃ§Ã£o atualizada para refletir realidade

---
**Version**: v.final | **RAM**: 4GB | **Focus**: AnÃ¡lise discurso polÃ­tico brasileiro consolidado