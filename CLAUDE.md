# digiNEV v.final - Brazilian Political Discourse Analysis

## üéØ CONTEXTO
**Tipo**: Pesquisa Acad√™mica em Ci√™ncias Sociais
**Foco**: An√°lise sociol√≥gica de discurso pol√≠tico brasileiro
**Dataset**: Mensagens Telegram (2019-2023)
**Specs**: 4GB RAM | Portuguese-optimized | 17 stages cient√≠ficos otimizados | Consolidado

## üèóÔ∏è Sistema Cient√≠fico Consolidado v.final

### Pipeline Cient√≠fico Otimizado (17 est√°gios) - IMPLEMENTADO E VALIDADO
**FASE 1: PREPARA√á√ÉO (01-02)**
1. **Feature Extraction (01)**: Detec√ß√£o autom√°tica de colunas e features
2. **Text Preprocessing (02)**: Limpeza b√°sica de texto em portugu√™s

**FASE 2: REDU√á√ÉO DE VOLUME (03-06) - CR√çTICO PARA PERFORMANCE**
3. **Cross-Dataset Deduplication (03)**: Elimina√ß√£o de duplicatas (redu√ß√£o 40-50%)
4. **Statistical Analysis (04)**: An√°lise estat√≠stica comparativa
5. **Content Quality Filter (05)**: Filtro de qualidade (redu√ß√£o 15-25%)
6. **Political Relevance Filter (06)**: Filtro de relev√¢ncia pol√≠tica (redu√ß√£o 30-40%)

**FASE 3: AN√ÅLISE LINGU√çSTICA (07-09) - VOLUME OTIMIZADO**
7. **Linguistic Processing (07)**: Processamento lingu√≠stico avan√ßado com spaCy
8. **Political Classification (08)**: Classifica√ß√£o pol√≠tica brasileira
9. **TF-IDF Vectorization (09)**: TF-IDF com tokens spaCy

**FASE 4: AN√ÅLISES AVAN√áADAS (10-17)**
10. **Clustering Analysis (10)**: Clustering baseado em features lingu√≠sticas
11. **Topic Modeling (11)**: Topic modeling com embeddings
12. **Semantic Analysis (12)**: An√°lise sem√¢ntica avan√ßada
13. **Temporal Analysis (13)**: An√°lise temporal
14. **Network Analysis (14)**: Coordena√ß√£o e padr√µes de rede
15. **Domain Analysis (15)**: An√°lise de dom√≠nios e URLs
16. **Event Context (16)**: Detec√ß√£o de contextos pol√≠ticos
17. **Channel Analysis (17)**: Classifica√ß√£o de canais/fontes

**Stack**: Python | scikit-learn | spaCy pt_core_news_sm | pandas | numpy | Anthropic Claude API

### API Integration (v6.2) ‚Äî Fev 2026
- **6 stages com API h√≠brida**: Stage 06, 08, 11, 12, 16, 17
- **Padr√£o**: Heur√≠stica 100% ‚Üí confidence score ‚Üí API para baixa confian√ßa ‚Üí merge
- **Modelo**: `claude-sonnet-4-20250514` (Sonnet 4)
- **Batch API**: Suportada (50% desconto), ativ√°vel via `USE_BATCH_API=true` no `.env`
- **Prompt Caching**: Ativo (90% desconto no input repetido)
- **Fallback**: Sem API key ‚Üí 100% heur√≠stica (pipeline NUNCA falha)

| Stage | Fun√ß√£o | Threshold | Colunas novas |
|-------|--------|-----------|---------------|
| S06 | Affordances | confidence < 0.6 | (reclassifica categorias existentes) |
| S08 | Classifica√ß√£o pol√≠tica | confidence < 0.4 | `political_confidence` |
| S11 | Topic modeling (LDA + API) | confidence < 0.4 | `topic_label`, `topic_confidence` |
| S12 | Sentimento/emo√ß√µes | confidence < 0.5 | `sentiment_confidence`, `emotion_anger/fear/hope/disgust`, `emotion_sarcasm` |
| S16 | Contexto de eventos | confidence < 0.5 | `event_confidence`, `specific_event` |
| S17 | Classifica√ß√£o de canais | tipo = 'general' | `channel_confidence`, `channel_theme` |

- **Resultados reais (500 rows)**: S08 neutral 40%‚Üí9.4% | S11 t√≥picos nomeados ("Not√≠cias Pol√≠ticas Lula") | S12 +sarcasmo/emo√ß√µes | S16 22 eventos detectados (8_janeiro=18) | S17 100% "general" reclassificados
- **M√©todos gen√©ricos**: `_api_classify_sync()`, `_api_submit_batch()`, `_api_poll_batch()`, `_api_process_low_confidence()`, `_parse_api_json_response()`

### Modulariza√ß√£o (TAREFA 11) ‚Äî Fev 2026
- Cada stage extra√≠do como m√≥dulo independente em `src/stages/stage_XX.py`
- Registry de stages: `from stages import STAGE_REGISTRY`
- Helpers compartilhados: `from stages.helpers import _calculate_emoji_ratio, ...`
- `src/analyzer.py` = **source of truth** (vers√£o autoritativa inline)
- `src/stages/` = vers√£o modular de refer√™ncia, 1:1 com os m√©todos inline
- 19 arquivos: 17 stages + helpers.py + __init__.py (3327 linhas total)

### Reestrutura√ß√£o do Pipeline (TARETAs 1-10) ‚Äî Fev 2026
- **8 bugs corrigidos**: spaCy input, caps/emoji/hashtag sobre body, token names, URL detection
- **TCW integrado** no Stage 08 (217 c√≥digos, 10 categorias, 181 termos)
- **L√©xico expandido**: +2 macrotemas (corrup√ß√£o, pol√≠tica externa) no lexico_unified_system.json
- **Keywords expandido**: +2 categorias (cat11_corrupcao, cat12_politica_externa)
- **Token matching** via set() lookup com spaCy lemmas (O(1) por token)

## üöÄ Execu√ß√£o

### Uso Program√°tico
```python
from src.analyzer import Analyzer

analyzer = Analyzer()
output = analyzer.analyze(df)  # Retorna dict
result_df = output['data']     # DataFrame com 126 colunas (113 base + 13 API)
print(f"Stages: {output['stages_completed']}/17")
print(f"Colunas: {output['columns_generated']}")
```

### Teste R√°pido com Dados Reais
```python
import pandas as pd
from src.analyzer import Analyzer

df = pd.read_csv('path/to/dataset.csv', nrows=500, sep=',',
                  quotechar='"', quoting=1, on_bad_lines='skip')
analyzer = Analyzer()
output = analyzer.analyze(df)
print(f"Rows: {len(df)} ‚Üí {output['total_records']} (p√≥s-filtro)")
```

## üîß Caracter√≠sticas Principais

### Classifica√ß√£o Pol√≠tica (Stage 05)
- **Categorias**: extrema-direita, direita, centro, esquerda, neutral, unknown
- **L√©xico pol√≠tico brasileiro** integrado
- **Classifica√ß√£o baseada** em an√°lise de conte√∫do real

### Recursos Implementados
- **spaCy**: Processamento lingu√≠stico em portugu√™s (pt_core_news_lg)
- **scikit-learn**: TF-IDF, K-Means clustering, LDA topic modeling
- **Python puro**: An√°lise estat√≠stica, temporal e de redes
- **Regex otimizado**: Extra√ß√£o de features em portugu√™s brasileiro

## üìÅ Estrutura

```
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ analyzer.py              # Pipeline principal (17 stages inline) ‚Äî SOURCE OF TRUTH
‚îÇ   ‚îú‚îÄ‚îÄ lexicon_loader.py        # Carregador de l√©xico pol√≠tico
‚îÇ   ‚îú‚îÄ‚îÄ core/                    # Recursos de classifica√ß√£o
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ lexico_unified_system.json  # L√©xico unificado (12 macrotemas)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ political_keywords_dict.py  # Keywords pol√≠ticas (12 categorias)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tcw_codes.json              # TCW: 217 c√≥digos, 181 termos
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tcw_categories.json         # TCW: 10 categorias tem√°ticas
‚îÇ   ‚îú‚îÄ‚îÄ stages/                  # M√≥dulos extra√≠dos (TAREFA 11)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py          # STAGE_REGISTRY + imports
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ helpers.py           # 21 fun√ß√µes utilit√°rias compartilhadas
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ stage_01.py          # Feature Extraction
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ stage_02.py          # Text Preprocessing
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ...                  # Stages 03-17
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ stage_17.py          # Channel Analysis
‚îÇ   ‚îî‚îÄ‚îÄ dashboard/               # Dashboard acad√™mico
‚îú‚îÄ‚îÄ config/                      # Configura√ß√£o unificada
‚îÇ   ‚îî‚îÄ‚îÄ settings.yaml            # Configura√ß√µes principais
‚îú‚îÄ‚îÄ data/                        # Datasets de pesquisa
‚îî‚îÄ‚îÄ run_pipeline.py              # Script principal de execu√ß√£o
```

### Regras Estruturais
- TODO c√≥digo cient√≠fico em `/src`
- Configura√ß√£o distribu√≠da em `/config`
- NUNCA criar `.fixed`, `.new`, `.updated`
- SEMPRE editar arquivos in-place

## üî¨ Aplica√ß√µes de Pesquisa
- Evolu√ß√£o da polariza√ß√£o pol√≠tica (2019-2023)
- Padr√µes de legitima√ß√£o da viol√™ncia
- Marcadores do discurso autorit√°rio
- An√°lise de coordena√ß√£o em rede
- Indicadores de eros√£o democr√°tica

## üìä Sa√≠da de Dados
- **126 colunas** geradas pelo pipeline sequencial de 17 stages (113 base + 13 API)
- Classifica√ß√£o pol√≠tica (extrema-direita, direita, centro-direita, neutral) + `political_confidence`
- An√°lise estat√≠stica (word_count, char_count, sentence_count, caps_ratio, emoji_ratio)
- Features extra√≠das (hashtags, URLs, mentions, emojis ‚Äî sobre body cru)
- Deduplica√ß√£o cross-dataset com contador de frequ√™ncia
- Filtros de qualidade com scores 0-100
- Affordances (8 categorias: ataque, intera√ß√£o, m√≠dia_social, mobiliza√ß√£o, etc.)
- spaCy: tokens, lemmas, entities, lemmatized_text (sobre body cru)
- Classifica√ß√£o pol√≠tica com token matching via set() sobre spacy_lemmas
- TCW: tcw_codes (3-digit), tcw_categories (10 cat.), tcw_agreement (1-3)
- TF-IDF com scores e top termos (sobre lemmatized_text)
- Clustering K-Means com dist√¢ncias calculadas
- Topic modeling LDA com `topic_label` (nomeado via API) + `topic_confidence`
- Sentimento: `sentiment_label` + emo√ß√µes granulares (anger, fear, hope, disgust, sarcasm)
- Eventos: `specific_event` (8_janeiro, stf_inquerito, eleicao_2022, etc.) + `event_confidence`
- Canais: `channel_type` (conspiracy, military, activism, etc.) + `channel_confidence`, `channel_theme`
- An√°lise temporal, network, dom√≠nios

### Resultados de Valida√ß√£o ‚Äî v6.0 (heur√≠stica pura, Fev 2026)

| Teste | Dataset | Rows in‚Üíout | Stages | Errors | Colunas | Tempo |
|-------|---------|-------------|--------|--------|---------|-------|
| 1 | 4_elec (100) | 100‚Üí67 | 17/17 | 0 | 113 | 0.7s |
| 2 | 4_elec (500) | 500‚Üí298 | 17/17 | 0 | 113 | 3.4s |
| 3 | 2_pandemia (1000) | 1000‚Üí705 | 17/17 | 0 | 113 | 7.6s |
| 4 | 1_govbolso (2000) | 2000‚Üí717 | 17/17 | 0 | 113 | 6.1s |

### Resultados de Valida√ß√£o ‚Äî v6.2 (6 API stages, Fev 2026)

| Teste | Dataset | Rows in‚Üíout | Stages | Errors | Colunas | Tempo |
|-------|---------|-------------|--------|--------|---------|-------|
| E2E quick | 4_elec (100) | 100‚Üí67 | 17/17 | 0 | 126 | ~90s |
| E2E standard | 4_elec (200) | 200‚Üí120 | 17/17 | 0 | 126 | ~187s |
| E2E full | 4_elec (500) | 500‚Üí298 | 17/17 | 0 | 126 | ~384s |

## üß™ Testes
```bash
# Teste ponta-a-ponta v6.2 (com API)
python test_e2e_pipeline.py --quick      # 100 rows, ~90s
python test_e2e_pipeline.py              # 200 rows, ~3min (default)
python test_e2e_pipeline.py --full       # 500 rows, ~6min
python test_e2e_pipeline.py --no-api     # 100% heur√≠stico

# Execu√ß√£o com dados reais
python run_pipeline.py
```

## üí° Diretrizes de Desenvolvimento

### Princ√≠pios Fundamentais
1. **TESTAR SEMPRE** - Cada mudan√ßa testada imediatamente
2. **DADOS REAIS** - Usar datasets reais, n√£o sint√©ticos
3. **REFATORAR INCREMENTALMENTE** - Pequenas mudan√ßas validadas
4. **FALHAR R√ÅPIDO** - Detectar problemas cedo
5. **MEDIR IMPACTO** - Comparar performance antes/depois

### Workflow Obrigat√≥rio
```python
# Baseline ‚Üí Mudan√ßa ‚Üí Teste ‚Üí Valida√ß√£o ‚Üí Commit
df_original = pd.read_csv('data/controlled_test_100.csv', sep=';')
baseline_results = pipeline.process_dataset(df_original.copy())
# ... c√≥digo modificado ...
new_results = pipeline.process_dataset(df_test.copy())
assert len(new_results) == len(baseline_results)
```

## üîß Pol√≠ticas de Implementa√ß√£o

### Refatora√ß√£o de M√≥dulos
```python
# 1. Branch ‚Üí 2. M√≥dulo isolado ‚Üí 3. Teste ‚Üí 4. Integra√ß√£o ‚Üí 5. Consolida√ß√£o
refactoring_checklist = {
    'political_analyzer.py': {'tested': False, 'integrated': False},
    'sentiment_analyzer.py': {'tested': False, 'integrated': False}
}
# Consolidar APENAS se todos passaram
```

### Debugging e Valida√ß√£o
```python
# Logging detalhado
logging.debug(f"Input: {df.shape}, Columns: {df.columns.tolist()}")

# Tratamento de erros com contexto
try:
    result = complex_operation(data)
except Exception as e:
    logging.error(f"Erro: {e}, Context: {data.shape}")
    raise

# Valida√ß√£o pragm√°tica
def validate_dataframe(df, stage_name):
    validations = {'not_empty': len(df) > 0, 'has_text': 'text' in df.columns}
    failed = [k for k, v in validations.items() if not v]
    if failed: logging.warning(f"Stage {stage_name}: {failed}")
    return df
```

### Otimiza√ß√£o e Cache
```python
# Medir antes de otimizar
@measure_performance
def expensive_function(): pass

# Cache inteligente
@lru_cache(maxsize=10)
def cached_operation(cache_key): pass

# Monitoramento de mem√≥ria
def check_memory(expected_gb=2.0):
    mem_gb = psutil.Process().memory_info().rss / 1024**3
    if mem_gb > expected_gb: gc.collect()
```

## üìù Controle de Mudan√ßas

### Estrutura do Changelog
```markdown
## [2025-09-30] - Sprint Atual
### ‚úÖ Adicionado: Pipeline 22 est√°gios, valida√ß√£o dados reais
### üîÑ Modificado: political_analyzer.py otimiza√ß√£o (linha 45-67)
### üêõ Corrigido: Bug mem√≥ria stage_15, encoding UTF-8
### üìä M√©tricas: Tempo 45s‚Üí31s, Mem√≥ria 2.1GB‚Üí1.4GB
```

### Automa√ß√£o
```python
class ChangelogManager:
    def add_change(self, type, description, details=None):
        # Buffer autom√°tico com timestamp
    def commit_to_changelog(self, version=None):
        # Consolida√ß√£o por tipo: added/changed/fixed/removed
```

## üé≠ Orquestra√ß√£o de Tarefas

### Padr√£o de Orquestra√ß√£o
```python
@dataclass
class Task:
    name: str
    function: Callable
    dependencies: List[str] = None
    retry_count: int = 3
    timeout: float = 300
    critical: bool = True

class PragmaticOrchestrator:
    def add_task(self, task: Task): # Registrar tarefa
    async def run_task(self, task_name: str): # Executar com retry/timeout
    async def orchestrate(self): # Executar respeitando depend√™ncias
```

### Exemplo de Uso
```python
orchestrator = PragmaticOrchestrator()
orchestrator.add_task(Task("load_data", lambda: pd.read_csv(...), critical=True))
orchestrator.add_task(Task("validate", validate_func, dependencies=["load_data"]))
results = await orchestrator.orchestrate()
```

### Monitoramento
```python
class OrchestratorMonitor:
    def print_status(self): # Status visual das tarefas
    def get_metrics(self): # M√©tricas de sucesso/falha
```

## üîÑ Regras de Desenvolvimento

### Pol√≠tica de Atualiza√ß√µes
**ANTES** de modificar: LISTAR ‚Üí PRESERVAR ‚Üí COMENTAR ‚Üí TESTAR

### Edi√ß√£o de C√≥digo
```python
# ‚ùå NUNCA: Deletar arquivo inteiro, reescrever do zero
# ‚úÖ SEMPRE: Identificar trecho exato, mostrar "linhas X-Y", verificar impactos
```

### Verifica√ß√£o de Integra√ß√£o
- [ ] Fun√ß√£o alterada: onde √© chamada?
- [ ] Import modificado: quais arquivos importam?
- [ ] Output alterado: verificar pipelines dependentes

### Implementa√ß√£o
```python
# Dados reais obrigat√≥rios
if not os.path.exists(data_path):
    raise FileNotFoundError(f"Dados reais necess√°rios: {data_path}")

# Guardrails sempre
assert data is not None and len(data) > 0
assert required_columns.issubset(data.columns)
```

### Continuidade de Pipeline
```python
# Pipeline atual:
# [‚úì] Etapa 1: Coleta ‚Üí [‚úì] Etapa 2: Limpeza ‚Üí [‚ñ∫] Etapa 3: ALTERANDO
```

## ‚ö†Ô∏è Checklist Cr√≠tico
- [ ] Arquivo em `/src`?
- [ ] Nome preservado?
- [ ] C√≥digo comentado?
- [ ] CHANGELOG atualizado?
- [ ] Linguagem acad√™mica?

## üö´ Proibi√ß√µes
- ‚ùå Inventar fun√ß√µes sem verificar
- ‚ùå Criar fora de `/src`
- ‚ùå Usar linguagem comercial
- ‚ùå Criar `.fixed`/`.new`
- ‚ùå Deletar sem preservar

## üìä Dados e Arquivos

### Datasets de Pesquisa
- `data/1_2019-2021-govbolso.csv` (135.9 MB) - Per√≠odo Bolsonaro
- `data/2_2021-2022-pandemia.csv` (230.0 MB) - Pandemia
- `data/3_2022-2023-poseleic.csv` (93.2 MB) - P√≥s-elei√ß√£o
- `data/4_2022-2023-elec.csv` (54.2 MB) - Elei√ß√µes
- `data/5_2022-2023-elec-extra.csv` (25.2 MB) - Dados extras
- `data/controlled_test_100.csv` (0.0 MB) - Teste validado

### Arquivos Cr√≠ticos
**Sistema Principal:**
- `/src/analyzer.py` - Pipeline consolidado 17 est√°gios otimizados (SOURCE OF TRUTH)
- `/run_pipeline.py` - Script de execu√ß√£o principal
- `/test_e2e_pipeline.py` - Teste ponta-a-ponta v6.2 (6 API stages, 4 modos)

**Dashboard:**
- `/src/dashboard/data_analysis_dashboard.py` - Dashboard principal
- `/src/dashboard/start_dashboard.py` - Iniciador do dashboard

## üìù Atualiza√ß√µes Recentes

### Fev 2026 ‚Äî API Integration v6.2 (6 Stages)
- ‚úÖ **6 stages com API h√≠brida**: S06 (affordances), S08 (pol√≠tico), S11 (topic naming), S12 (sentimento), S16 (eventos), S17 (canais)
- ‚úÖ **126 colunas** output (113 base + 13 API)
- ‚úÖ **Teste E2E** completo: `test_e2e_pipeline.py` (quick/standard/full/stress)
- ‚úÖ **Valida√ß√£o**: 17/17 stages, 0 erros em 100/200/500 rows
- ‚úÖ **Resultados API**: neutral 9.4%, t√≥picos nomeados, 22 eventos, canais reclassificados

### Fev 2026 ‚Äî Reestrutura√ß√£o + Modulariza√ß√£o (v6.0)
- ‚úÖ **8 bugs corrigidos** no pipeline (spaCy input, caps/emoji/hashtag, token names, URL detection)
- ‚úÖ **TCW integrado** no Stage 08 (217 c√≥digos, 10 categorias, 181 termos √∫nicos)
- ‚úÖ **L√©xico expandido** com macrotemas corrup√ß√£o e pol√≠tica externa
- ‚úÖ **Token matching** reformulado: set() lookup com spaCy lemmas ‚Üí O(1)/token
- ‚úÖ **Modulariza√ß√£o completa** (TAREFA 11): 19 arquivos em src/stages/
- ‚úÖ **4 testes ponta-a-ponta** em 3 datasets diferentes, 0 erros

### Out 2025 ‚Äî Pipeline Consolidado
- ‚úÖ Pipeline otimizado em 17 stages sequenciais
- ‚úÖ Sistema de deduplica√ß√£o cross-dataset (redu√ß√£o 40-50%)
- ‚úÖ Filtros de qualidade e relev√¢ncia pol√≠tica
- ‚úÖ Classifica√ß√£o pol√≠tica brasileira integrada
- ‚úÖ Dashboard unificado dispon√≠vel

---
**Version**: v6.2 (API Integration: 6 stages hybrid) | **RAM**: 4GB | **Colunas**: 126 | **Focus**: An√°lise discurso pol√≠tico brasileiro