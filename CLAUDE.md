# digiNEV v.final - Brazilian Political Discourse Analysis

## ğŸ¯ CONTEXTO
**Tipo**: Pesquisa AcadÃªmica em CiÃªncias Sociais
**Foco**: AnÃ¡lise sociolÃ³gica de discurso polÃ­tico brasileiro
**Dataset**: Mensagens Telegram (2019-2023)
**Specs**: 4GB RAM | Portuguese-optimized | 17 stages cientÃ­ficos otimizados | Consolidado

## ğŸ—ï¸ Sistema CientÃ­fico Consolidado v.final

### Pipeline CientÃ­fico Otimizado (17 estÃ¡gios) - IMPLEMENTADO E VALIDADO
**FASE 1: PREPARAÃ‡ÃƒO (01-02)**
1. **Feature Extraction (01)**: DetecÃ§Ã£o automÃ¡tica de colunas e features
2. **Text Preprocessing (02)**: Limpeza bÃ¡sica de texto em portuguÃªs

**FASE 2: REDUÃ‡ÃƒO DE VOLUME (03-06) - CRÃTICO PARA PERFORMANCE**
3. **Cross-Dataset Deduplication (03)**: EliminaÃ§Ã£o de duplicatas (reduÃ§Ã£o 40-50%)
4. **Statistical Analysis (04)**: AnÃ¡lise estatÃ­stica comparativa
5. **Content Quality Filter (05)**: Filtro de qualidade (reduÃ§Ã£o 15-25%)
6. **Political Relevance Filter (06)**: Filtro de relevÃ¢ncia polÃ­tica (reduÃ§Ã£o 30-40%)

**FASE 3: ANÃLISE LINGUÃSTICA (07-09) - VOLUME OTIMIZADO**
7. **Linguistic Processing (07)**: Processamento linguÃ­stico avanÃ§ado com spaCy
8. **Political Classification (08)**: ClassificaÃ§Ã£o polÃ­tica brasileira
9. **TF-IDF Vectorization (09)**: TF-IDF com tokens spaCy

**FASE 4: ANÃLISES AVANÃ‡ADAS (10-17)**
10. **Clustering Analysis (10)**: Clustering baseado em features linguÃ­sticas
11. **Topic Modeling (11)**: Topic modeling com embeddings
12. **Semantic Analysis (12)**: AnÃ¡lise semÃ¢ntica avanÃ§ada
13. **Temporal Analysis (13)**: AnÃ¡lise temporal
14. **Network Analysis (14)**: CoordenaÃ§Ã£o e padrÃµes de rede
15. **Domain Analysis (15)**: AnÃ¡lise de domÃ­nios e URLs
16. **Event Context (16)**: DetecÃ§Ã£o de contextos polÃ­ticos
17. **Channel Analysis (17)**: ClassificaÃ§Ã£o de canais/fontes

**Stack**: Python | scikit-learn | spaCy pt_core_news_sm | pandas | numpy | Anthropic Claude API

### API Integration (v6.1) â€” Fev 2026
- **3 stages com API**: Stage 06 (affordances), Stage 08 (polÃ­tico), Stage 12 (sentimento)
- **PadrÃ£o**: HeurÃ­stica 100% â†’ API apenas para baixa confianÃ§a (threshold configurÃ¡vel)
- **Modelo**: `claude-sonnet-4-20250514` (Sonnet 4)
- **Batch API**: Suportada (50% desconto), ativÃ¡vel via `USE_BATCH_API=true` no `.env`
- **Prompt Caching**: Ativo (90% desconto no input repetido)
- **Fallback**: Sem API key â†’ 100% heurÃ­stica (pipeline NUNCA falha)
- **Colunas novas**: `political_confidence`, `sentiment_confidence`, `emotion_anger/fear/hope/disgust`, `emotion_sarcasm`
- **Resultados reais**: Stage 08 neutral 40%â†’9.4% | Stage 12 +sarcasmo/emoÃ§Ãµes granulares
- **MÃ©todos genÃ©ricos**: `_api_classify_sync()`, `_api_submit_batch()`, `_api_poll_batch()`, `_api_process_low_confidence()`

### ModularizaÃ§Ã£o (TAREFA 11) â€” Fev 2026
- Cada stage extraÃ­do como mÃ³dulo independente em `src/stages/stage_XX.py`
- Registry de stages: `from stages import STAGE_REGISTRY`
- Helpers compartilhados: `from stages.helpers import _calculate_emoji_ratio, ...`
- `src/analyzer.py` = **source of truth** (versÃ£o autoritativa inline)
- `src/stages/` = versÃ£o modular de referÃªncia, 1:1 com os mÃ©todos inline
- 19 arquivos: 17 stages + helpers.py + __init__.py (3327 linhas total)

### ReestruturaÃ§Ã£o do Pipeline (TARETAs 1-10) â€” Fev 2026
- **8 bugs corrigidos**: spaCy input, caps/emoji/hashtag sobre body, token names, URL detection
- **TCW integrado** no Stage 08 (217 cÃ³digos, 10 categorias, 181 termos)
- **LÃ©xico expandido**: +2 macrotemas (corrupÃ§Ã£o, polÃ­tica externa) no lexico_unified_system.json
- **Keywords expandido**: +2 categorias (cat11_corrupcao, cat12_politica_externa)
- **Token matching** via set() lookup com spaCy lemmas (O(1) por token)

## ğŸš€ ExecuÃ§Ã£o

### Uso ProgramÃ¡tico
```python
from src.analyzer import Analyzer

analyzer = Analyzer()
output = analyzer.analyze(df)  # Retorna dict
result_df = output['data']     # DataFrame com 120 colunas (113 base + 7 API)
print(f"Stages: {output['stages_completed']}/17")
print(f"Colunas: {output['columns_generated']}")
```

### Teste RÃ¡pido com Dados Reais
```python
import pandas as pd
from src.analyzer import Analyzer

df = pd.read_csv('path/to/dataset.csv', nrows=500, sep=',',
                  quotechar='"', quoting=1, on_bad_lines='skip')
analyzer = Analyzer()
output = analyzer.analyze(df)
print(f"Rows: {len(df)} â†’ {output['total_records']} (pÃ³s-filtro)")
```

## ğŸ”§ CaracterÃ­sticas Principais

### ClassificaÃ§Ã£o PolÃ­tica (Stage 05)
- **Categorias**: extrema-direita, direita, centro, esquerda, neutral, unknown
- **LÃ©xico polÃ­tico brasileiro** integrado
- **ClassificaÃ§Ã£o baseada** em anÃ¡lise de conteÃºdo real

### Recursos Implementados
- **spaCy**: Processamento linguÃ­stico em portuguÃªs (pt_core_news_lg)
- **scikit-learn**: TF-IDF, K-Means clustering, LDA topic modeling
- **Python puro**: AnÃ¡lise estatÃ­stica, temporal e de redes
- **Regex otimizado**: ExtraÃ§Ã£o de features em portuguÃªs brasileiro

## ğŸ“ Estrutura

```
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ analyzer.py              # Pipeline principal (17 stages inline) â€” SOURCE OF TRUTH
â”‚   â”œâ”€â”€ lexicon_loader.py        # Carregador de lÃ©xico polÃ­tico
â”‚   â”œâ”€â”€ core/                    # Recursos de classificaÃ§Ã£o
â”‚   â”‚   â”œâ”€â”€ lexico_unified_system.json  # LÃ©xico unificado (12 macrotemas)
â”‚   â”‚   â”œâ”€â”€ political_keywords_dict.py  # Keywords polÃ­ticas (12 categorias)
â”‚   â”‚   â”œâ”€â”€ tcw_codes.json              # TCW: 217 cÃ³digos, 181 termos
â”‚   â”‚   â””â”€â”€ tcw_categories.json         # TCW: 10 categorias temÃ¡ticas
â”‚   â”œâ”€â”€ stages/                  # MÃ³dulos extraÃ­dos (TAREFA 11)
â”‚   â”‚   â”œâ”€â”€ __init__.py          # STAGE_REGISTRY + imports
â”‚   â”‚   â”œâ”€â”€ helpers.py           # 21 funÃ§Ãµes utilitÃ¡rias compartilhadas
â”‚   â”‚   â”œâ”€â”€ stage_01.py          # Feature Extraction
â”‚   â”‚   â”œâ”€â”€ stage_02.py          # Text Preprocessing
â”‚   â”‚   â”œâ”€â”€ ...                  # Stages 03-17
â”‚   â”‚   â””â”€â”€ stage_17.py          # Channel Analysis
â”‚   â””â”€â”€ dashboard/               # Dashboard acadÃªmico
â”œâ”€â”€ config/                      # ConfiguraÃ§Ã£o unificada
â”‚   â””â”€â”€ settings.yaml            # ConfiguraÃ§Ãµes principais
â”œâ”€â”€ data/                        # Datasets de pesquisa
â””â”€â”€ run_pipeline.py              # Script principal de execuÃ§Ã£o
```

### Regras Estruturais
- TODO cÃ³digo cientÃ­fico em `/src`
- ConfiguraÃ§Ã£o distribuÃ­da em `/config`
- NUNCA criar `.fixed`, `.new`, `.updated`
- SEMPRE editar arquivos in-place

## ğŸ”¬ AplicaÃ§Ãµes de Pesquisa
- EvoluÃ§Ã£o da polarizaÃ§Ã£o polÃ­tica (2019-2023)
- PadrÃµes de legitimaÃ§Ã£o da violÃªncia
- Marcadores do discurso autoritÃ¡rio
- AnÃ¡lise de coordenaÃ§Ã£o em rede
- Indicadores de erosÃ£o democrÃ¡tica

## ğŸ“Š SaÃ­da de Dados
- **113 colunas** geradas pelo pipeline sequencial de 17 stages (102 features + 11 originais)
- ClassificaÃ§Ã£o polÃ­tica (extrema-direita, direita, centro-direita, neutral)
- AnÃ¡lise estatÃ­stica (word_count, char_count, sentence_count, caps_ratio, emoji_ratio)
- Features extraÃ­das (hashtags, URLs, mentions, emojis â€” sobre body cru)
- DeduplicaÃ§Ã£o cross-dataset com contador de frequÃªncia
- Filtros de qualidade com scores 0-100
- Affordances (8 categorias: ataque, interaÃ§Ã£o, mÃ­dia_social, mobilizaÃ§Ã£o, etc.)
- spaCy: tokens, lemmas, entities, lemmatized_text (sobre body cru)
- ClassificaÃ§Ã£o polÃ­tica com token matching via set() sobre spacy_lemmas
- TCW: tcw_codes (3-digit), tcw_categories (10 cat.), tcw_agreement (1-3)
- TF-IDF com scores e top termos (sobre lemmatized_text)
- Clustering K-Means com distÃ¢ncias calculadas
- Topic modeling LDA com probabilidades reais
- AnÃ¡lise temporal, network, domÃ­nios, eventos, canais

### Resultados de ValidaÃ§Ã£o (4 testes ponta-a-ponta, Fev 2026)

| Teste | Dataset | Rows inâ†’out | Stages | Errors | Tempo |
|-------|---------|-------------|--------|--------|-------|
| 1 | 4_elec (100) | 100â†’67 | 17/17 | 0 | 0.7s |
| 2 | 4_elec (500) | 500â†’298 | 17/17 | 0 | 3.4s |
| 3 | 2_pandemia (1000) | 1000â†’705 | 17/17 | 0 | 7.6s |
| 4 | 1_govbolso (2000) | 2000â†’717 | 17/17 | 0 | 6.1s |

## ğŸ§ª Testes
```bash
# Teste do pipeline consolidado
python test_clean_analyzer.py

# ExecuÃ§Ã£o com dados reais
python run_pipeline.py
```

## ğŸ’¡ Diretrizes de Desenvolvimento

### PrincÃ­pios Fundamentais
1. **TESTAR SEMPRE** - Cada mudanÃ§a testada imediatamente
2. **DADOS REAIS** - Usar datasets reais, nÃ£o sintÃ©ticos
3. **REFATORAR INCREMENTALMENTE** - Pequenas mudanÃ§as validadas
4. **FALHAR RÃPIDO** - Detectar problemas cedo
5. **MEDIR IMPACTO** - Comparar performance antes/depois

### Workflow ObrigatÃ³rio
```python
# Baseline â†’ MudanÃ§a â†’ Teste â†’ ValidaÃ§Ã£o â†’ Commit
df_original = pd.read_csv('data/controlled_test_100.csv', sep=';')
baseline_results = pipeline.process_dataset(df_original.copy())
# ... cÃ³digo modificado ...
new_results = pipeline.process_dataset(df_test.copy())
assert len(new_results) == len(baseline_results)
```

## ğŸ”§ PolÃ­ticas de ImplementaÃ§Ã£o

### RefatoraÃ§Ã£o de MÃ³dulos
```python
# 1. Branch â†’ 2. MÃ³dulo isolado â†’ 3. Teste â†’ 4. IntegraÃ§Ã£o â†’ 5. ConsolidaÃ§Ã£o
refactoring_checklist = {
    'political_analyzer.py': {'tested': False, 'integrated': False},
    'sentiment_analyzer.py': {'tested': False, 'integrated': False}
}
# Consolidar APENAS se todos passaram
```

### Debugging e ValidaÃ§Ã£o
```python
# Logging detalhado
logging.debug(f"Input: {df.shape}, Columns: {df.columns.tolist()}")

# Tratamento de erros com contexto
try:
    result = complex_operation(data)
except Exception as e:
    logging.error(f"Erro: {e}, Context: {data.shape}")
    raise

# ValidaÃ§Ã£o pragmÃ¡tica
def validate_dataframe(df, stage_name):
    validations = {'not_empty': len(df) > 0, 'has_text': 'text' in df.columns}
    failed = [k for k, v in validations.items() if not v]
    if failed: logging.warning(f"Stage {stage_name}: {failed}")
    return df
```

### OtimizaÃ§Ã£o e Cache
```python
# Medir antes de otimizar
@measure_performance
def expensive_function(): pass

# Cache inteligente
@lru_cache(maxsize=10)
def cached_operation(cache_key): pass

# Monitoramento de memÃ³ria
def check_memory(expected_gb=2.0):
    mem_gb = psutil.Process().memory_info().rss / 1024**3
    if mem_gb > expected_gb: gc.collect()
```

## ğŸ“ Controle de MudanÃ§as

### Estrutura do Changelog
```markdown
## [2025-09-30] - Sprint Atual
### âœ… Adicionado: Pipeline 22 estÃ¡gios, validaÃ§Ã£o dados reais
### ğŸ”„ Modificado: political_analyzer.py otimizaÃ§Ã£o (linha 45-67)
### ğŸ› Corrigido: Bug memÃ³ria stage_15, encoding UTF-8
### ğŸ“Š MÃ©tricas: Tempo 45sâ†’31s, MemÃ³ria 2.1GBâ†’1.4GB
```

### AutomaÃ§Ã£o
```python
class ChangelogManager:
    def add_change(self, type, description, details=None):
        # Buffer automÃ¡tico com timestamp
    def commit_to_changelog(self, version=None):
        # ConsolidaÃ§Ã£o por tipo: added/changed/fixed/removed
```

## ğŸ­ OrquestraÃ§Ã£o de Tarefas

### PadrÃ£o de OrquestraÃ§Ã£o
```python
@dataclass
class Task:
    name: str
    function: Callable
    dependencies: List[str] = None
    retry_count: int = 3
    timeout: float = 300
    critical: bool = True

class PragmaticOrchestrator:
    def add_task(self, task: Task): # Registrar tarefa
    async def run_task(self, task_name: str): # Executar com retry/timeout
    async def orchestrate(self): # Executar respeitando dependÃªncias
```

### Exemplo de Uso
```python
orchestrator = PragmaticOrchestrator()
orchestrator.add_task(Task("load_data", lambda: pd.read_csv(...), critical=True))
orchestrator.add_task(Task("validate", validate_func, dependencies=["load_data"]))
results = await orchestrator.orchestrate()
```

### Monitoramento
```python
class OrchestratorMonitor:
    def print_status(self): # Status visual das tarefas
    def get_metrics(self): # MÃ©tricas de sucesso/falha
```

## ğŸ”„ Regras de Desenvolvimento

### PolÃ­tica de AtualizaÃ§Ãµes
**ANTES** de modificar: LISTAR â†’ PRESERVAR â†’ COMENTAR â†’ TESTAR

### EdiÃ§Ã£o de CÃ³digo
```python
# âŒ NUNCA: Deletar arquivo inteiro, reescrever do zero
# âœ… SEMPRE: Identificar trecho exato, mostrar "linhas X-Y", verificar impactos
```

### VerificaÃ§Ã£o de IntegraÃ§Ã£o
- [ ] FunÃ§Ã£o alterada: onde Ã© chamada?
- [ ] Import modificado: quais arquivos importam?
- [ ] Output alterado: verificar pipelines dependentes

### ImplementaÃ§Ã£o
```python
# Dados reais obrigatÃ³rios
if not os.path.exists(data_path):
    raise FileNotFoundError(f"Dados reais necessÃ¡rios: {data_path}")

# Guardrails sempre
assert data is not None and len(data) > 0
assert required_columns.issubset(data.columns)
```

### Continuidade de Pipeline
```python
# Pipeline atual:
# [âœ“] Etapa 1: Coleta â†’ [âœ“] Etapa 2: Limpeza â†’ [â–º] Etapa 3: ALTERANDO
```

## âš ï¸ Checklist CrÃ­tico
- [ ] Arquivo em `/src`?
- [ ] Nome preservado?
- [ ] CÃ³digo comentado?
- [ ] CHANGELOG atualizado?
- [ ] Linguagem acadÃªmica?

## ğŸš« ProibiÃ§Ãµes
- âŒ Inventar funÃ§Ãµes sem verificar
- âŒ Criar fora de `/src`
- âŒ Usar linguagem comercial
- âŒ Criar `.fixed`/`.new`
- âŒ Deletar sem preservar

## ğŸ“Š Dados e Arquivos

### Datasets de Pesquisa
- `data/1_2019-2021-govbolso.csv` (135.9 MB) - PerÃ­odo Bolsonaro
- `data/2_2021-2022-pandemia.csv` (230.0 MB) - Pandemia
- `data/3_2022-2023-poseleic.csv` (93.2 MB) - PÃ³s-eleiÃ§Ã£o
- `data/4_2022-2023-elec.csv` (54.2 MB) - EleiÃ§Ãµes
- `data/5_2022-2023-elec-extra.csv` (25.2 MB) - Dados extras
- `data/controlled_test_100.csv` (0.0 MB) - Teste validado

### Arquivos CrÃ­ticos
**Sistema Principal:**
- `/src/analyzer.py` - Pipeline consolidado 17 estÃ¡gios otimizados
- `/run_pipeline.py` - Script de execuÃ§Ã£o principal
- `/test_clean_analyzer.py` - Teste do sistema

**Dashboard:**
- `/src/dashboard/data_analysis_dashboard.py` - Dashboard principal
- `/src/dashboard/start_dashboard.py` - Iniciador do dashboard

## ğŸ“ AtualizaÃ§Ãµes Recentes

### Fev 2026 â€” ReestruturaÃ§Ã£o + ModularizaÃ§Ã£o
- âœ… **8 bugs corrigidos** no pipeline (spaCy input, caps/emoji/hashtag, token names, URL detection)
- âœ… **TCW integrado** no Stage 08 (217 cÃ³digos, 10 categorias, 181 termos Ãºnicos)
- âœ… **LÃ©xico expandido** com macrotemas corrupÃ§Ã£o e polÃ­tica externa
- âœ… **Token matching** reformulado: set() lookup com spaCy lemmas â†’ O(1)/token
- âœ… **ModularizaÃ§Ã£o completa** (TAREFA 11): 19 arquivos em src/stages/
- âœ… **4 testes ponta-a-ponta** em 3 datasets diferentes, 0 erros
- âœ… **113 colunas** output consistente em todos os testes

### Out 2025 â€” Pipeline Consolidado
- âœ… Pipeline otimizado em 17 stages sequenciais
- âœ… Sistema de deduplicaÃ§Ã£o cross-dataset (reduÃ§Ã£o 40-50%)
- âœ… Filtros de qualidade e relevÃ¢ncia polÃ­tica
- âœ… ClassificaÃ§Ã£o polÃ­tica brasileira integrada
- âœ… Dashboard unificado disponÃ­vel

---
**Version**: v.final (ReestruturaÃ§Ã£o + ModularizaÃ§Ã£o) | **RAM**: 4GB | **Focus**: AnÃ¡lise discurso polÃ­tico brasileiro